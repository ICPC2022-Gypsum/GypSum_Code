{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open('../pretrain_models/bert_nmt/code_bert.json','r',encoding='utf-8').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": 51, \"code\": \"def get config value request key default search in settings True value request session get key request COOKIES get key if value is None if search in settings value getattr settings key default else value defaultif isinstance default int try value int value except Value Error value request session[key] int default return value\", \"predictions\": [\"get a cookie value from requests cache or cookies .\"], \"references\": [\"retrieves the value of key from configuration in the following order: - from the session; if not found there then - from cookies; if not found there then - from the settings file if search_in_settings is true .\"], \"bleu\": 0.009116101522508774, \"rouge_l\": 0.11310259579728059}\n",
      "\n",
      "{\"id\": 86, \"code\": \"def download **kwargs kwargs['direction'] DOWNLOA Dreturn scp **kwargs\", \"predictions\": [\"download a scipy .\"], \"references\": [\"run the local scp command to download a file or directory from a remote host and kill it if the reactor stops .\"], \"bleu\": 0.004396209659757786, \"rouge_l\": 0.19719827586206898}\n",
      "\n",
      "{\"id\": 99, \"code\": \"def get redirect url course key usage key course key chapter section vertical unused position final target id path to location modulestore usage key if chapter is None redirect url reverse 'courseware' args unicode course key elif section is None redirect url reverse 'courseware chapter' args unicode course key chapter elif position is None redirect url reverse 'courseware section' args unicode course key chapter section else redirect url reverse 'courseware position' args unicode course key chapter section navigation index position redirect url + '?{}' format urlencode {'activate block id' unicode final target id } return redirect url\", \"predictions\": [\"returns the redirect url for the current request .\"], \"references\": [\"returns the redirect url back to courseware args: course_id: course id string location: the location id of course component raises: itemnotfounderror if no data at the location or nopathtoitem if location not in any class returns: redirect url string .\"], \"bleu\": 0.013640065972840808, \"rouge_l\": 0.21981981981981982}\n",
      "\n",
      "{\"id\": 126, \"code\": \"def load pickle fname with get file obj fname 'rb' as fin return c Pickle load fin\", \"predictions\": [\"load pickle object from a file .\"], \"references\": [\"load a previously saved object from file parameters fname : str filename to unpickle notes this method can be used to load *both* models and results .\"], \"bleu\": 0.017352550286093733, \"rouge_l\": 0.2659110723626853}\n",
      "\n",
      "{\"id\": 227, \"code\": \"def write callback option opt str value parser * args ** kwargs if not hasattr parser values 'write' option dest 'write'option action 'store false'parser values write Falsefor in range 3 testphrase ' Yes Iwanttoenablewritesupport'response raw input ' Writesupportrequested Pleasetype\\\"' + testphrase + '\\\"belowprecisely case-sensitive \\\\n' if response testphrase option action 'store true'parser values write Truereturnprint ' Writesupportdisabled '\", \"predictions\": [\"callback for setting option to write the output .\"], \"references\": [\"callback function to ensure that write support is only enabled if user repeats a long string this call back checks whether the user really wants write support and then either enables it by changing the option to store_true .\"], \"bleu\": 0.008189852908276235, \"rouge_l\": 0.18723143032535294}\n",
      "\n",
      "{\"id\": 271, \"code\": \"def restart cluster if TRAFFICCTL cmd traffic ctl 'cluster' 'restart' '--manager' else cmd traffic line '-M' log debug ' Running %s' cmd return subprocess cmd\", \"predictions\": [\"restart cluster .\"], \"references\": [\"restart the traffic_manager process and the traffic_server process on all the nodes in a cluster .\"], \"bleu\": 0.009971877423139049, \"rouge_l\": 0.28110599078341014}\n",
      "\n",
      "{\"id\": 289, \"code\": \"def convert host to hex host ips []if host is not None for family ip in convert host to ip host hexip nf binascii b2 a hex socket inet pton family ip hexip hf ''for i in range 0 len hexip nf 8 ipgroup nf hexip nf[i i + 8 ]ipgroup hf socket ntohl int ipgroup nf base 16 hexip hf '%s% 08 X' % hexip hf ipgroup hf ips append family hexip hf return ips\", \"predictions\": [\"convert host to hex string of \\\"ips\\\" format .\"], \"references\": [\"convert the provided host to the format in /proc/net/tcp* /proc/net/tcp uses little-endian four byte hex for ipv4 /proc/net/tcp6 uses little-endian per 4b word for ipv6 args: host: string with either hostname .\"], \"bleu\": 0.01843141533161088, \"rouge_l\": 0.2657952069716775}\n",
      "\n",
      "{\"id\": 378, \"code\": \"def get tftp image info instance instance type image info {'kernel' [ None None] 'ramdisk' [ None None] 'deploy kernel' [ None None] 'deploy ramdisk' [ None None]}try image info['kernel'][ 0 ] str instance['kernel id'] image info['ramdisk'][ 0 ] str instance['ramdisk id'] image info['deploy kernel'][ 0 ] get deploy aki id instance type image info['deploy ramdisk'][ 0 ] get deploy ari id instance type except Key Error as e passmissing labels []for label in image info keys uuid path image info[label]if not uuid missing labels append label else image info[label][ 1 ] os path join CONF baremetal tftp root instance['uuid'] label if missing labels raise exception Nova Exception ' Cannotactivate PX Ebootloader Thefollowingbootparameterswerenotpassedtobaremetaldriver %s' % missing labels return image info\", \"predictions\": [\"get the tftp from the filesystem .\"], \"references\": [\"generate the paths for tftp files for this instance raises novaexception if - instance does not contain kernel_id or ramdisk_id - deploy_kernel_id or deploy_ramdisk_id can not be read from instance_type[extra_specs] and defaults are not set .\"], \"bleu\": 0.0037084735360148682, \"rouge_l\": 0.16587355540448673}\n",
      "\n",
      "{\"id\": 410, \"code\": \"def build collection type dataset instances dataset collection model Dataset Collection set collection elements dataset collection type dataset instances return dataset collection\", \"predictions\": [\"build the collection of a dataset .\"], \"references\": [\"build datasetcollection with populated datasetcollectionelement objects corresponding to the supplied dataset instances or throw exception if this is not a valid collection of the specified type .\"], \"bleu\": 0.01794160530120456, \"rouge_l\": 0.2659110723626853}\n",
      "\n",
      "{\"id\": 456, \"code\": \"def create path docker compose if docker compose ret write docker compose path docker compose if isinstance ret dict return retelse return standardize result False ' Creatingadocker-composeprojectfailed youmustsendavaliddocker-composefile' None None return standardize result True ' Successfullycreatedthedocker-composefile' {'compose base dir' path} None\", \"predictions\": [\"create docker-compose file .\"], \"references\": [\"create and validate a docker-compose file into a directory path path where the docker-compose file will be stored on the server docker_compose docker_compose file cli example: .\"], \"bleu\": 0.0017100602717573356, \"rouge_l\": 0.22761194029850745}\n",
      "\n",
      "{\"id\": 598, \"code\": \"def sessions app url 'http //localhost 8080 /manager' timeout 180 return simple cmd 'sessions' app url timeout timeout\", \"predictions\": [\"list the server sessions for the given app .\"], \"references\": [\"return the status of the webapp sessions app the webapp context path url : URL the url of the server manager webapp timeout : 180 timeout for http request cli examples: .\"], \"bleu\": 0.01843141533161088, \"rouge_l\": 0.17719680464778503}\n",
      "\n",
      "{\"id\": 683, \"code\": \"def connection info for db or uri if db or uri startswith 'postgresql //' 'postgres //' us urlparse urlsplit db or uri if len us path > 1 db name us path[ 1 ]elif us username db name us usernameelse db name us hostnamereturn db name {'dsn' db or uri} connection info {'database' db or uri}for p in 'host' 'port' 'user' 'password' cfg tools config[ 'db ' + p ]if cfg connection info[p] cfgreturn db or uri connection info\", \"predictions\": [\"get connection info from a db .\"], \"references\": [\"parse the given db_or_uri and return a 2-tuple connection params are either a dictionary with a single key dsn containing a connection uri .\"], \"bleu\": 0.019474777613022468, \"rouge_l\": 0.17613089509143406}\n",
      "\n",
      "{\"id\": 829, \"code\": \"def interpret in shape xshape if isinstance xshape int nin nsteps xshape 1 elif len xshape 2 nin nsteps xshapeelse nin np prod xshape[ -1 ] nsteps xshape[ -1 ]return nin nsteps\", \"predictions\": [\"see :shape: xshape .\"], \"references\": [\"helper function to interpret the tensor layout of preceding layer for input to a recurrent layer .\"], \"bleu\": 0.013931732312048943, \"rouge_l\": 0.08567415730337079}\n",
      "\n",
      "{\"id\": 1119, \"code\": \"def tokens Match expected Tokens received Tokens ignore Error Order ignore Errors False check Self Closing Falsefor token in expected Tokens if token[ 0 ] ' Start Tag' and len token 4 or token[ 0 ] ' End Tag' and len token 3 check Self Closing Truebreakif not check Self Closing for token in received Tokens if token[ 0 ] ' Start Tag' or token[ 0 ] ' End Tag' token pop if not ignore Error Order and not ignore Errors return expected Tokens received Tokens else tokens {'expected' [[] []] 'received' [[] []]}for token Type token List in zip tokens keys expected Tokens received Tokens for token in token List if token ' Parse Error' tokens[token Type][ 0 ] append token elif not ignore Errors tokens[token Type][ 1 ] append token return tokens['expected'] tokens['received']\", \"predictions\": [\"check that the tokens match the given tokens .\"], \"references\": [\"test whether the test has passed or failed if the ignoreerrororder flag is set to true we dont test the relative positions of parse errors and non parse errors .\"], \"bleu\": 0.016276220793949598, \"rouge_l\": 0.14022988505747128}\n",
      "\n",
      "{\"id\": 1144, \"code\": \"def bookmark absent name force False recursive False return absent name 'bookmark' force recursive\", \"predictions\": [\"ensure that the bookmark bookmark is absent .\"], \"references\": [\"ensure bookmark is absent on the system name : string name of snapshot force : boolean try harder to destroy the dataset recursive : boolean also destroy all the child datasets .\"], \"bleu\": 0.017091627935930588, \"rouge_l\": 0.22559171597633138}\n",
      "\n",
      "{\"id\": 1195, \"code\": \"def read msgpack path or buf encoding 'utf- 8 ' iterator False **kwargs path or buf get filepath or buffer path or buf if iterator return Iterator path or buf def read fh l list unpack fh encoding encoding **kwargs if len l 1 return l[ 0 ]return lif isinstance path or buf compat string types try exists os path exists path or buf except Type Error Value Error exists Falseif exists with open path or buf 'rb' as fh return read fh if isinstance path or buf compat binary type fh Nonetry fh compat Bytes IO path or buf return read fh finally if fh is not None fh close if hasattr path or buf 'read' and compat callable path or buf read return read path or buf raise Value Error 'path or bufneedstobeastringfilepathorfile-like'\", \"predictions\": [\"reads msgpack objects from file .\"], \"references\": [\"load msgpack pandas object from the specified file path this is an experimental library and the storage format may not be stable until a future release .\"], \"bleu\": 0.0083876826971184, \"rouge_l\": 0.2174688057040998}\n",
      "\n",
      "{\"id\": 1209, \"code\": \"def p function p if p[ 1 ] 'oneway' oneway Truebase 1else oneway Falsebase 0if p[ len p - 1 ] ' ' throws []else throws p[ len p - 1 ]p[ 0 ] [oneway p[ base + 1 ] p[ base + 2 ] p[ base + 4 ] throws]\", \"predictions\": [\"function : function .\"], \"references\": [\"function : oneway function_type identifier throws | oneway function_type identifier | function_type identifier throws | function_type identifier .\"], \"bleu\": 0.015344279425461304, \"rouge_l\": 0.24465240641711228}\n",
      "\n",
      "{\"id\": 1302, \"code\": \"def main try set Up Directory Set Current Directory ORIG DIR from iptest process util import launch ironpython changing extensionsret val launch ironpython changing extensions 'dllsite py' add ['-S'] additional Script Params 'O Kto Run' finally clean Up exit ret val\", \"predictions\": [\"main entry point .\"], \"references\": [\"runs the test by spawning off another ip process which utilizes the newly created dlls directory .\"], \"bleu\": 0.013931732312048943, \"rouge_l\": 0.08567415730337079}\n",
      "\n",
      "{\"id\": 1388, \"code\": \"def init rate 22050 bits 16 stereo True buffer 1024 global Sound audio Driver Sound Sound Pygameaudio Driver 'n/a'if stereo True stereo Chans 2else stereo Chans 0if bits 16 bits -16 mixer init rate bits stereo Chans buffer sndarray use arraytype 'numpy' set Rate set Bits set Stereo mixer get init if set Rate rate logging warn ' Requestedsoundsampleratewasnotpoossible' if set Bits bits logging warn ' Requestedsounddepth bits wasnotpossible' if set Stereo 2 and stereo True logging warn ' Requestedstereosettingwasnotpossible'\", \"predictions\": [\"initialize audio channel .\"], \"references\": [\"if you need a specific format for sounds you need to run this init function .\"], \"bleu\": 0.017888698387160718, \"rouge_l\": 0.09023668639053255}\n",
      "\n",
      "{\"id\": 1392, \"code\": \"def get locales from config locales offered config get 'ckan locales offered' '' split filtered out config get 'ckan locales filtered out' '' split locale default [config get 'ckan locale default' 'en' ]locale order config get 'ckan locale order' '' split known locales get locales all locales set known locales set locales offered set locale order set locale default all locales - set filtered out return all locales\", \"predictions\": [\"get a list of locales .\"], \"references\": [\"despite the name of this function it gets the locales defined by the config and also the locals available subject to the config .\"], \"bleu\": 0.013078614250991381, \"rouge_l\": 0.1804733727810651}\n",
      "\n",
      "{\"id\": 1406, \"code\": \"def make linkcode resolve package url fmt revision get git revision return partial linkcode resolve revision revision package package url fmt url fmt\", \"predictions\": [\"return a compiled linkcode .\"], \"references\": [\"returns a linkcode_resolve function for the given url format revision is a git commit reference package is the name of the root module of the package url_fmt is along the lines of .\"], \"bleu\": 0.0011172634455759794, \"rouge_l\": 0.09291698400609291}\n",
      "\n",
      "{\"id\": 1474, \"code\": \"def objtag accessing obj accessed obj *args **kwargs return accessed obj tags get *args\", \"predictions\": [\"usage: obj .\"], \"references\": [\"usage: objtag objtag only true if accessed_obj has the specified tag and optional category .\"], \"bleu\": 0.010890544041151608, \"rouge_l\": 0.1983739837398374}\n",
      "\n",
      "{\"id\": 1613, \"code\": \"def NDP Attack Fake Router ra iface None mac src filter None ip src filter None def is request req mac src filter ip src filter '\\\\n Checkifpacketreqisarequest\\\\n'if not Ether in req and I Pv 6 in req and ICM Pv 6 ND RS in req return 0mac src req[ Ether] srcif mac src filter and mac src mac src filter return 0ip src req[I Pv 6 ] srcif ip src filter and ip src ip src filter return 0return 1def ra reply callback req iface '\\\\n Callbackthatsendsan R Ainreplytoan RS\\\\n'src req[I Pv 6 ] srcsendp ra iface iface verbose 0 print ' Fake R Asentinresponseto R Sfrom%s' % src if not iface iface conf ifacesniff filter 'icmp 6 'sniff store 0 filter sniff filter lfilter lambda x is request x mac src filter ip src filter prn lambda x ra reply callback x iface iface iface\", \"predictions\": [\"fake version of rpc .\"], \"references\": [\"the purpose of this function is to send provided ra message at layer 2 in response to received rs messages .\"], \"bleu\": 0.012315792024227385, \"rouge_l\": 0.13847900113507378}\n",
      "\n",
      "{\"id\": 1650, \"code\": \"@pytest mark parametrize u'mode' modes def test gaussian eval 2D mode model Gaussian 2 D 1 0 0 20 20 x np arange -100 101 y np arange -100 101 x y np meshgrid x y values model x y disc values discretize model model -100 101 -100 101 mode mode assert allclose values disc values atol 0 001\", \"predictions\": [\"test gaussian model .\"], \"references\": [\"discretize gaussian with different modes and check if result is at least similar to gaussian1d .\"], \"bleu\": 0.019797099072043068, \"rouge_l\": 0.1804733727810651}\n",
      "\n",
      "{\"id\": 1662, \"code\": \"def access sandbox name asset ids result util oauthgetm '%s/%s' % 'sandbox' 'access' {'sandbox' sandbox name 'id' asset ids} return result['response']['assets']\", \"predictions\": [\"return the access list of asset names .\"], \"references\": [\"returns a list of assets with expiring access urls that can be used to download them *requires oauth* args: sandbox_name : a string representing the name of the sandbox asset_ids : a list of asset_ids to fetch kwargs: returns: a list of asset dictionaries example: .\"], \"bleu\": 0.00297007958641445, \"rouge_l\": 0.16433189655172414}\n",
      "\n",
      "{\"id\": 1665, \"code\": \"def follow all url parser token bits token split contents if len bits 2 raise Template Syntax Error ' Acceptedformat{%follow all url[instance]%}' else return Display Activity Follow Url bits[ 1 ] actor only False\", \"predictions\": [\"displays all follow links .\"], \"references\": [\"renders the url to follow an object as both actor and target <a href=\\\"{% follow_all_url other_user %}\\\"> {% if request .\"], \"bleu\": 0.012315792024227385, \"rouge_l\": 0.13847900113507378}\n",
      "\n",
      "{\"id\": 1668, \"code\": \"def preprocess expr func None hint ' Integral' derivs expr atoms Derivative if not func funcs set union *[d atoms Applied Undef for d in derivs] if len funcs 1 raise Value Error ' Thefunctioncannotbeautomaticallydetectedfor%s ' % expr func funcs pop fvars set func args if hint is None return expr func reps [ d d doit for d in derivs if not hint endswith ' Integral' or d has func or set d variables & fvars ]eq expr subs reps return eq func\", \"predictions\": [\"preprocess expr using a rational preprocessor .\"], \"references\": [\"prepare expr for solving by making sure that differentiation is done so that only func remains in unevaluated derivatives and that doit is applied to all other derivatives .\"], \"bleu\": 0.008872121459794557, \"rouge_l\": 0.10008203445447088}\n",
      "\n",
      "{\"id\": 1712, \"code\": \"@task task ignore result True def get and store friends user facebook try logger info 'attemptingtogetandstorefriendsfor%s' user id stored friends facebook get and store friends user logger info 'celeryisstoring%sfriends' len stored friends return stored friendsexcept Integrity Error as e logger warn 'get and store friendsfailedfor%switherror%s' user id e\", \"predictions\": [\"runs get_page() .\"], \"references\": [\"since facebook is quite slow this version also runs the get on the background inserting again will not cause any errors .\"], \"bleu\": 0.0010560774867844412, \"rouge_l\": 0.14071510957324107}\n",
      "\n",
      "{\"id\": 1747, \"code\": \"def get barcode curr seq barcode len raw barcode curr seq[ 0 barcode len]raw seq curr seq[barcode len ]return raw barcode raw seq\", \"predictions\": [\"a barcode .\"], \"references\": [\"split sequence into barcode and remaining sequence linker and primer part of remaining sequence .\"], \"bleu\": 0.010890544041151608, \"rouge_l\": 0.1983739837398374}\n",
      "\n",
      "{\"id\": 1805, \"code\": \"def process keys remote xbmc done 0try xbmc previous keyexcept xbmc previous key ''xbmc connect datalen 0try data remote recv 1024 datalen len data except Exception as e if str e 'timedout' return 2time sleep 2 raise eif datalen 13 keycode data encode 'hex' [10 12 ]if keycode 'ff' xbmc release button return donetry if xbmc previous key '43 ' xbmc previous key keycodeif keycode '31 ' return 3elif keycode '30 ' return 4xbmc previous key keycodeif g keymap[keycode] xbmc send remote button g keymap[keycode] except Exception as e print ' Unknowndata %s' % str e return done\", \"predictions\": [\"this function calls the xbmc client to use keys from xbmc .\"], \"references\": [\"return codes: 0 - key was processed normally 2 - socket read timeout 3 - ps and then skip plus was pressed 4 - ps and then skip minus was pressed fixme: move to enums .\"], \"bleu\": 0.01556187881441492, \"rouge_l\": 0.07644110275689221}\n",
      "\n",
      "{\"id\": 1841, \"code\": \"def topological sort elems result []visited set def visit n if n not in visited visited add n if n in elems map visit elems[n] result append n map visit elems return result\", \"predictions\": [\"topological sort: visit(s) .\"], \"references\": [\"return a list of elements sorted so that their dependencies are listed before them in the result .\"], \"bleu\": 0.010850044034164912, \"rouge_l\": 0.08155080213903743}\n",
      "\n",
      "{\"id\": 1875, \"code\": \"@register simple tagdef bootstrap form errors *args **kwargs return render form errors *args **kwargs\", \"predictions\": [\"render form errors from template .\"], \"references\": [\"render form errors **tag name**:: bootstrap_form_errors **parameters**: form the form that is to be rendered type control which type of errors should be rendered .\"], \"bleu\": 0.0183208083974659, \"rouge_l\": 0.23238095238095238}\n",
      "\n",
      "{\"id\": 1885, \"code\": \"def qiime open fp permission 'U' if is gzip fp return gzip open fp else return open fp permission\", \"predictions\": [\"open qi file .\"], \"references\": [\"wrapper to allow opening of gzipped or non-compressed files read or write the contents of a file file_fp : file path permission : either r .\"], \"bleu\": 0.001625044850085843, \"rouge_l\": 0.11776061776061778}\n",
      "\n",
      "{\"id\": 1906, \"code\": \"def test finder only installs data require data finder Package Finder [] [data index url 'datarequire' ] session Pip Session links finder find all candidates 'fakepackage' expected [' 1 0 0' '9 9 9']if sys version info < 2 7 expected append '2 6 0' elif 2 7 < sys version info < 3 expected append '2 7 0' elif sys version info > 3 3 expected append '3 3 0' assert set [str v version for v in links] set expected\", \"predictions\": [\"test packagefinder only installs data require .\"], \"references\": [\"test whether the packagefinder understand data-python-requires this can optionally be exposed by a simple-repository to tell which distribution are compatible with which version of python by adding a data-python-require to the anchor links .\"], \"bleu\": 0.004667150639433924, \"rouge_l\": 0.13080771979985703}\n",
      "\n",
      "{\"id\": 1916, \"code\": \"def approx fprime cs x f epsilon None args kwargs {} n len x epsilon get epsilon x 1 epsilon n increments np identity n * 1j * epsilon partials [ f x + ih *args **kwargs imag / epsilon[i] for i ih in enumerate increments ]return np array partials T\", \"predictions\": [\"see :func:f(fprime .\"], \"references\": [\"calculate gradient or jacobian with complex step derivative approximation parameters x : array parameters at which the derivative is evaluated f : function f(*(+args) .\"], \"bleu\": 0.00035105768763006985, \"rouge_l\": 0.06256410256410255}\n",
      "\n",
      "{\"id\": 1918, \"code\": \"def qnwlogn n mu None sig 2 None nodes weights qnwnorm n mu sig 2 return np exp nodes weights\", \"predictions\": [\"compute the q-th coefficient of n-th n-th entropy .\"], \"references\": [\"computes nodes and weights for multivariate lognormal distribution parameters n : int or array_like a length-d iterable of the number of nodes in each dimension mu : scalar or array_like .\"], \"bleu\": 0.014564602295577704, \"rouge_l\": 0.13646532438478745}\n",
      "\n",
      "{\"id\": 2095, \"code\": \"@register inclusion tag 'addons/tags box html' @jinja 2 contextfunctiondef tags box context addon tags None c dict context items c update {'addon' addon 'tags' tags} return c\", \"predictions\": [\"displays box .\"], \"references\": [\"details page: show a box with existing tags along with a form to add new ones .\"], \"bleu\": 0.005591391746305624, \"rouge_l\": 0.17758369723435224}\n",
      "\n",
      "{\"id\": 2149, \"code\": \"def get file encoding content encoding Nonetry lines to check content split u'\\\\n' 2 for index in range 2 if len lines to check > index line encoding search coding line lines to check[index] if line encoding encoding line encodingbreakexcept Unicode Decode Error as error print errorif encoding is None encoding u'UTF- 8 'return encoding\", \"predictions\": [\"determine encoding .\"], \"references\": [\"try to get the encoding of the file using the pep 0263 rules search the first or the second line of the file returns the encoding or the default utf-8 .\"], \"bleu\": 5.2579002036298904e-05, \"rouge_l\": 0.10243492863140219}\n",
      "\n",
      "{\"id\": 2181, \"code\": \"def textile text head offset 0 html type 'xhtml' encoding None output None return Textile textile text head offset head offset html type html type\", \"predictions\": [\"return a textile of text .\"], \"references\": [\"this function takes additional parameters: head_offset - offset to apply to heading levels html_type - xhtml or html style tags .\"], \"bleu\": 0.01813224057849837, \"rouge_l\": 0.0673289183222958}\n",
      "\n",
      "{\"id\": 2234, \"code\": \"def pretty depth depth np clip depth 0 2 ** 10 - 1 depth depth >> 2depth depth astype np uint 8 return depth\", \"predictions\": [\"turn a depth into a pretty-negative integer .\"], \"references\": [\"converts depth into a nicer format for display this is abstracted to allow for experimentation with normalization args: depth: a numpy array with 2 bytes per pixel returns: a numpy array that has been processed whos datatype is unspecified .\"], \"bleu\": 0.00604995648388928, \"rouge_l\": 0.14878048780487804}\n",
      "\n",
      "{\"id\": 2252, \"code\": \"def update chain graph loc du ud ins graph get ins from loc loc for var in ins get used vars for def loc in set ud[ var loc ] du[ var def loc ] remove loc ud[ var loc ] remove def loc if not ud get var loc ud pop var loc if def loc > 0 and not du[ var def loc ] du pop var def loc def ins graph get ins from loc def loc if def ins is call def ins remove defined var elif def ins has side effect continueelse update chain graph def loc du ud graph remove ins def loc\", \"predictions\": [\"update chain graph with location in chain_locals .\"], \"references\": [\"updates the du chain of the instruction located at loc such that there is no more reference to it so that we can remove it .\"], \"bleu\": 0.01870562754502435, \"rouge_l\": 0.1073943661971831}\n",
      "\n",
      "{\"id\": 2341, \"code\": \"def stddev from average timeseries series pandas Series [x[ 1 ] for x in timeseries] mean series mean std Dev series std t tail avg timeseries return abs t - mean > 3 * std Dev\", \"predictions\": [\"returns the stddth from average of timeseries .\"], \"references\": [\"a timeseries is anomalous if the absolute value of the average of the latest three datapoint minus the moving average is greater than three standard deviations of the average .\"], \"bleu\": 0.016045011753648093, \"rouge_l\": 0.190625}\n",
      "\n",
      "{\"id\": 2345, \"code\": \"@contextfilterdef currency format context value currency None if not currency currency Currency objects get is default True if not currency symbol return unicode value + '' + currency code else return currency symbol + unicode value\", \"predictions\": [\"formats currency according to the current currency .\"], \"references\": [\"adds the currency symbol as set in sales module settings to a given string if the currency has no symbol it adds a three letter code to the end e .\"], \"bleu\": 0.01415967317452787, \"rouge_l\": 0.23176291793313067}\n",
      "\n",
      "{\"id\": 2357, \"code\": \"def whitespace around comma logical line line logical linefor m in WHITESPACE AFTER COMMA REGEX finditer line found m start + 1 if ' DCTB ' in m group yield found \\\"E 242 tabafter'%s'\\\" % m group [0 ] else yield found \\\"E 241 multiplespacesafter'%s'\\\" % m group [0 ]\", \"predictions\": [\"avoid extraneous whitespace .\"], \"references\": [\"avoid extraneous whitespace in the following situations: - more than one space around an assignment operator to align it with another .\"], \"bleu\": 0.007855246784369016, \"rouge_l\": 0.273542600896861}\n",
      "\n",
      "{\"id\": 2362, \"code\": \"def docformat docstring docdict None if not docstring return docstringif docdict is None docdict {}if not docdict return docstringlines docstring expandtabs splitlines if len lines < 2 icount 0else icount indentcount lines lines[ 1 ] indent '' * icount indented {}for name dstr in docdict items lines dstr expandtabs splitlines try newlines [lines[ 0 ]]for line in lines[ 1 ] newlines append indent + line indented[name] '\\\\n' join newlines except Index Error indented[name] dstrreturn docstring % indented\", \"predictions\": [\"pretty print the docstring .\"], \"references\": [\"fill a function docstring from variables in dictionary adapt the indent of the inserted docs parameters docstring : string docstring from function .\"], \"bleu\": 0.00887113600998264, \"rouge_l\": 0.19202518363064006}\n",
      "\n",
      "{\"id\": 2395, \"code\": \"def test external js and css resource embedding class Custom Model 1 Model javascript 'external js 1' css 'external css 1'class Custom Model 2 Model javascript ['external js 2' 'external js 3'] css ['external css 2' 'external css 3']class Custom Model 3 Model javascript ['external js 1' 'external js 3'] css ['external css 1' 'external css 2']r resources Resources assert 'external js 1' in r js files assert 'external css 1' in r css files assert 'external js 2' in r js files assert 'external js 3' in r js files assert 'external css 2' in r css files assert 'external css 3' in r css files assert r css files count 'external css 1' 1 assert r css files count 'external css 2' 1 assert r js files count 'external js 3' 1 assert r js files count 'external js 1' 1\", \"predictions\": [\"test that external_external_external_external_external function works as javascript files .\"], \"references\": [\"this test method has to be at the end of the test modules because subclassing a model causes the custommodel to be added as a viewable and messes up the resources state for the other tests .\"], \"bleu\": 0.007477716150450982, \"rouge_l\": 0.11753371868978803}\n",
      "\n",
      "{\"id\": 2459, \"code\": \"def child max dependencies dependents scores result dict num needed dict k len v for k v in dependencies items current set k for k v in num needed items if v 0 while current key current pop score scores[key]children dependencies[key]if children score + max result[child] for child in children result[key] scorefor parent in dependents[key] num needed[parent] - 1if num needed[parent] 0 current add parent return result\", \"predictions\": [\"the score that has no more than dependencies .\"], \"references\": [\"maximum-ish of scores of children this takes a dictionary of scores per key and returns a new set of scores per key that is the maximum of the scores of all children of that node plus its own score .\"], \"bleu\": 0.005665414001429893, \"rouge_l\": 0.10990990990990991}\n",
      "\n",
      "{\"id\": 2482, \"code\": \"def test read twoline normal table '\\\\n Col 1 Col 2 \\\\n-------------\\\\n 1 2xx\\\"hello\\\"\\\\n 2 4\\\\'sworlds\\\\n'dat ascii read table Reader ascii Fixed Width Two Line assert equal dat dtype names ' Col 1 ' ' Col 2 ' assert almost equal dat[ 1 ][ 0 ] 2 4 assert equal dat[ 0 ][ 1 ] '\\\"hello\\\"' assert equal dat[ 1 ][ 1 ] \\\"'sworlds\\\"\", \"predictions\": [\"read twoline .\"], \"references\": [\"typical fixed format table with two header lines (with some cruft thrown in to test column positioning .\"], \"bleu\": 0.003620197623718955, \"rouge_l\": 0.08437067773167356}\n",
      "\n",
      "{\"id\": 2512, \"code\": \"def cleanup oauth url redirect uri if '?' in redirect uri redirect base redirect query redirect uri split '?' 1 query dict items Query Dict redirect query items else query dict items Query Dict '' True excluded query items [ k v for k v in query dict items if k lower in DROP QUERY PARAMS ]for k v in excluded query items redirect uri remove query param redirect uri k redirect uri redirect uri strip '?' redirect uri redirect uri strip '&' return redirect uri\", \"predictions\": [\"clean up redirects .\"], \"references\": [\"we have to maintain order with respect to the queryparams which is a bit of a pain todo: very hacky will subclass querydict to sortedquerydict at some point and use a decent sort function .\"], \"bleu\": 0.0001547675660262702, \"rouge_l\": 0.04485294117647059}\n",
      "\n",
      "{\"id\": 2608, \"code\": \"def reconstruct A B z f factorint igcd A B for p e in f items if e 1 raise Value Error 'aandbshouldbesquare-free' z * preturn z\", \"predictions\": [\"reconstruct a polynomial from aandbsand f(x)and(a) y(a) .\"], \"references\": [\"reconstruct the z value of an equivalent solution of ax^2 + by^2 + cz^2 from the z value of a solution of the square-free normal form of the equation .\"], \"bleu\": 0.012891018425181842, \"rouge_l\": 0.14296875}\n",
      "\n",
      "{\"id\": 2726, \"code\": \"def run statement filename None sort -1 prof Profile try prof prof run statement except System Exit passif filename is not None prof dump stats filename else return prof print stats sort\", \"predictions\": [\"run statement under profiler .\"], \"references\": [\"run statement under profiler optionally saving results in filename this function takes a single argument that can be passed to the \\\"exec\\\" statement .\"], \"bleu\": 0.017790820037134242, \"rouge_l\": 0.3083923154701719}\n",
      "\n",
      "{\"id\": 2761, \"code\": \"def atomic open filename mode 'w' if mode in 'r' 'rb' 'r+' 'rb+' 'a' 'ab' raise Type Error \\\" Readorappendmodesdon'tworkwithatomic open\\\" ntf tempfile Named Temporary File mode prefix ' atomic write' dir os path dirname filename delete False return Atomic W File ntf ntf name filename\", \"predictions\": [\"create a atomic file .\"], \"references\": [\"works like a regular open() but writes updates into a temporary file instead of the given file and moves it over when the file is closed .\"], \"bleu\": 0.003986058353908482, \"rouge_l\": 0.16681859617137648}\n",
      "\n",
      "{\"id\": 2894, \"code\": \"def exists *nictag **kwargs ret {}nictagadm check nictagadm if len nictag 0 return {' Error' ' Pleaseprovideatleastonenictagtocheck '}cmd '{nictagadm}exists-l{nictags}' format nictagadm nictagadm nictags '' join nictag res salt ['cmd run all'] cmd if not kwargs get 'verbose' False ret res['retcode'] 0 else missing res['stderr'] splitlines for nt in nictag ret[nt] nt not in missing return ret\", \"predictions\": [\"check if nictag exists .\"], \"references\": [\"check if nictags exists nictag : string one or more nictags to check verbose : boolean return list of nictags cli example: .\"], \"bleu\": 0.011675071568105216, \"rouge_l\": 0.25603357817418676}\n",
      "\n",
      "{\"id\": 2922, \"code\": \"def verify structure memlen itemsize ndim shape strides offset if offset % itemsize return Falseif offset < 0 or offset + itemsize > memlen return Falseif any v % itemsize for v in strides return Falseif ndim < 0 return ndim 0 and not shape and not strides if 0 in shape return Trueimin sum strides[j] * shape[j] - 1 for j in range ndim if strides[j] < 0 imax sum strides[j] * shape[j] - 1 for j in range ndim if strides[j] > 0 return 0 < offset + imin and offset + imax + itemsize < memlen\", \"predictions\": [\"check if items are valid .\"], \"references\": [\"verify that the parameters represent a valid array within the bounds of the allocated memory: char *mem: start of the physical memory block memlen: length of the physical memory block offset: buf - mem .\"], \"bleu\": 0.0019458999024608275, \"rouge_l\": 0.08652482269503545}\n",
      "\n",
      "{\"id\": 2964, \"code\": \"def get Location **kwargs global CURRENT LA Tglobal CURRENT LO Nif kwargs is not None CURRENT LAT kwargs['lat']CURRENT LON kwargs['lon']\", \"predictions\": [\"global function for setting a location .\"], \"references\": [\"this function is called by configure for setting current gps location in global variables info: the on_location and on_status callables might be called from another thread than the thread used for creating the gps object .\"], \"bleu\": 0.0047971653933833345, \"rouge_l\": 0.20734194425560845}\n",
      "\n",
      "{\"id\": 3153, \"code\": \"def extract subrois timeseries file label file indices from nipype utils filemanip import split filenameimport nibabel as nbimport osimg nb load timeseries file data img get data roiimg nb load label file rois roiimg get data prefix split filename timeseries file [1 ]out ts file os path join os getcwd u'%s subcortical ts txt' % prefix with open out ts file u'wt' as fp for fsindex in indices ijk np nonzero rois fsindex ts data[ijk]for i0 row in enumerate ts fp write u'%d %d %d %d ' % fsindex ijk[ 0 ][i 0 ] ijk[ 1 ][i 0 ] ijk[ 2 ][i 0 ] + u' ' join [ u'% 10 f' % val for val in row] + u'\\\\n' return out ts file\", \"predictions\": [\"extract timeseries from the label indices file .\"], \"references\": [\"extract voxel time courses for each subcortical roi index parameters timeseries_file: a 4d nifti file label_file: a 3d file containing rois in the same space/size of the 4d file indices: a list of indices for rois to extract .\"], \"bleu\": 0.004380273704134083, \"rouge_l\": 0.1521197007481297}\n",
      "\n",
      "{\"id\": 3160, \"code\": \"@require GE Tdef set subscription request token subscribe try username Username Cipher decrypt token encode user User objects get username username except Unicode Decode Error raise Http 404 'base 64 url' except Username Decryption Exception as exn raise Http 404 exn message except User Does Not Exist raise Http 404 'username' if subscribe User Preference objects get or create user user key NOTIFICATION PREF KEY defaults {'value' Username Cipher encrypt user username } return render to response 'resubscribe html' {'token' token} else User Preference objects filter user user key NOTIFICATION PREF KEY delete return render to response 'unsubscribe html' {'token' token}\", \"predictions\": [\"setting subscription .\"], \"references\": [\"a view that disables or re-enables notifications for a user who may not be authenticated this view is meant to be the target of an unsubscribe link .\"], \"bleu\": 0.00012914690594428887, \"rouge_l\": 0.05632502308402585}\n",
      "\n",
      "{\"id\": 3269, \"code\": \"def concat datetimetz to concat name None if len set [str x dtype for x in to concat] 1 raise Value Error 'to concatmusthavethesametz' tz to concat[ 0 ] tznew values np concatenate [x asi 8 for x in to concat] return to concat[ 0 ] simple new new values tz tz name name\", \"predictions\": [\"concatenate datetimals .\"], \"references\": [\"concat datetimeindex with the same tz all inputs must be datetimeindex it is used in datetimeindex .\"], \"bleu\": 0.005052392784929312, \"rouge_l\": 0.08879184861717612}\n",
      "\n",
      "{\"id\": 3279, \"code\": \"def ones like x dtype None name None return tf ones like x dtype dtype name name\", \"predictions\": [\"equivalent of numpy .\"], \"references\": [\"instantiates an all-ones keras variable of the same shape as another keras variable or tensor and returns it .\"], \"bleu\": 0.009351487442933324, \"rouge_l\": 0.15561224489795916}\n",
      "\n",
      "{\"id\": 3441, \"code\": \"def split url or path url or path if ' //' in url or path return url or path rstrip '/' rsplit '/' 1 return osp split url or path rstrip osp sep\", \"predictions\": [\"return a split url .\"], \"references\": [\"return the latest component of a string containing either an url of the form <scheme>://<path> or a local file system path .\"], \"bleu\": 0.011456860824837005, \"rouge_l\": 0.26608505997818976}\n",
      "\n",
      "{\"id\": 3484, \"code\": \"def sim otu table sample ids otu ids samples otu metadata tree num replicates dissimilarity sample dicts []res sam names []for i sample info in enumerate samples sample vector sample info[ 0 ]for j in range num replicates sample dict {}for k in range len otu ids otu abundance sample vector[k]if otu abundance 0 continuenew otu id get new otu id otu ids[k] tree dissimilarity if new otu id in sample dict sample dict[new otu id] + otu abundanceelse sample dict[new otu id] otu abundancesample dicts append sample dict res sam names append sample ids[i] + ' ' + str j res otu mtx res otus combine sample dicts sample dicts res otu metadata []if otu metadata is None or otu metadata [] res otu metadata Noneelse for otu id in res otus try res otu metadata append otu metadata[otu ids index otu id ] except Value Error res otu metadata append None return res sam names res otus res otu mtx res otu metadata\", \"predictions\": [\"given a sample otu table .\"], \"references\": [\"make n samples related to each sample in an input otu table input: the constituents of an otu table * sample_ids: list * otu_ids: list * samples: iterable .\"], \"bleu\": 0.007147179089626634, \"rouge_l\": 0.20435510887772193}\n",
      "\n",
      "{\"id\": 3512, \"code\": \"def list prefix None bin env None user None cwd None packages {}if prefix is None or 'pip' startswith prefix packages['pip'] version bin env for line in freeze bin env bin env user user cwd cwd if line startswith '-f' or line startswith '#' continueelif line startswith '-ehg+nottrust' continueelif line startswith '-e' line line split '-e' [1 ] version name line split '#egg ' elif len line split ' ' > 2 name line split ' ' [0 ]version line split ' ' [1 ]else logger error \\\" Can'tparseline'{ 0 }'\\\" format line continueif prefix if name lower startswith prefix lower packages[name] version else packages[name] version return packages\", \"predictions\": [\"list all available packages .\"], \"references\": [\"filter list of installed apps from freeze and check to see if prefix exists in the list of packages installed .\"], \"bleu\": 0.013234179795826943, \"rouge_l\": 0.20771850170261064}\n",
      "\n",
      "{\"id\": 3537, \"code\": \"def get sleep on power button ret salt utils mac utils execute return result 'systemsetup-getallowpowerbuttontosleepcomputer' return salt utils mac utils validate enabled salt utils mac utils parse return ret 'on'\", \"predictions\": [\"get whether sleep on or not .\"], \"references\": [\"displays whether allow power button to sleep computer is on or off if supported :return: a string value representing the \\\"allow power button to sleep computer\\\" settings :rtype: string cli example: .\"], \"bleu\": 0.008173654384096259, \"rouge_l\": 0.22984174830444618}\n",
      "\n",
      "{\"id\": 3647, \"code\": \"def channel hop 2 mon iface global monchannel first pass args jamming daemon runningchannel Num 0if args channel with lock monchannel args channelwhile jamming daemon running if not args channel channel Num + 1if channel Num > 11 channel Num 1with lock first pass 0with lock monchannel channel Nummon iface set channel monchannel output monchannel if args channel time sleep 0 05 elif first pass 1 time sleep 1 continuedeauth monchannel\", \"predictions\": [\"make channel indexing on one socket .\"], \"references\": [\"first time it runs through the channels it stays on each channel for 5 seconds in order to populate the deauth list nicely .\"], \"bleu\": 0.019474777613022468, \"rouge_l\": 0.11742059672762271}\n",
      "\n",
      "{\"id\": 3650, \"code\": \"def send email confirmation request user signup False from models import Email Address Email Confirmation COOLDOWN PERIOD timedelta minutes 3 email user email user if email try email address Email Address objects get for user user email if not email address verified if app settings EMAIL CONFIRMATION HMAC send email Trueelse send email not Email Confirmation objects filter sent gt now - COOLDOWN PERIOD email address email address exists if send email email address send confirmation request signup signup else send email Falseexcept Email Address Does Not Exist send email Trueemail address Email Address objects add email request user email signup signup confirm True assert email addressif send email get adapter request add message request messages INFO 'account/messages/email confirmation sent txt' {'email' email} if signup get adapter request stash user request user pk to url str user\", \"predictions\": [\"send email confirmation page to send an email .\"], \"references\": [\"e-mail verification mails are sent: a) explicitly: when a user signs up b) implicitly: when a user attempts to log in using an unverified e-mail while email_verification is mandatory .\"], \"bleu\": 0.016276220793949598, \"rouge_l\": 0.14022988505747128}\n",
      "\n",
      "{\"id\": 3710, \"code\": \"def zeromq event registry xml parent data zmq event XML Sub Element xml parent 'org jenkinsci plugins ZMQ Event Publisher Hudson Notification Property' XML Sub Element zmq event 'enabled' text 'true'\", \"predictions\": [\"yaml: zeromq-omq event registry .\"], \"references\": [\"yaml: zeromq-event this is a jenkins plugin that will publish jenkins job run events to a zmq pub socket .\"], \"bleu\": 0.01504254234731835, \"rouge_l\": 0.14437869822485208}\n",
      "\n",
      "{\"id\": 3728, \"code\": \"def Underride d **options if d is None d {}for key val in options items d setdefault key val return d\", \"predictions\": [\"override options .\"], \"references\": [\"add key-value pairs to d only if key is not in d .\"], \"bleu\": 0.019167100299515256, \"rouge_l\": 0.1123388581952118}\n",
      "\n",
      "{\"id\": 3789, \"code\": \"@never cachedef complete request template u'shop/complete html' extra context None try order Order objects from request request except Order Does Not Exist raise Http 404 items order items all skus [item sku for item in items]variations Product Variation objects filter sku in skus names {}for variation in variations select related u'product' names[variation sku] variation product titlefor i item in enumerate items setattr items[i] u'name' names[item sku] context {u'order' order u'items' items u'has pdf' HAS PDF u'steps' checkout CHECKOUT STEPS}context update extra context or {} return Template Response request template context\", \"predictions\": [\"complete view .\"], \"references\": [\"redirected to once an order is complete - pass the order object for tracking items via google anayltics .\"], \"bleu\": 0.002870716241770844, \"rouge_l\": 0.16073781291172595}\n",
      "\n",
      "{\"id\": 4125, \"code\": \"def generate File From Templates template File Names output File Path replacement Dict install Path os path dirname file output File open output File Path 'w' output Lines []input Lines []first File Truefor template File Name in template File Names if not first File input Lines extend [os linesep] * 2 first File Falseinput File Path os path join install Path template File Name input File open input File Path input Lines extend input File readlines input File close print ' Writing' len input Lines 'lines 'for line in input Lines temp Line linefor k v in replacement Dict iteritems if v is None v ' None'temp Line re sub k v temp Line output File write temp Line output File close\", \"predictions\": [\"generate a set of template files .\"], \"references\": [\"generates a file by applying token replacements to the given template file templatefilename: a list of template file names; these files are assumed to be in the same directory as the running expgenerator .\"], \"bleu\": 0.006142315671093595, \"rouge_l\": 0.21801286633309513}\n",
      "\n",
      "{\"id\": 4128, \"code\": \"def hostinterface create hostid ip dns '' main 1 type 1 useip 1 port None **connection args conn args login **connection args if not port port INTERFACE DEFAULT PORTS[type]try if conn args method 'hostinterface create'params {'hostid' hostid 'ip' ip 'dns' dns 'main' main 'port' port 'type' type 'useip' useip}params params extend params **connection args ret query method params conn args['url'] conn args['auth'] return ret['result']['interfaceids']else raise Key Errorexcept Key Error return ret\", \"predictions\": [\"create an hostinterface .\"], \"references\": [\"create new host interface note: this function accepts all standard host group interface: keyword argument names differ depending on your zabbix version .\"], \"bleu\": 0.0034402199746280714, \"rouge_l\": 0.1314655172413793}\n",
      "\n",
      "{\"id\": 4143, \"code\": \"def check explicit underscore import logical line filename if filename in UNDERSCORE IMPORT FILES passelif underscore import check match logical line or custom underscore check match logical line UNDERSCORE IMPORT FILES append filename elif translated log match logical line or string translation match logical line yield 0 'N 323 Founduseof withoutexplicitimportof '\", \"predictions\": [\"check that explicit underscore function uses explicit_automatically check_function .\"], \"references\": [\"check for explicit import of the _ function we need to ensure that any files that are using the _() function to translate logs are explicitly importing the _ function .\"], \"bleu\": 0.01611838202814164, \"rouge_l\": 0.18195376584638331}\n",
      "\n",
      "{\"id\": 4158, \"code\": \"def test config ip magic 'config'\", \"predictions\": [\"test %config .\"], \"references\": [\"test that config magic does not raise can happen if configurable init is moved too early into magics .\"], \"bleu\": 0.002870716241770844, \"rouge_l\": 0.16073781291172595}\n",
      "\n",
      "{\"id\": 4178, \"code\": \"def With Events disp user event class disp Dispatch disp if not disp class dict get 'CLSID' try ti disp oleobj Get Type Info disp clsid ti Get Type Attr [0 ] tlb index ti Get Containing Type Lib tla tlb Get Lib Attr gencache Ensure Module tla[ 0 ] tla[ 1 ] tla[ 3 ] tla[ 4 ] b Validate File 0 disp class gencache Get Class For Prog ID str disp clsid except pythoncom com error raise Type Error ' This CO Mobjectcannotautomatethemakepyprocess-pleaserunmakepymanuallyforthisobject' else disp class disp class clsid disp class CLSI Dimport newevents class getevents clsid if events class is None raise Value Error ' This CO Mobjectdoesnotsupportevents ' result class new classobj 'COM Event Class' events class user event class {} instance result class disp if hasattr user event class ' init ' user event class init instance return instance\", \"predictions\": [\"similar to dispatch twisted .\"], \"references\": [\"similar to dispatchwithevents - except that the returned object is *not* also usable as the original dispatch object - that is the returned object is not dispatchable .\"], \"bleu\": 0.004103644758770213, \"rouge_l\": 0.2153574580759047}\n",
      "\n",
      "{\"id\": 4235, \"code\": \"def introspect rebulk context None return Introspection rebulk context\", \"predictions\": [\"call introspection .\"], \"references\": [\"introspect a rebulk instance to grab defined objects and properties that can be generated .\"], \"bleu\": 0.00984071741598585, \"rouge_l\": 0.0991869918699187}\n",
      "\n",
      "{\"id\": 4322, \"code\": \"def get module files src directory blacklist STD BLACKLIST files []for directory dirnames filenames in os walk src directory handle blacklist blacklist dirnames filenames if not ' init py' in filenames dirnames[ ] continuefor filename in filenames if is python file filename src join directory filename files append src return files\", \"predictions\": [\"given a python module .\"], \"references\": [\"given a package directory return a list of all available python modules files in the package and its subpackages :type src_directory: str .\"], \"bleu\": 0.011154862978216261, \"rouge_l\": 0.25603357817418676}\n",
      "\n",
      "{\"id\": 4433, \"code\": \"def transform series series force list False vals series valuesreturn transform array vals force list\", \"predictions\": [\"transform the value of a series into a normalize .\"], \"references\": [\"transforms a pandas series into serialized form args: series : the pandas series to transform force_list : whether to only output to standard lists this function can encode some dtypes using a binary encoding .\"], \"bleu\": 0.017402534183403744, \"rouge_l\": 0.20198675496688742}\n",
      "\n",
      "{\"id\": 4467, \"code\": \"def unpack groups hg unbundle 10 obj yield [chunk for chunk in unpack chunks hg unbundle 10 obj ] yield [chunk for chunk in unpack chunks hg unbundle 10 obj ] while True length struct unpack '>l' readexactly hg unbundle 10 obj 4 if length < 4 breakfilename readexactly hg unbundle 10 obj length - 4 encode 'string escape' yield filename [chunk for chunk in unpack chunks hg unbundle 10 obj ]\", \"predictions\": [\"extract a list of groups from a hg file .\"], \"references\": [\"this method provides a generator of parsed groups from a mercurial unbundle10 object which is created when a changeset that is pushed to a tool shed repository using hg push from the command line is read using readbundle .\"], \"bleu\": 0.015352355430572463, \"rouge_l\": 0.2581620314389359}\n",
      "\n",
      "{\"id\": 4480, \"code\": \"def find mapreduce yaml start checked dir startwhile dir not in checked checked add dir for mr yaml name in MR YAML NAMES yaml path os path join dir mr yaml name if os path exists yaml path return yaml pathdir os path dirname dir return None\", \"predictions\": [\"finds the yaml startreduce .\"], \"references\": [\"traverse the directory tree identified by start until a directory already in checked is encountered or the path of mapreduce .\"], \"bleu\": 0.012315792024227385, \"rouge_l\": 0.13847900113507378}\n",
      "\n",
      "{\"id\": 4710, \"code\": \"def test slicing on instance with parameterless model p2 Polynomial 2 D 1 c0 0 1 c1 0 2 c0 1 3 p1 Polynomial 2 D 1 c0 0 1 c1 0 2 c0 1 3 mapping Mapping 0 1 0 1 offx Shift -2 name u'x translation' offy Shift -1 name u'y translation' aff Affine Transformation 2 D matrix [[ 1 2] [3 4]] name u'rotation' model mapping p1 & p2 offx & offy aff assert model param names u'c 0 0 1' u'c 1 0 1' u'c 0 1 1' u'c 0 0 2' u'c 1 0 2' u'c 0 1 2' u'offset 3' u'offset 4' u'matrix 5' u'translation 5' assert model 1 2 23 0 53 0 m model[ 3 ]assert m param names u'offset 3' u'offset 4' u'matrix 5' u'translation 5' assert m 1 2 1 0 1 0\", \"predictions\": [\"test slicing of parameterless objects .\"], \"references\": [\"regression test to fix an issue where the indices attached to parameter names on a compound model were not handled properly when one or more submodels have no parameters .\"], \"bleu\": 0.004477468761653063, \"rouge_l\": 0.0991869918699187}\n",
      "\n",
      "{\"id\": 4795, \"code\": \"@click command u'setup-global-help' @click option u'--mariadb root password' def setup global help mariadb root password None from frappe installer import update site configfrappe local flags frappe dict frappe local flags in setup help Truefrappe local flags in install Truefrappe local lang u'en'frappe local conf frappe get site config sites path u' ' update site config u'global help setup' 1 site config path os path join u' ' u'common site config json' if mariadb root password frappe local conf root password mariadb root passwordfrom frappe utils help import syncsync\", \"predictions\": [\"set global help .\"], \"references\": [\"setup help table in a separate database that will be shared by the whole bench and set global_help_setup as 1 in common_site_config .\"], \"bleu\": 0.003696756943594074, \"rouge_l\": 0.1314655172413793}\n",
      "\n",
      "{\"id\": 5020, \"code\": \"def get head types pat if isinstance pat pytree Node Pattern pytree Leaf Pattern if pat type is None raise Every Nodereturn {pat type}if isinstance pat pytree Negated Pattern if pat content return get head types pat content raise Every Nodeif isinstance pat pytree Wildcard Pattern r set for p in pat content for x in p r update get head types x return rraise Exception \\\" Ohno Idon'tunderstandpattern%s\\\" % pat\", \"predictions\": [\"given a pytreepattern .\"], \"references\": [\"accepts a pytree pattern node and returns a set of the pattern types which will match first .\"], \"bleu\": 0.012007547560562644, \"rouge_l\": 0.16310160427807485}\n",
      "\n",
      "{\"id\": 5036, \"code\": \"def ishow for manager in Gcf get all fig managers manager show if show needmain thread start new thread Fltk run interactive show needmain False\", \"predictions\": [\"run the fltk command .\"], \"references\": [\"show all the figures and enter the fltk mainloop in another thread this allows to keep hand in interractive python session warning: does not work under windows this should be the last line of your script .\"], \"bleu\": 0.0006415229349754184, \"rouge_l\": 0.1256005490734386}\n",
      "\n",
      "{\"id\": 5041, \"code\": \"def restore defaults top level logger logging get Logger name split ' ' [0 ] top level logger propagate Truetop level logger set Level logging NOTSET while top level logger handlers top level logger handlers pop\", \"predictions\": [\"restore logging from default logging .\"], \"references\": [\"use this if you are embedding our library in a larger application and wish to handle logging yourself at the level of the root logger .\"], \"bleu\": 0.008720918324830598, \"rouge_l\": 0.1123388581952118}\n",
      "\n",
      "{\"id\": 5076, \"code\": \"def summarize trans history None summary Workflow Summary trans history return summary jobs summary warnings\", \"predictions\": [\"returns summary of passed in .\"], \"references\": [\"return mapping of job description to datasets for active items in supplied history - needed for building workflow from a history .\"], \"bleu\": 0.018252676551591566, \"rouge_l\": 0.19426751592356686}\n",
      "\n",
      "{\"id\": 5146, \"code\": \"def gen preprocess options macros include dirs pp opts []for macro in macros if not isinstance macro tuple and 1 < len macro < 2 raise Type Error \\\"badmacrodefinition'%s' \\\" + \\\"eachelementof'macros'listmustbea 1 -or 2 -tuple\\\" % macro if len macro 1 pp opts append '-U%s' % macro[ 0 ] elif len macro 2 if macro[ 1 ] is None pp opts append '-D%s' % macro[ 0 ] else pp opts append '-D%s %s' % macro for dir in include dirs pp opts append '-I%s' % dir return pp opts\", \"predictions\": [\"generate c preprocessor options .\"], \"references\": [\"generate c pre-processor options as used by at least two types of compilers: the typical unix compiler and visual c++ .\"], \"bleu\": 0.016641100089707282, \"rouge_l\": 0.27695800227014755}\n",
      "\n",
      "{\"id\": 5158, \"code\": \"def get ip port afi host and port str host and port str host and port str strip if host and port str startswith '[' af socket AF INET 6 host rest host and port str[ 1 ] split ']' if rest port int rest[ 1 ] else port DEFAULT KAFKA POR Treturn host port af elif ' ' not in host and port str af address family host and port str return host and port str DEFAULT KAFKA PORT af else try socket inet pton socket AF INET 6 host and port str return host and port str DEFAULT KAFKA PORT socket AF INET 6 except Attribute Error log warning 'socket inet ptonnotavailableonthisplatform consider`pipinstallwin inet pton`' passexcept Value Error socket error pass host port host and port str rsplit ' ' 1 port int port af address family host return host port af\", \"predictions\": [\"given an ipi string .\"], \"references\": [\"parse the ip and port from a string in the format of: * host_or_ip <- can be either ipv4 address literal or hostname/fqdn * host_or_ipv4:port <- can be either ipv4 address literal or hostname/fqdn * [host_or_ip] <- ipv6 address literal * [host_or_ip]:port .\"], \"bleu\": 0.00015120516485693899, \"rouge_l\": 0.07292289300657502}\n",
      "\n",
      "{\"id\": 5219, \"code\": \"def make increasing candle open high low close dates **kwargs increase x increase y Candlestick open high low close dates **kwargs get candle increase if 'line' in kwargs kwargs setdefault 'fillcolor' kwargs['line']['color'] else kwargs setdefault 'fillcolor' DEFAULT INCREASING COLOR if 'name' in kwargs kwargs setdefault 'showlegend' True else kwargs setdefault 'showlegend' False kwargs setdefault 'name' ' Increasing' kwargs setdefault 'line' dict color DEFAULT INCREASING COLOR candle incr data dict type 'box' x increase x y increase y whiskerwidth 0 boxpoints False **kwargs return [candle incr data]\", \"predictions\": [\"make a candle increasing candle .\"], \"references\": [\"makes boxplot trace for increasing candlesticks _make_increasing_candle() and _make_decreasing_candle separate the increasing traces from the decreasing traces so kwargs can be passed separately to increasing or decreasing traces when direction is set to increasing or decreasing in figurefactory .\"], \"bleu\": 0.0009990583218472395, \"rouge_l\": 0.0785070785070785}\n",
      "\n",
      "{\"id\": 5254, \"code\": \"def contextwin l win assert win % 2 1 assert win > 1 l list l lpadded win // 2 * [ -1 ] + l + win // 2 * [ -1 ] out [lpadded[i i + win ] for i in range len l ]assert len out len l return out\", \"predictions\": [\"return the context for the current window .\"], \"references\": [\"win :: int corresponding to the size of the window given a list of indexes composing a sentence l :: array containing the word indexes it will return a list of list of indexes corresponding to context windows surrounding each word in the sentence .\"], \"bleu\": 0.0021503892707659907, \"rouge_l\": 0.13406593406593406}\n",
      "\n",
      "{\"id\": 5285, \"code\": \"@ File System in directory current directory 'django' 'celeries' def test failfast status output run scenario **{'--failfast' None} the output should contain ' Thisoneispresent' the output should contain ' Celeriesbeforeall' the output should contain ' Celeriesbeforeharvest' the output should contain \\\" Celeriesbeforefeature' Testthedjangoappleaves'\\\" the output should contain \\\" Celeriesbeforescenario' Thisoneispresent'\\\" the output should contain \\\" Celeriesbeforestep' Given Isayfoobar'\\\" the output should contain \\\" Celeriesafterstep' Given Isayfoobar'\\\" the output should contain \\\" Celeriesbeforestep' Thenitfails'\\\" the output should contain \\\" Celeriesafterstep' Thenitfails'\\\" the output should contain \\\" Celeriesafterscenario' Thisoneispresent'\\\" the output should contain \\\" Celeriesafterfeature' Testthedjangoappleaves'\\\" the output should contain ' Celeriesafterharvest' the output should contain ' Celeriesafterall' the output should not contain ' Thisoneisnevercalled'\", \"predictions\": [\"running failfast status .\"], \"references\": [\"passing --failfast to the harvest command will cause lettuce to stop in the first failure .\"], \"bleu\": 0.017888698387160718, \"rouge_l\": 0.09023668639053255}\n",
      "\n",
      "{\"id\": 5401, \"code\": \"def trade events strategy portfolio execution heartbeat while True try event events get False except queue Empty passelse if event is not None if event type 'TICK' logger info ' Receivednewtickevent %s' event strategy calculate signals event portfolio update portfolio event elif event type 'SIGNAL' logger info ' Receivednewsignalevent %s' event portfolio execute signal event elif event type 'ORDER' logger info ' Receivedneworderevent %s' event execution execute order event time sleep heartbeat\", \"predictions\": [\"run events and signal from portfolio .\"], \"references\": [\"carries out an infinite while loop that polls the events queue and directs each event to either the strategy component of the execution handler .\"], \"bleu\": 0.016882254315278775, \"rouge_l\": 0.17023255813953486}\n",
      "\n",
      "{\"id\": 5480, \"code\": \"def urlencoded processor entity cherrypy cpreqbody process urlencoded entity cherrypy serving request unserialized data entity paramscherrypy serving request raw body ''\", \"predictions\": [\"unserialized request .\"], \"references\": [\"accept x-www-form-urlencoded data and reformat it into a low state data structure .\"], \"bleu\": 0.019167100299515256, \"rouge_l\": 0.1123388581952118}\n",
      "\n",
      "{\"id\": 5483, \"code\": \"def transform array array force list False try dt 2001 np datetime 64 '2001 ' legacy datetime 64 dt 2001 astype 'int 64 ' dt 2001 astype 'datetime 64 [ms]' astype 'int 64 ' except Attribute Error as e if e args \\\"'module'objecthasnoattribute'datetime 64 '\\\" import sysif ' Py Py' in sys version legacy datetime 64 Falsepasselse raise eelse raise eif array dtype kind 'M' if legacy datetime 64 if array dtype np dtype 'datetime 64 [ns]' array array astype 'int 64 ' / 10 ** 6 0 else array array astype 'datetime 64 [us]' astype 'int 64 ' / 1000 0 elif array dtype kind 'm' array array astype 'timedelta 64 [us]' astype 'int 64 ' / 1000 0 return serialize array array force list\", \"predictions\": [\"transforms a numpy array to a serialized dask array .\"], \"references\": [\"transform a numpy arrays into serialized format converts un-serializable dtypes and returns json serializable format args: array : a numpy array to be transformed force_list : whether to only output to standard lists this function can encode some dtypes using a binary encoding .\"], \"bleu\": 0.013562223712994391, \"rouge_l\": 0.1995637949836423}\n",
      "\n",
      "{\"id\": 5488, \"code\": \"def prop set prop value extra args None cibfile None return item create item 'property' item id '{ 0 } {1 }' format prop value item type None create 'set' extra args extra args cibfile cibfile\", \"predictions\": [\"create a set of property value .\"], \"references\": [\"set the value of a cluster property prop name of the property value value of the property prop extra_args additional options for the pcs property command cibfile use cibfile instead of the live cib cli example: .\"], \"bleu\": 0.004158556660970397, \"rouge_l\": 0.20238885202388857}\n",
      "\n",
      "{\"id\": 5509, \"code\": \"def set device request device u'' response redirect add cache bypass next url request or u'/' set cookie response u'mezzanine-device' device 60 * 60 * 24 * 365 return response\", \"predictions\": [\"redirect to the device .\"], \"references\": [\"sets a device name in a cookie when a user explicitly wants to go to the site for a particular device .\"], \"bleu\": 0.015078076801581441, \"rouge_l\": 0.26608505997818976}\n",
      "\n",
      "{\"id\": 5645, \"code\": \"def test get debug values exc prev value config compute test valuetry config compute test value 'raise'x T vector try for x val in op get debug values x assert Falseraised Falseexcept Attribute Error raised Trueassert raisedfinally config compute test value prev value\", \"predictions\": [\"test get_debug_value() .\"], \"references\": [\"tests that get_debug_value raises an exception when debugger is set to raise and a value is missing .\"], \"bleu\": 0.003620197623718955, \"rouge_l\": 0.08437067773167356}\n",
      "\n",
      "{\"id\": 5656, \"code\": \"def patch wrapper old new try new name old name new module old module new doc old doc new dict old dict except Exception passreturn new\", \"predictions\": [\"replace :func:monkey .\"], \"references\": [\"helper function that forwards all the function details to the decorated function .\"], \"bleu\": 0.019167100299515256, \"rouge_l\": 0.1123388581952118}\n",
      "\n",
      "{\"id\": 5787, \"code\": \"def test history import symlink with History Archive as history archive history archive write metafiles history archive write link 'datasets/ Pasted Entry 1 txt' ' /target txt' history archive write file 'target txt' 'insecure' run jihaw cleanup history archive ' Symlinkdatasetinimportarchiveallowed'\", \"predictions\": [\"ensure that import_dataset_dataset_dataset_dataset_dataset_dataset_dat\"], \"references\": [\"ensure a history containing a dataset that is a symlink cannot be imported .\"], \"bleu\": 0.015198978579778455, \"rouge_l\": 0.21070811744386875}\n",
      "\n",
      "{\"id\": 5882, \"code\": \"@dog stats api timed 'status service celery ping' def celery ping start time time result delayed ping apply async 'ping' 0 1 task id result idtry value result get timeout 4 0 success Trueexcept Timeout Error value Nonesuccess Falseoutput {'success' success 'task id' task id 'value' value 'time' time time - start }return Http Response json dumps output indent 4 content type 'application/json'\", \"predictions\": [\"asynchronery tasks .\"], \"references\": [\"a simple view that checks if celery can process a simple task .\"], \"bleu\": 0.019167100299515256, \"rouge_l\": 0.1123388581952118}\n",
      "\n",
      "{\"id\": 5945, \"code\": \"def salt cloud force ascii exc if not isinstance exc Unicode Encode Error Unicode Translate Error raise Type Error \\\" Can'thandle{ 0 }\\\" format exc unicode trans {u'\\\\xa 0 ' u'' u'\\\\u 2013 ' u'-'}if exc object[exc start exc end] in unicode trans return unicode trans[exc object[exc start exc end]] exc end raise exc\", \"predictions\": [\"handle the cloud cloud provider .\"], \"references\": [\"helper method to try its best to convert any unicode text into ascii without stack tracing since salt internally does not handle unicode strings this method is not supposed to be used directly .\"], \"bleu\": 0.002298809112166344, \"rouge_l\": 0.08879184861717612}\n",
      "\n",
      "{\"id\": 5987, \"code\": \"def get money supply rdint vs random request Request vs MACRO URL % vs P TYPE['http'] vs DOMAINS['sina'] rdint vs MACRO TYPE[ 2 ] 1 600 rdint text urlopen request timeout 10 read text text decode 'gbk' reg Sym re compile '\\\\\\\\ count *? \\\\\\\\}' datastr reg Sym findall text datastr datastr[ 0 ]datastr datastr split 'data ' [1 ]js json loads datastr df pd Data Frame js columns vs MONEY SUPPLY COLS for i in df columns df[i] df[i] apply lambda x np where x is None '--' x return df\", \"predictions\": [\"return dataframe date :\\u80a1\\ufffd\\u671f\\u80a1\\u6708\\u4ee5\\u671f\\u8ba1\\u6708\\u4ee5\\u6708\"], \"references\": [\"return dataframe month :\\u7edf\\u8ba1\\u65f6\\u95f4 m2 :\\u8d27\\u5e01\\u548c\\u51c6\\u8d27\\u5e01\\uff08\\u5e7f\\u4e49\\u8d27\\u5e01m2\\uff09 m2_yoy:\\u8d27\\u5e01\\u548c\\u51c6\\u8d27\\u5e01\\uff08\\u5e7f\\u4e49\\u8d27\\u5e01m2\\uff09\\u540c\\u6bd4\\u589e\\u957f(%) m1:\\u8d27\\u5e01 m1_yoy:\\u8d27\\u5e01\\u540c\\u6bd4\\u589e\\u957f(%) m0:\\u6d41\\u901a\\u4e2d\\u73b0\\u91d1 m0_yoy:\\u6d41\\u901a\\u4e2d\\u73b0\\u91d1\\u540c\\u6bd4\\u589e\\u957f(%) cd:\\u6d3b\\u671f\\u5b58\\u6b3e cd_yoy:\\u6d3b\\u671f\\u5b58\\u6b3e\\u540c\\u6bd4\\u589e\\u957f(%) qm:\\u51c6\\u8d27\\u5e01 qm_yoy:\\u51c6\\u8d27\\u5e01\\u540c\\u6bd4\\u589e\\u957f(%) ftd:\\u5b9a\\u671f\\u5b58\\u6b3e ftd_yoy:\\u5b9a\\u671f\\u5b58\\u6b3e\\u540c\\u6bd4\\u589e\\u957f(%) sd:\\u50a8\\u84c4\\u5b58\\u6b3e sd_yoy:\\u50a8\\u84c4\\u5b58\\u6b3e\\u540c\\u6bd4\\u589e\\u957f(%) rests:\\u5176\\u4ed6\\u5b58\\u6b3e rests_yoy:\\u5176\\u4ed6\\u5b58\\u6b3e\\u540c\\u6bd4\\u589e\\u957f(%) .\"], \"bleu\": 0.0052531201302439936, \"rouge_l\": 0.1367713004484305}\n",
      "\n",
      "{\"id\": 5990, \"code\": \"def basic auth realm checkpassword debug False if '\\\"' in realm raise Value Error ' Realmcannotcontainthe\\\" quote character ' request cherrypy serving requestauth header request headers get 'authorization' if auth header is not None try scheme params auth header split '' 1 if scheme lower 'basic' username password base 64 decodestring params username password username password split ' ' 1 if checkpassword realm username password if debug cherrypy log ' Authsucceeded' 'TOOLS AUTH BASIC' request login usernamereturnexcept Value Error binascii Error raise cherrypy HTTP Error 400 ' Bad Request' cherrypy serving response headers['www-authenticate'] ' Basicrealm \\\"%s\\\"' % realm raise cherrypy HTTP Error 401 ' Youarenotauthorizedtoaccessthatresource'\", \"predictions\": [\"if auth fails .\"], \"references\": [\"basic_auth is a cherrypy tool which hooks at before_handler to perform http basic access authentication .\"], \"bleu\": 0.017888698387160718, \"rouge_l\": 0.09023668639053255}\n",
      "\n",
      "{\"id\": 6021, \"code\": \"def power name 'power on' wait 300 **kwargs ret {'name' name 'result' False 'comment' '' 'changes' {}}org salt ['ipmi get power'] **kwargs state map {'off' 'off' 'on' 'on' 'power off' 'off' 'power on' 'on' 'shutdown' 'off' 'reset' 'na' 'boot' 'na'}if org state map[name] ret['result'] Trueret['comment'] 'systemalreadyinthisstate'return retif opts ['test'] ret['comment'] 'wouldpower {0 }system' format name ret['result'] Noneret['changes'] {'old' org 'new' name}return retoutdddd salt ['ipmi set power'] name wait wait **kwargs ret['comment'] 'changedsystempower'ret['result'] Trueret['changes'] {'old' org 'new' name}return ret\", \"predictions\": [\"enable power power on off .\"], \"references\": [\"request power state change name ensure power state one of: * power_on -- system turn on * power_off -- system turn off * shutdown -- request os proper shutdown * reset -- reset * boot -- if system is off .\"], \"bleu\": 0.0010123740681592997, \"rouge_l\": 0.1875768757687577}\n",
      "\n",
      "{\"id\": 6049, \"code\": \"def convert to RGB 255 colors rgb components []for component in colors rounded num decimal Decimal str component * 255 0 quantize decimal Decimal '1 ' rounding decimal ROUND HALF EVEN rounded num int rounded num rgb components append rounded num return rgb components[ 0 ] rgb components[ 1 ] rgb components[ 2 ]\", \"predictions\": [\"convert colors to 255 .\"], \"references\": [\"multiplies each element of a triplet by 255 each coordinate of the color tuple is rounded to the nearest float and then is turned into an integer .\"], \"bleu\": 0.003263508557908275, \"rouge_l\": 0.10767872903795235}\n",
      "\n",
      "{\"id\": 6059, \"code\": \"def expand reqs fpath absfpath os path abspath fpath output expand reqs helper absfpath set return sorted set output\", \"predictions\": [\"expand reqs .\"], \"references\": [\"returns a sorted list of unique dependencies specified by the requirements file fpath .\"], \"bleu\": 0.013733827497510927, \"rouge_l\": 0.10535405872193437}\n",
      "\n",
      "{\"id\": 6076, \"code\": \"def test set format shares subfmt t Time '+ 02000 - 02 - 03 ' format 'fits' out subfmt 'date hms' precision 5 tc t copy t format 'isot'assert t precision 5 assert t out subfmt 'date hms' assert t value '2000 - 02 - 03 T 00 00 00 00000 ' t format 'fits'assert t value tc value assert t precision 5\", \"predictions\": [\"subfmt .\"], \"references\": [\"set format and round trip through a format that shares out_subfmt .\"], \"bleu\": 0.005119732577934196, \"rouge_l\": 0.12655601659751037}\n",
      "\n",
      "{\"id\": 6082, \"code\": \"def temp directory prefix create trashcan dir return create trashcan subdir prefix\", \"predictions\": [\"creates a trashcan .\"], \"references\": [\"create a temporary directory with the given *prefix* that will survive at least as long as this process invocation .\"], \"bleu\": 0.0072829457434388815, \"rouge_l\": 0.14878048780487804}\n",
      "\n",
      "{\"id\": 6140, \"code\": \"def check multinomial samples value expected shape expected mean tol assert value shape expected shape assert is binary value assert np all value sum axis 1 1 mean value mean axis 0 max error np abs mean - expected mean max if max error > tol print ' Actualmean ' print mean print ' Expectedmean ' print expected mean print ' Maximalerror ' max error raise Value Error \\\" Samplesdon'tseemtohavetherightmean \\\"\", \"predictions\": [\"check that multinomial is valid .\"], \"references\": [\"tests that a matrix of multinomial samples 1) has the right shape 2) is binary 3) has one 1 per row 4) converges to the right mean .\"], \"bleu\": 0.007100020117291939, \"rouge_l\": 0.21070811744386875}\n",
      "\n",
      "{\"id\": 6144, \"code\": \"def sanitize hostname hostname default name None def truncate hostname name if len name > 63 LOG warning LW ' Hostname% hostname sislongerthan 63 truncateitto% truncated name s' {'hostname' name 'truncated name' name[ 63 ]} return name[ 63 ]if isinstance hostname six text type hostname hostname encode 'latin- 1 ' 'ignore' if six PY 3 hostname hostname decode 'latin- 1 ' hostname truncate hostname hostname hostname re sub '[ ]' '-' hostname hostname re sub '[^\\\\\\\\w -]+' '' hostname hostname hostname lower hostname hostname strip ' -' if hostname '' and default name is not None return truncate hostname default name return hostname\", \"predictions\": [\"sanitize hostname .\"], \"references\": [\"return a hostname which conforms to rfc-952 and rfc-1123 specs except the length of hostname .\"], \"bleu\": 0.009279877584343722, \"rouge_l\": 0.18740399385560674}\n",
      "\n",
      "{\"id\": 6183, \"code\": \"def new repo path qtutils opendir dialog N u' New Repository ' core getcwd if not path return Noneif git is git worktree path or git is git dir path return path status out err core run command [u'git' u'init' path] if status 0 return pathelse title N u' Error Creating Repository' msg N u'\\\"% command s\\\"returnedexitstatus% status d' % dict command u'gitinit%s' % path status status details N u' Output \\\\n%s' % out if err details + u'\\\\n\\\\n'details + N u' Errors %s' % err qtutils critical title msg details return None\", \"predictions\": [\"create a new repo .\"], \"references\": [\"prompt for a new directory and create a new git repository :returns str: repository path or none if no repository was created .\"], \"bleu\": 0.014680625283676267, \"rouge_l\": 0.25603357817418676}\n",
      "\n",
      "{\"id\": 6221, \"code\": \"def objective mle precision alpha p precision shape[ 0 ]cost -2 0 * log likelihood mle precision + p * np log 2 * np pi cost + alpha * np abs precision sum - np abs np diag precision sum return cost\", \"predictions\": [\"compute cost function for l{llelement} .\"], \"references\": [\"evaluation of the graph-lasso objective function the objective function is made of a shifted scaled version of the normalized log-likelihood and a penalisation term to promote sparsity .\"], \"bleu\": 0.006248811036697839, \"rouge_l\": 0.10535405872193437}\n",
      "\n",
      "{\"id\": 6241, \"code\": \"def mlinspace a b nums order 'C' a numpy array a dtype 'float 64 ' b numpy array b dtype 'float 64 ' nums numpy array nums dtype 'int 64 ' nodes [numpy linspace a[i] b[i] nums[i] for i in range len nums ]return cartesian nodes order order\", \"predictions\": [\"performs mnlinspace between a and b .\"], \"references\": [\"constructs a regular cartesian grid parameters: a: lower bounds in each dimension b: upper bounds in each dimension nums: number of nodes along each dimension order: order in which the product is enumerated returns: out: each line corresponds to one point of the product space .\"], \"bleu\": 0.0007821900882449724, \"rouge_l\": 0.06663025669033315}\n",
      "\n",
      "{\"id\": 6282, \"code\": \"def group sums dummy x group dummy if data util is using ndarray type group dummy None return np dot x T group dummy else return x T * group dummy\", \"predictions\": [\"squared sums .\"], \"references\": [\"sum by groups given group dummy variable group_dummy can be either ndarray or sparse matrix .\"], \"bleu\": 0.007051182147062658, \"rouge_l\": 0.09370199692780337}\n",
      "\n",
      "{\"id\": 6302, \"code\": \"def disconnect receiver signal Any sender Any weak True if signal is None raise errors Dispatcher Type Error ' Signalcannotbe None receiver %rsender %r ' % receiver sender if weak receiver saferef safe Ref receiver senderkey id sender try signals connections[senderkey]receivers signals[signal]except Key Error raise errors Dispatcher Key Error ' Noreceiversfoundforsignal%rfromsender%r' % signal sender try remove Old Back Refs senderkey signal receiver receivers except Value Error raise errors Dispatcher Key Error ' Noconnectiontoreceiver%sforsignal%sfromsender%s' % receiver signal sender cleanup Connections senderkey signal\", \"predictions\": [\"disconnect a signal from a signal and disconnecting to the given sender .\"], \"references\": [\"disconnect receiver from sender for signal receiver -- the registered receiver to disconnect signal -- the registered signal to disconnect sender -- the registered sender to disconnect weak -- the weakref state to disconnect disconnect reverses the process of connect .\"], \"bleu\": 0.016143429375268553, \"rouge_l\": 0.2370905052748473}\n",
      "\n",
      "{\"id\": 6372, \"code\": \"def config name config ret {'name' name 'changes' {} 'result' False 'comment' ''}existing config Noneif salt ['marathon has app'] name existing config salt ['marathon app'] name ['app']if existing config update config copy deepcopy existing config salt utils configcomparer compare and update config config update config ret['changes'] else ret['changes']['app'] {'new' config 'old' None}update config configif ret['changes'] if opts ['test'] ret['result'] Noneret['comment'] ' Marathonapp{ 0 }issettobeupdated' format name return retupdate result salt ['marathon update app'] name update config if 'exception' in update result ret['result'] Falseret['comment'] ' Failedtoupdateappconfigfor{ 0 } {1 }' format name update result['exception'] return retelse ret['result'] Trueret['comment'] ' Updatedappconfigfor{ 0 }' format name return retret['result'] Trueret['comment'] ' Marathonapp{ 0 }configuredcorrectly' format name return ret\", \"predictions\": [\"update the marathon config .\"], \"references\": [\"ensure that the marathon app with the given id is present and is configured to match the given config values .\"], \"bleu\": 0.016641100089707282, \"rouge_l\": 0.27695800227014755}\n",
      "\n",
      "{\"id\": 6395, \"code\": \"def wsgify func argspec inspect getargspec func if argspec args and argspec args[ 0 ] 'self' @functools wraps func def wsgify self self env start response try return func self Request env env start response except HTTP Exception as err resp return err resp env start response return wsgify selfelse @functools wraps func def wsgify bare env start response try return func Request env env start response except HTTP Exception as err resp return err resp env start response return wsgify bare\", \"predictions\": [\"wraps the wsgiser method .\"], \"references\": [\"a decorator for translating functions which take a swob request object and return a response object into wsgi callables .\"], \"bleu\": 0.0135924714044228, \"rouge_l\": 0.07218934911242604}\n",
      "\n",
      "{\"id\": 6528, \"code\": \"def normalize points for row in points row / points[ -1 ]return points\", \"predictions\": [\"normalize points .\"], \"references\": [\"normalize a collection of points in homogeneous coordinates so that last row = 1 .\"], \"bleu\": 0.011702651167821564, \"rouge_l\": 0.2975609756097561}\n",
      "\n",
      "{\"id\": 6566, \"code\": \"def numbered symbols prefix 'x' cls None start 0 exclude [] *args **assumptions exclude set exclude or [] if cls is None from sympy import Symbolcls Symbolwhile True name '%s%s' % prefix start s cls name *args **assumptions if s not in exclude yield s start + 1\", \"predictions\": [\"yield symbols .\"], \"references\": [\"generate an infinite stream of symbols consisting of a prefix and increasing subscripts provided that they do not occur in exclude .\"], \"bleu\": 0.0010560774867844412, \"rouge_l\": 0.14071510957324107}\n",
      "\n",
      "{\"id\": 6595, \"code\": \"def check access action context data dict None try audit context get ' auth audit' [] [ -1 ]except Index Error audit ''if audit and audit[ 0 ] action context[' auth audit'] pop user context get 'user' try if 'auth user obj' not in context context['auth user obj'] Noneif not context get 'ignore auth' if not context get ' auth user obj checked' if context get 'user' and not context get 'auth user obj' context['auth user obj'] model User by name context['user'] context[' auth user obj checked'] Truecontext prepopulate context context logic authorization authz is authorized action context data dict if not logic authorization['success'] msg logic authorization get 'msg' '' raise Not Authorized msg except Not Authorized as e log debug u'checkaccess Not Authorized-%suser %s\\\"%s\\\"' action user unicode e raiselog debug 'checkaccess OK-%suser %s' action user return True\", \"predictions\": [\"wrapper function that handles the access action .\"], \"references\": [\"calls the authorization function for the provided action this is the only function that should be called to determine whether a user is allowed to perform a particular action .\"], \"bleu\": 0.017756724409141493, \"rouge_l\": 0.190625}\n",
      "\n",
      "{\"id\": 6610, \"code\": \"def unpatch policies f @functools wraps f def wrapper *args **kwargs with patch policies test POLICIES return f *args **kwargs return wrapper\", \"predictions\": [\"decorator to unpatch policies .\"], \"references\": [\"this will unset a testcase level patch_policies to use the module level policies setup for the _test_servers instead .\"], \"bleu\": 0.019743076272439736, \"rouge_l\": 0.22620519159456118}\n",
      "\n",
      "{\"id\": 6614, \"code\": \"@step ' Icreatelogrecordswith' def step I create logrecords with table context assert context table 'REQUIRE context table'context table require columns ['category' 'level' 'message'] for row in context table rows category row['category']if category ' ROOT ' category Nonelevel Log Level parse type row['level'] message row['message']make log record category level message\", \"predictions\": [\"example logrecords .\"], \"references\": [\"step definition that creates one more log records by using a table .\"], \"bleu\": 0.019167100299515256, \"rouge_l\": 0.1123388581952118}\n",
      "\n",
      "{\"id\": 6671, \"code\": \"def extract subrois timeseries file label file indices img nb load timeseries file data img get data roiimg nb load label file rois roiimg get data prefix split filename timeseries file [1 ]out ts file os path join os getcwd u'%s subcortical ts txt' % prefix with open out ts file u'wt' as fp for fsindex in indices ijk np nonzero rois fsindex ts data[ijk]for i0 row in enumerate ts fp write u'%d %d %d %d ' % fsindex ijk[ 0 ][i 0 ] ijk[ 1 ][i 0 ] ijk[ 2 ][i 0 ] + u' ' join [ u'% 10 f' % val for val in row] + u'\\\\n' return out ts file\", \"predictions\": [\"extract subcortical data from a file .\"], \"references\": [\"extract voxel time courses for each subcortical roi index parameters timeseries_file: a 4d nifti file label_file: a 3d file containing rois in the same space/size of the 4d file indices: a list of indices for rois to extract .\"], \"bleu\": 0.0025285077504291252, \"rouge_l\": 0.19316022799240026}\n",
      "\n",
      "{\"id\": 6883, \"code\": \"def keyboard role name rawtext text lineno inliner options {} content [] new element nodes literal rawtext text new element set class 'kbd' return [new element] []\", \"predictions\": [\"a keyboard role .\"], \"references\": [\"this function creates an inline console input block as defined in the twitter bootstrap documentation overrides the default behaviour of the kbd role *usage:* :kbd:<your code> *example:* :kbd:<section> this code is not highlighted .\"], \"bleu\": 0.00021992590505856641, \"rouge_l\": 0.09214501510574018}\n",
      "\n",
      "{\"id\": 6921, \"code\": \"def encode short string pieces value encoded value as bytes value length len encoded value if length > 255 raise exceptions Short String Too Long encoded value pieces append struct pack 'B' length pieces append encoded value return 1 + length\", \"predictions\": [\"encode a short .\"], \"references\": [\"encode a string value as short string and append it to pieces list returning the size of the encoded value .\"], \"bleu\": 0.007663958429554193, \"rouge_l\": 0.2850467289719626}\n",
      "\n",
      "{\"id\": 7011, \"code\": \"def chuang f1 individual total 0if individual[ -1 ] 0 for i in xrange 0 len individual - 1 4 total + inv trap individual[i i + 4 ] else for i in xrange 0 len individual - 1 4 total + trap individual[i i + 4 ] return total\", \"predictions\": [\"wang/multivariate chuang-1 function .\"], \"references\": [\"binary deceptive function from : multivariate multi-model approach for globally multimodal problems by chung-yao chuang and wen-lian hsu .\"], \"bleu\": 0.009351487442933324, \"rouge_l\": 0.15561224489795916}\n",
      "\n",
      "{\"id\": 7044, \"code\": \"def require jinja 2 test func test func skip If jinja 2 is None 'thistestrequiresjinja 2 ' test func test func override settings TEMPLATES [{'BACKEND' 'django template backends django Django Templates' 'APP DIRS' True} {'BACKEND' 'django template backends jinja 2 Jinja 2 ' 'APP DIRS' True 'OPTIONS' {'keep trailing newline' True}}] test func return test func\", \"predictions\": [\"decorator for jinja2 extension .\"], \"references\": [\"decorator to enable a jinja2 template engine in addition to the regular django template engine for a test or skip it if jinja2 isnt available .\"], \"bleu\": 0.0051478994064591945, \"rouge_l\": 0.22997172478793593}\n",
      "\n",
      "{\"id\": 7201, \"code\": \"def get resource from path path resource Falsefor adpath in ad paths adpath os path join adpath '' if os path commonprefix [adpath path] adpath resource path replace adpath '' 1 breakif resource relative resource split os path sep if not relative[ 0 ] relative pop 0 module relative pop 0 return module '/' join relative os path sep join relative return None\", \"predictions\": [\"given a path .\"], \"references\": [\"tries to extract the module name and the resources relative path out of an absolute resource path .\"], \"bleu\": 0.014279460992754662, \"rouge_l\": 0.16310160427807485}\n",
      "\n",
      "{\"id\": 7234, \"code\": \"def save registration code user course id mode slug invoice None order None invoice item None code random code generator matching coupons Coupon objects filter code code is active True if matching coupons return save registration code user course id mode slug invoice invoice order order invoice item invoice item course registration Course Registration Code code code course id unicode course id created by user invoice invoice order order mode slug mode slug invoice item invoice item try with transaction atomic course registration save return course registrationexcept Integrity Error return save registration code user course id mode slug invoice invoice order order invoice item invoice item\", \"predictions\": [\"save a course for the specified user .\"], \"references\": [\"recursive function that generate a new code every time and saves in the course registration table if validation check passes args: user : the user creating the course registration codes .\"], \"bleu\": 0.011906818413624672, \"rouge_l\": 0.23176291793313067}\n",
      "\n",
      "{\"id\": 7277, \"code\": \"def correlate eye world eye timestamps world timestamps e ts eye timestampsw ts list world timestamps eye frames by timestamp dict zip e ts range len e ts eye timestamps by world index [[] for i in world timestamps]frame idx 0try current e ts e ts pop 0 except logger warning ' Noeyetimestampsfound ' return eye timestamps by world indexwhile e ts try t between frames w ts[frame idx] + w ts[ frame idx + 1 ] / 2 0 except Index Error breakif current e ts < t between frames eye timestamps by world index[frame idx] append current e ts current e ts e ts pop 0 else frame idx + 1idx 0eye world frame map []for candidate world ts in zip eye timestamps by world index w ts if not candidate e past ts get past timestamp idx eye timestamps by world index e future ts get future timestamp idx eye timestamps by world index eye world frame map append eye frames by timestamp[get nearest timestamp e past ts e future ts world ts ] else eye world frame map append eye frames by timestamp[eye timestamps by world index[idx][ -1 ]] idx + 1return eye world frame map\", \"predictions\": [\"correlestamps for eye timestamps .\"], \"references\": [\"this function takes a list of eye timestamps and world timestamps and correlates one eye frame per world frame returns a mapping that correlates a single eye frame index with each world frame index .\"], \"bleu\": 0.0009570397584996433, \"rouge_l\": 0.13212996389891696}\n",
      "\n",
      "{\"id\": 7288, \"code\": \"def generate dependency paths name packages dir os path join st dir u' Packages' dependency dir os path join packages dir name ver u'st%s' % st version plat sublime platform arch sublime arch return {'all' os path join dependency dir 'all' 'ver' os path join dependency dir ver 'plat' os path join dependency dir u'%s %s' % ver plat 'arch' os path join dependency dir u'%s %s %s' % ver plat arch }\", \"predictions\": [\"generate path for dependency packages .\"], \"references\": [\"accepts a dependency name and generates a dict containing the three standard import paths that are valid for the current machine .\"], \"bleu\": 0.018252676551591566, \"rouge_l\": 0.1295116772823779}\n",
      "\n",
      "{\"id\": 7299, \"code\": \"@step ' Iwillanswerallpromptswith\\\" [^\\\"]* \\\"' def i answer prompts with step prompt world browser execute script 'window prompt function {return%s }' % prompt\", \"predictions\": [\"answer with i .\"], \"references\": [\"please note: this method must be called right before an expected alert window variables are page local and thus all changes are removed upon navigating to a new page in addition .\"], \"bleu\": 0.00032764293984871725, \"rouge_l\": 0.048722044728434506}\n",
      "\n",
      "{\"id\": 7328, \"code\": \"def handle del request basket line id **kwargs return {u'ok' basket delete line int line id }\", \"predictions\": [\"handle delete .\"], \"references\": [\"handle deleting a distinct order line from the basket given its unique line id .\"], \"bleu\": 0.010890544041151608, \"rouge_l\": 0.1983739837398374}\n",
      "\n",
      "{\"id\": 7381, \"code\": \"@register specialize@register stabilize@register canonicalize@register useless@gof local optimizer [T alloc] def local useless alloc node op node opif not isinstance op Alloc return Falseinput node inputs[ 0 ]output node outputs[ 0 ]if input type output type return [input]\", \"predictions\": [\"if alloc is empty .\"], \"references\": [\"if the input type is the same as the output type there is no change in the shape of the input .\"], \"bleu\": 0.010835229990606801, \"rouge_l\": 0.1995637949836423}\n",
      "\n",
      "{\"id\": 7474, \"code\": \"def mask missing arr values to mask if not isinstance values to mask list np ndarray values to mask [values to mask]try values to mask np array values to mask dtype arr dtype except Exception values to mask np array values to mask dtype object na mask isnull values to mask nonna values to mask[ ~ na mask ]mask Nonefor x in nonna if mask is None if is numeric v string like arr x mask Falseelse mask arr x if is scalar mask mask np zeros arr shape dtype bool elif is numeric v string like arr x mask Falseelse mask arr x if na mask any if mask is None mask isnull arr else mask isnull arr return mask\", \"predictions\": [\"mask missing values .\"], \"references\": [\"return a masking array of same size/shape as arr with entries equaling any member of values_to_mask set to true .\"], \"bleu\": 0.006580884365953166, \"rouge_l\": 0.07439024390243902}\n",
      "\n",
      "{\"id\": 7528, \"code\": \"def cg simp e if isinstance e Add return cg simp add e elif isinstance e Sum return cg simp sum e elif isinstance e Mul return Mul *[cg simp arg for arg in e args] elif isinstance e Pow return Pow cg simp e base e exp else return e\", \"predictions\": [\"convert a cg .\"], \"references\": [\"simplify and combine cg coefficients this function uses various symmetry and properties of sums and products of clebsch-gordan coefficients to simplify statements involving these terms [1]_ .\"], \"bleu\": 0.0012655862017730084, \"rouge_l\": 0.11380597014925373}\n",
      "\n",
      "{\"id\": 7535, \"code\": \"@dispatch Join Sequence Sequence def compute up t lhs rhs **kwargs if lhs rhs lhs rhs itertools tee lhs 2 on left [t lhs fields index col for col in listpack t on left ]on right [t rhs fields index col for col in listpack t on right ]left default None if t how in 'right' 'outer' else toolz itertoolz no default right default None if t how in 'left' 'outer' else toolz itertoolz no default pairs toolz join on left lhs on right rhs left default left default right default right default assemble pair assemble t on left on right return map assemble pairs\", \"predictions\": [\"compute an up-based pairs up to ths .\"], \"references\": [\"join operation for python streaming backend note that a pure streaming join is challenging/impossible because any row in one seq might connect to any row in the other .\"], \"bleu\": 0.01285617726475233, \"rouge_l\": 0.09807073954983922}\n",
      "\n",
      "{\"id\": 7540, \"code\": \"def api github v1 user profile event payload branches stream **kwargs commit stream streamissue stream 'issues'return api github v2 user profile event payload branches stream commit stream issue stream **kwargs\", \"predictions\": [\"api: accepts v2 .\"], \"references\": [\"processes github payload with version 1 field specification payload comes in unmodified from github stream is set to commits if otherwise unset .\"], \"bleu\": 0.0031085896619325354, \"rouge_l\": 0.06573275862068965}\n",
      "\n",
      "{\"id\": 7583, \"code\": \"@xframe options sameorigin@login required@process document pathdef edit attachment request document slug document locale document get object or 404 Document locale document locale slug document slug if request method 'POST' return redirect document get edit url if not allow add attachment by request user raise Permission Deniedform Attachment Revision Form data request POST files request FILES if form is valid revision form save commit False revision creator request userattachment Attachment objects create title revision title revision attachment attachmentrevision save attachment attach document request user revision return redirect document get edit url else context {'form' form 'document' document}return render request 'attachments/edit attachment html' context\", \"predictions\": [\"edit attachment .\"], \"references\": [\"create a new attachment object and populate its initial revision or show a separate form view that allows to fix form submission errors .\"], \"bleu\": 0.0005422082607400484, \"rouge_l\": 0.12992545260915866}\n",
      "\n",
      "{\"id\": 7598, \"code\": \"def check orphans no tips cursor orphans with tips cursor all '\\\\n WIT Hvalid tips AS SELECT*FRO Mcurrent tips WHER Eamount> 0 \\\\n SELEC Tusername\\\\n FROM SELEC Ttipper A Susername FRO Mvalid tips\\\\n UNION\\\\n SELEC Ttippee A Susername FRO Mvalid tips foo\\\\n WHERENOTEXISTS SELECT 1 FRO Melsewhere WHER Eparticipant username \\\\n' assert len orphans with tips 0 orphans with tips\", \"predictions\": [\"check that the orphans are not present .\"], \"references\": [\"finds participants * without elsewhere account attached * having non zero outstanding tip this should not happen because when we remove the last elsewhere account in take_over we also zero out all tips .\"], \"bleu\": 0.007394562515678539, \"rouge_l\": 0.08567415730337079}\n",
      "\n",
      "{\"id\": 7620, \"code\": \"def define servers global CF Gtry for server in CFG['servers'] svr CFG['servers'][server]s Config Server server replace '{' '[' replace '}' ']' svr if s fillserver s priority set 1 s fillserver set False except Key Error pass\", \"predictions\": [\"define servers .\"], \"references\": [\"define servers listed in the setup file return a list of configserver instances .\"], \"bleu\": 0.019422565110272495, \"rouge_l\": 0.3160621761658031}\n",
      "\n",
      "{\"id\": 7660, \"code\": \"def extract s res decoder match s if res is None raise Not A Number s sign intpart fraction exppart res group 1 2 3 4 if sign '+' sign ''if fraction fraction fraction[ 1 ]if exppart expo int exppart[ 1 ] else expo 0return sign intpart fraction expo\", \"predictions\": [\"extract a number from a string of the form .\"], \"references\": [\"return or raise an exception: sign is + or - intpart is 0 or more digits beginning with a nonzero fraction is 0 or more digits expo is an integer .\"], \"bleu\": 0.017083647679751315, \"rouge_l\": 0.08931185944363104}\n",
      "\n",
      "{\"id\": 7669, \"code\": \"def reloader observer server app interval fd lockfile tempfile mkstemp prefix 'bottle-reloader ' suffix ' lock' os close fd try while os path exists lockfile args [sys executable] + sys argv environ os environ copy environ['BOTTLE CHILD'] 'true'environ['BOTTLE LOCKFILE'] lockfilep subprocess Popen args env environ while p poll is None os utime lockfile None time sleep interval if p poll 3 if os path exists lockfile os unlink lockfile sys exit p poll elif not server quiet print ' Reloadingserver 'except Keyboard Interrupt passif os path exists lockfile os unlink lockfile\", \"predictions\": [\"a reloader .\"], \"references\": [\"start a child process with identical commandline arguments and restart it as long as it exists with status code 3 .\"], \"bleu\": 0.0014738748624100577, \"rouge_l\": 0.14681107099879662}\n",
      "\n",
      "{\"id\": 7683, \"code\": \"def askopenfiles mode 'r' **options files askopenfilenames **options if files ofiles []for filename in files ofiles append open filename mode files ofilesreturn files\", \"predictions\": [\"ask for the given files .\"], \"references\": [\"ask for multiple filenames and return the open file objects returns a list of open file objects or an empty list if cancel selected .\"], \"bleu\": 0.013920804010379954, \"rouge_l\": 0.23238095238095238}\n",
      "\n",
      "{\"id\": 7735, \"code\": \"def project activity year options db current dbtable current s3 db project activityquery table deleted False min field table date min start date min db query select min field orderby min field limitby 0 1 first [min field]if start date min start year start date min yearelse start year Nonemax field table end date max end date max db query select max field orderby max field limitby 0 1 first [max field]if end date max end year end date max yearelse end year Noneif not start year or not end year return {start year start year} or {end year end year} years {}for year in xrange start year end year + 1 years[year] yearreturn years\", \"predictions\": [\"given a list of activity years .\"], \"references\": [\"returns a dict of the options for the year virtual field used by the search widget orderby needed for postgres @todo: migrate to stats_year_options() .\"], \"bleu\": 0.016882254315278775, \"rouge_l\": 0.17023255813953486}\n",
      "\n",
      "{\"id\": 7743, \"code\": \"def prep opts ryn 'manor' if not lane stack setup opts opts ryn ryn\", \"predictions\": [\"prepare the stack if necessary .\"], \"references\": [\"required items in opts are keys id __role sock_dir ryn is the remote yard name to communicate with each use much call raetlane .\"], \"bleu\": 0.012171021972294544, \"rouge_l\": 0.12031558185404337}\n",
      "\n",
      "{\"id\": 7776, \"code\": \"def expand file arguments new args []expanded Falsefor arg in sys argv if arg startswith '@' expanded Truewith open arg[ 1 ] 'r' as f for line in f readlines new args + shlex split line else new args append arg if expanded print 'esptool py%s' % '' join new args[ 1 ] sys argv new args\", \"predictions\": [\"expand $expool .\"], \"references\": [\"any argument starting with \\\"@\\\" gets replaced with all values read from a text file .\"], \"bleu\": 0.007051182147062658, \"rouge_l\": 0.09370199692780337}\n",
      "\n",
      "{\"id\": 7823, \"code\": \"@hsa jit device True def shuf device inclusive scan data temp tid hsa get local id 0 lane tid & WARPSIZE - 1 warpid tid >> 6 warp scan res shuf wave inclusive scan data hsa barrier if lane WARPSIZE - 1 temp[warpid] warp scan reshsa barrier if warpid 0 shuf wave inclusive scan temp[lane] hsa barrier blocksum 0if warpid > 0 blocksum temp[ warpid - 1 ]return warp scan res + blocksum\", \"predictions\": [\"harp shuf .\"], \"references\": [\"args data: scalar input for tid temp: shared memory for temporary work .\"], \"bleu\": 0.019167100299515256, \"rouge_l\": 0.1123388581952118}\n",
      "\n",
      "{\"id\": 7899, \"code\": \"def populate xheaders request response model object id from django conf import settingsif request META get 'REMOTE ADDR' in settings INTERNAL IPS or hasattr request 'user' and request user is authenticated and request user is staff response['X- Object- Type'] '%s %s' % model meta app label model meta object name lower response['X- Object- Id'] str object id\", \"predictions\": [\"adds the given x-object-type header to the given model-object-name .\"], \"references\": [\"adds the \\\"x-object-type\\\" and \\\"x-object-id\\\" headers to the given httpresponse according to the given model and object_id -- but only if the given httprequest object has an ip address within the internal_ips setting or if the request is from a logged in staff member .\"], \"bleu\": 0.00957327456221322, \"rouge_l\": 0.2283422459893048}\n",
      "\n",
      "{\"id\": 7948, \"code\": \"def add debugging monkeypatches from twisted application service import Serviceold start Service Service start Serviceold stop Service Service stop Servicedef start Service self assert not self running return old start Service self def stop Service self assert self runningreturn old stop Service self Service start Service start Service Service stop Service stop Serviceif twisted version major < 9 and sys version info[ 2] 2 7 def nopatch self *args raise unittest Skip Test 'unittest Test Case patchisnotavailable' unittest Test Case patch nopatch\", \"predictions\": [\"monkey-patch debugging .\"], \"references\": [\"do not call this directly this adds a few \\\"harmless\\\" monkeypatches which make it easier to debug failing tests .\"], \"bleu\": 0.001858671434298421, \"rouge_l\": 0.07672955974842767}\n",
      "\n",
      "{\"id\": 7968, \"code\": \"@pytest mark skipif 'not HAS BEAUTIFUL SOUP' def test htmlsplitter splitter html HTML Splitter lines [html Soup String Beautiful Soup '<table><tr><th> Col 1 </th><th> Col 2 </th></tr></table>' tr html Soup String Beautiful Soup '<table><tr><td> Data 1 </td><td> Data 2 </td></tr></table>' tr ]expected data [[' Col 1 ' ' Col 2 '] [' Data 1 ' ' Data 2 ']]assert list splitter lines expected data lines append '<tr><td> Data 3 </td><td> Data 4 </td></tr>' with pytest raises Type Error list splitter lines with pytest raises core Inconsistent Table Error list splitter []\", \"predictions\": [\"test that htmlsplitter is correctly .\"], \"references\": [\"test to make sure that htmlsplitter correctly inputs lines of type soupstring to return a generator that gives all header and data elements .\"], \"bleu\": 0.017212424341159886, \"rouge_l\": 0.3007889546351085}\n",
      "\n",
      "{\"id\": 7987, \"code\": \"def tag Test tag comment None return getattr pytest mark tag\", \"predictions\": [\"return a tag that can be used by test .\"], \"references\": [\"a decorator for tagging a test class or test method with the given tag string tag: test tag string comment: reason for the tag; string; optional examples: @tagtest class clustertests: def testswarmwithaggregation: pass def testswarmwithoutaggregation: pass or class misctests: def testoneplusone: pass @tagtest def testswarm: pass .\"], \"bleu\": 0.0039189671458715585, \"rouge_l\": 0.12564366632337795}\n",
      "\n",
      "{\"id\": 7995, \"code\": \"def periodogram X X np asarray X pergr 1 0 / len X * np abs np fft fft X ** 2 pergr[ 0 ] 0 0return pergr\", \"predictions\": [\"return the periodogram .\"], \"references\": [\"returns the periodogram for the natural frequency of x parameters x : array-like array for which the periodogram is desired .\"], \"bleu\": 0.007248124376500034, \"rouge_l\": 0.21378504672897194}\n",
      "\n",
      "{\"id\": 8163, \"code\": \"def initialise bot Bridge Instance bot 'samplebridge' Incoming Messages\", \"predictions\": [\"initialize the botmbridge .\"], \"references\": [\"config key \\\"sample bridges must be defined for the bridge to initialise example format in config .\"], \"bleu\": 0.015417996259849322, \"rouge_l\": 0.17134831460674158}\n",
      "\n",
      "{\"id\": 8175, \"code\": \"def update path value timestamp None value float value with open path 'r+b' BUFFERING as fh if CAN FADVISE and FADVISE RANDOM posix fadvise fh fileno 0 0 POSIX FADV RANDOM return file update fh value timestamp\", \"predictions\": [\"update a path .\"], \"references\": [\"update path is a string value is a float timestamp is either an int or float .\"], \"bleu\": 0.01751822594256427, \"rouge_l\": 0.2570224719101124}\n",
      "\n",
      "{\"id\": 8214, \"code\": \"def make events add nulls def gen date interleavings for e1 e2 t1 t2 in product * [critical dates] * 4 if e1 < e2 yield e1 e2 t1 t2 event frames []for sid e1 e2 t1 t2 in enumerate gen date interleavings event frames append make events for sid sid [e 1 e2 ] [t 1 t2 ] if add nulls for date in critical dates event frames append make null event date events np arange sid + 1 timestamp date return pd concat event frames ignore index True\", \"predictions\": [\"make events .\"], \"references\": [\"every event has at least three pieces of data associated with it: 1 .\"], \"bleu\": 0.013733827497510927, \"rouge_l\": 0.10535405872193437}\n",
      "\n",
      "{\"id\": 8230, \"code\": \"def aws output args aws config environment os environ copy environment update aws config return check output ['aws'] + args env environment\", \"predictions\": [\"runs aws output .\"], \"references\": [\"run the aws command line tool with the supplied subcommand args and the supplied aws_config as environment variables .\"], \"bleu\": 0.009351487442933324, \"rouge_l\": 0.15561224489795916}\n",
      "\n",
      "{\"id\": 8256, \"code\": \"def get ctx file path from manifest filename repo changeset revision stripped filename basic util strip path filename for changeset in reversed upper bounded changelog repo changeset revision manifest ctx repo changectx changeset for ctx file in manifest ctx files ctx file name basic util strip path ctx file if ctx file name stripped filename return manifest ctx ctx file return None None\", \"predictions\": [\"given the manifest file .\"], \"references\": [\"get the ctx file path for the latest revision of filename from the repository manifest up to the value of changeset_revision .\"], \"bleu\": 0.011456860824837005, \"rouge_l\": 0.1995637949836423}\n",
      "\n",
      "{\"id\": 8309, \"code\": \"def present name password permission ret {'name' name 'result' True 'changes' {} 'comment' ''}users salt ['drac list users'] if opts ['test'] if name in users ret['comment'] '`{ 0 }`alreadyexists' format name else ret['comment'] '`{ 0 }`willbecreated' format name ret['changes'] {name 'willbecreated'}return retif name in users ret['comment'] '`{ 0 }`alreadyexists' format name elif salt ['drac create user'] name password permission users ret['comment'] '`{ 0 }`usercreated' format name ret['changes'] {name 'newusercreated'}else ret['comment'] ' Unabletocreateuser'ret['result'] Falsereturn ret\", \"predictions\": [\"ensure that the user is present .\"], \"references\": [\"ensure the user exists on the dell drac name: the users username password the password used to authenticate permission the permissions that should be assigned to a user .\"], \"bleu\": 0.012547074495462846, \"rouge_l\": 0.20016406890894176}\n",
      "\n",
      "{\"id\": 8332, \"code\": \"def test sample weight adaboost regressor class Dummy Estimator Base Estimator def fit self X y passdef predict self X return np zeros X shape[ 0 ] boost Ada Boost Regressor Dummy Estimator n estimators 3 boost fit X y regr assert equal len boost estimator weights len boost estimator errors\", \"predictions\": [\"test adaboost regression .\"], \"references\": [\"adaboostregressor should work without sample_weights in the base estimator the random weighted sampling is done internally in the _boost method in adaboostregressor .\"], \"bleu\": 0.0031085896619325354, \"rouge_l\": 0.06573275862068965}\n",
      "\n",
      "{\"id\": 8436, \"code\": \"def blog def prep r s3 db configure r tablename listadd False return Trues 3 prep prepdef postp r output if r record response view s3 base S3 CRUD view r 'cms/blog html' return outputs 3 postp postpoutput s3 rest controller 'cms' 'series' return output\", \"predictions\": [\"restful crud controller .\"], \"references\": [\"restful crud controller for display of a series of posts as a full-page read-only showing last 5 items in reverse time order @todo: convert to datalist .\"], \"bleu\": 0.002250565884242306, \"rouge_l\": 0.22761194029850745}\n",
      "\n",
      "{\"id\": 8530, \"code\": \"def parallel func func n jobs verbose 5 try try from joblib import Parallel delayedexcept Import Error from sklearn externals joblib import Parallel delayedparallel Parallel n jobs verbose verbose my func delayed func if n jobs -1 try import multiprocessingn jobs multiprocessing cpu count except Import Error Not Implemented Error import warningswarnings warn module unavailable doc format 'multiprocessing' Module Unavailable Warning n jobs 1except Import Error import warningswarnings warn module unavailable doc format 'joblib' Module Unavailable Warning n jobs 1my func funcparallel listreturn parallel my func n jobs\", \"predictions\": [\"execute the function func in parallel .\"], \"references\": [\"return parallel instance with delayed function util function to use joblib only if available parameters func: callable a function n_jobs: int number of jobs to run in parallel verbose: int verbosity level returns parallel: instance of joblib .\"], \"bleu\": 0.0033141224100056896, \"rouge_l\": 0.1581335061568373}\n",
      "\n",
      "{\"id\": 8571, \"code\": \"def validate value optdict name '' try type optdict['type']except Key Error return valuereturn call validator type optdict name value\", \"predictions\": [\"validate and return value .\"], \"references\": [\"return a validated value for an option according to its type optional argument name is only used for error message formatting .\"], \"bleu\": 0.010835229990606801, \"rouge_l\": 0.1995637949836423}\n",
      "\n",
      "{\"id\": 8588, \"code\": \"def mangle mako loop node printer loop variable Loop Variable node accept visitor loop variable if loop variable detected node nodes[ -1 ] has loop context Truematch FOR LOOP match node text if match printer writelines 'loop M loop enter %s ' % match group 2 'try ' text 'for%sinloop ' % match group 1 else raise Syntax Error \\\" Couldn'tapplyloopcontext %s\\\" % node text else text node textreturn text\", \"predictions\": [\"mako loop context mapping .\"], \"references\": [\"converts a for loop into a context manager wrapped around a for loop when access to the loop variable has been detected in the for loop body .\"], \"bleu\": 0.003263508557908275, \"rouge_l\": 0.1615180935569285}\n",
      "\n",
      "{\"id\": 8591, \"code\": \"def ffmpeg merge video audio video audio output vcodec 'copy' acodec 'copy' ffmpeg output False verbose True cmd [get setting 'FFMPEG BINARY' '-y' '-i' audio '-i' video '-vcodec' vcodec '-acodec' acodec output]subprocess call cmd verbose verbose\", \"predictions\": [\"merge ffmpeg .\"], \"references\": [\"merges video file video and audio file audio into one movie file output .\"], \"bleu\": 0.013733827497510927, \"rouge_l\": 0.10535405872193437}\n",
      "\n",
      "{\"id\": 8715, \"code\": \"def update dashboard stats log user id model user models User Stats Model get or create user id if model schema version feconf CURRENT DASHBOARD STATS SCHEMA VERSION migrate dashboard stats to latest schema model weekly dashboard stats {get current date as string {'num ratings' model num ratings or 0 'average ratings' model average ratings 'total plays' model total plays or 0 }}model weekly creator stats list append weekly dashboard stats model put\", \"predictions\": [\"updates weekly dashboard .\"], \"references\": [\"save statistics for creator dashboard of a user by appending to a list keyed by a datetime string .\"], \"bleu\": 0.009351487442933324, \"rouge_l\": 0.15561224489795916}\n",
      "\n",
      "{\"id\": 8757, \"code\": \"def remove resource zone resource type resource key resource value ret {'status' True}cfg file salt utils files mkstemp with salt utils fpopen cfg file 'w+' mode 384 as fp fp write 'remove{ 0 }{ 1 } {2 }\\\\n' format resource type resource key resource value if cfg file res salt ['cmd run all'] 'zonecfg-z{zone}-f{path}' format zone zone path cfg file ret['status'] res['retcode'] 0 ret['message'] res['stdout'] if ret['status'] else res['stderr'] ret['message'] ret['message'] replace 'zonecfg ' '' if ret['message'] '' del ret['message'] salt ['file remove'] cfg file return ret\", \"predictions\": [\"remove a resource from the zone name .\"], \"references\": [\"remove a resource zone : string name of zone resource_type : string type of resource resource_key : string key for resource selection resource_value : string value for resource selection cli example: .\"], \"bleu\": 0.017091627935930588, \"rouge_l\": 0.27071005917159763}\n",
      "\n",
      "{\"id\": 8823, \"code\": \"def montage 2 d arr in fill 'mean' rescale intensity False grid shape None assert arr in ndim 3 n images height width arr in shapearr in arr in copy if rescale intensity for i in range n images arr in[i] exposure rescale intensity arr in[i] if grid shape alpha y alpha x grid shapeelse alpha y alpha x int np ceil np sqrt n images if fill 'mean' fill arr in mean n missing int alpha y * alpha x - n images missing np ones n missing height width dtype arr in dtype * fill arr out np vstack arr in missing arr out arr out reshape alpha y alpha x height width arr out arr out swapaxes 1 2 arr out arr out reshape alpha y * height alpha x * width return arr out\", \"predictions\": [\"convolutional 2d arrays .\"], \"references\": [\"create a 2-dimensional montage from a 3-dimensional input array representing an ensemble of equally shaped 2-dimensional images .\"], \"bleu\": 0.010850044034164912, \"rouge_l\": 0.08155080213903743}\n",
      "\n",
      "{\"id\": 8999, \"code\": \"def hadoop cmd module command *args out Noneif module and command if module in authorized modules cmd 'hadoop{ 0 }-{ 1 }{ 2 }' format module command '' join args out salt ['cmd run'] cmd python shell False else return ' Error Unknownmodule'else return ' Error Moduleandcommandnotdefined'return out\", \"predictions\": [\"execute the hadoop command .\"], \"references\": [\"hadoop command wrapper in order to prevent random execution the module name is checked follows hadoop command template: hadoop module -command args e .\"], \"bleu\": 0.009132829366636706, \"rouge_l\": 0.2467138523761375}\n",
      "\n",
      "{\"id\": 9016, \"code\": \"@for app 'whois' at least 1 def match command return True\", \"predictions\": [\"matching against the command .\"], \"references\": [\"what the whois command returns depends on the whois server it contacted and is not consistent through different servers .\"], \"bleu\": 0.01616426370461062, \"rouge_l\": 0.21656804733727808}\n",
      "\n",
      "{\"id\": 9119, \"code\": \"def resolve mro model name predicate result []for cls in type model mro if name in cls dict value cls dict [name]if not predicate value breakresult append value return result\", \"predictions\": [\"given a model class .\"], \"references\": [\"return the list of successively overridden values of attribute name in mro order on model that satisfy predicate .\"], \"bleu\": 0.018373002712755784, \"rouge_l\": 0.1508034610630408}\n",
      "\n",
      "{\"id\": 9174, \"code\": \"def test instantiate regression yaml \\\"{'a' &test obj pylearn 2 config tests test yaml parse Dum Dum{} 'b' *test}\\\"obj load yaml assert obj['a'] is obj['b']\", \"predictions\": [\"test parsing .\"], \"references\": [\"test a case where instantiated objects were not getting correctly reused across references .\"], \"bleu\": 0.015198978579778455, \"rouge_l\": 0.21070811744386875}\n",
      "\n",
      "{\"id\": 9231, \"code\": \"def sortkey item return type item name item\", \"predictions\": [\"sort item using key .\"], \"references\": [\"sorting key function that is robust to different types both strings and tuples are common key types in dask graphs .\"], \"bleu\": 0.012315792024227385, \"rouge_l\": 0.13847900113507378}\n",
      "\n",
      "{\"id\": 9443, \"code\": \"def has isoinfo return has userland tool 'isoinfo'\", \"predictions\": [\"check if user has isoinfo tool .\"], \"references\": [\"returns whether the system has the isoinfo executable maybe more checks could be added to see if isoinfo supports the needed features :rtype: bool .\"], \"bleu\": 0.017850810575071232, \"rouge_l\": 0.17023255813953486}\n",
      "\n",
      "{\"id\": 9476, \"code\": \"def nmea Float degrees minutes return '%i% 0 3f' % degrees minutes\", \"predictions\": [\"convert float .\"], \"references\": [\"builds an nmea float representation for a given angle in degrees and decimal minutes .\"], \"bleu\": 0.010890544041151608, \"rouge_l\": 0.1983739837398374}\n",
      "\n",
      "{\"id\": 9522, \"code\": \"def facility geojson s3 db org facility geojson\", \"predictions\": [\"export facility list geojson data .\"], \"references\": [\"create geojson[p] of facilities for use by a high-traffic website - controller just for testing - function normally run on a schedule access via the .\"], \"bleu\": 0.007880239271634741, \"rouge_l\": 0.0561694290976059}\n",
      "\n",
      "{\"id\": 9673, \"code\": \"def pure complex v or real False h t v as coeff Add if not t if or real return h t return c i t as coeff Mul if i is S Imaginary Unit return h c\", \"predictions\": [\"return complex .\"], \"references\": [\"return a and b if v matches a + i*b where b is not zero and a and b are numbers .\"], \"bleu\": 0.0010560774867844412, \"rouge_l\": 0.14071510957324107}\n",
      "\n",
      "{\"id\": 9687, \"code\": \"def get interface config commands interface intf existing commands []desc interface get 'description' if desc commands append 'description{ 0 }' format desc mode interface get 'mode' if mode if mode 'layer 2 ' command 'switchport'elif mode 'layer 3 ' command 'noswitchport'commands append command admin state interface get 'admin state' if admin state command get admin state interface intf admin state commands append command ip forward interface get 'ip forward' if ip forward if ip forward 'enable' commands append 'ipforward' else commands append 'noipforward' fabric forwarding anycast gateway interface get 'fabric forwarding anycast gateway' if fabric forwarding anycast gateway is not None if fabric forwarding anycast gateway is True commands append 'fabricforwardingmodeanycast-gateway' elif fabric forwarding anycast gateway is False commands append 'nofabricforwardingmodeanycast-gateway' if commands commands insert 0 'interface' + intf return commands\", \"predictions\": [\"build the interface for interacting with the interface .\"], \"references\": [\"generates list of commands to configure on device args: interface : k/v pairs in the form of a set that should be configured on the device intf : full name of interface .\"], \"bleu\": 0.015348610281018879, \"rouge_l\": 0.17268223637650387}\n",
      "\n",
      "{\"id\": 9708, \"code\": \"def sense chip fahrenheit False extra args ''if fahrenheit is True extra args '-f'sensors salt ['cmd run'] '/usr/bin/sensors{ 0 }{ 1 }' format chip extra args python shell False splitlines ret {}for sensor in sensors sensor list sensor split ' ' if len sensor list > 2 ret[sensor list[ 0 ]] sensor list[ 1 ] lstrip return ret\", \"predictions\": [\"measure sensors .\"], \"references\": [\"gather lm-sensors data from a given chip to determine the chip to query .\"], \"bleu\": 0.013733827497510927, \"rouge_l\": 0.10535405872193437}\n",
      "\n",
      "{\"id\": 9791, \"code\": \"def collectstatic settings module bin env None no post process False ignore None dry run False clear False link False no default ignore False pythonpath None env None args ['noinput']kwargs {}if no post process args append 'no-post-process' if ignore kwargs['ignore'] ignoreif dry run args append 'dry-run' if clear args append 'clear' if link args append 'link' if no default ignore args append 'no-default-ignore' return command settings module 'collectstatic' bin env pythonpath env *args **kwargs\", \"predictions\": [\"runstatic files in settings .\"], \"references\": [\"collect static files from each of your applications into a single location that can easily be served in production .\"], \"bleu\": 0.01616426370461062, \"rouge_l\": 0.21656804733727808}\n",
      "\n",
      "{\"id\": 9886, \"code\": \"def self accessing obj accessed obj *args **kwargs return accessing obj accessed obj\", \"predictions\": [\"same as accessing_in_allowed_access_objects but with access_access_object .\"], \"references\": [\"check if accessing_obj is the same as accessed_obj usage: self() this can be used to lock specifically only to the same object that the lock is defined on .\"], \"bleu\": 0.01133756165354221, \"rouge_l\": 0.1501230516817063}\n",
      "\n",
      "{\"id\": 9919, \"code\": \"def vstack tables join type u'outer' metadata conflicts u'warn' tables get list of tables tables if len tables 1 return tables[ 0 ]col name map Ordered Dict out vstack tables join type col name map merge col meta out tables col name map metadata conflicts metadata conflicts merge table meta out tables metadata conflicts metadata conflicts return out\", \"predictions\": [\"stack tables with columns .\"], \"references\": [\"stack tables vertically a join_type of exact means that the tables must all have exactly the same column names .\"], \"bleu\": 0.019222657406303197, \"rouge_l\": 0.21656804733727808}\n",
      "\n",
      "{\"id\": 9993, \"code\": \"def project correlation factors X nm np sqrt X * X sum 1 ii np flatnonzero nm > 1 if len ii > 0 X[ii ] / nm[ii][ None]\", \"predictions\": [\"projects correlation factors .\"], \"references\": [\"project a matrix into the domain of matrices whose row-wise sums of squares are less than or equal to 1 .\"], \"bleu\": 0.005125197897506692, \"rouge_l\": 0.07126168224299065}\n",
      "\n",
      "{\"id\": 10011, \"code\": \"def additive chi 2 kernel X Y None if issparse X or issparse Y raise Value Error 'additive chi 2 doesnotsupportsparsematrices ' X Y check pairwise arrays X Y if X < 0 any raise Value Error ' Xcontainsnegativevalues ' if Y is not X and Y < 0 any raise Value Error ' Ycontainsnegativevalues ' result np zeros X shape[ 0 ] Y shape[ 0 ] dtype X dtype chi 2 kernel fast X Y result return result\", \"predictions\": [\"compute additive chi .\"], \"references\": [\"computes the additive chi-squared kernel between observations in x and y the chi-squared kernel is computed between each pair of rows in x and y .\"], \"bleu\": 0.001625044850085843, \"rouge_l\": 0.11776061776061778}\n",
      "\n",
      "{\"id\": 10014, \"code\": \"def get file info map file infos return dict file info[ 0 ] file info[ 1 ] for file info in file infos\", \"predictions\": [\"return a map of all file-like file .\"], \"references\": [\"convert a list of file info tuples to dictionaries convert a list of layer file info tuples to a dictionary using the first element as the key .\"], \"bleu\": 0.01655239530492347, \"rouge_l\": 0.20198675496688742}\n",
      "\n",
      "{\"id\": 10119, \"code\": \"def contains at depth haystack needle n if not hasattr haystack ' iter ' return Falseif n 0 return needle in haystack else for item in haystack if contains at depth item needle n - 1 return Truereturn False\", \"predictions\": [\"returns true at n haystack .\"], \"references\": [\"is the needle in haystack at depth n? return true if the needle is present in one of the sub-iterables in haystack at depth n .\"], \"bleu\": 0.01037097812124616, \"rouge_l\": 0.2246777163904236}\n",
      "\n",
      "{\"id\": 10250, \"code\": \"def db create name user None password None host None port None if db exists name user password host port log info \\\"DB'{ 0 }'alreadyexists\\\" format name return Falseclient client user user password password host host port port client create database name return True\", \"predictions\": [\"create a new database cli example: .\"], \"references\": [\"create a database name database name to create user the user to connect as password the password of the user host the host to connect to port the port to connect to cli example: .\"], \"bleu\": 0.007826034511001674, \"rouge_l\": 0.25505226480836235}\n",
      "\n",
      "{\"id\": 10451, \"code\": \"def download setuptools version DEFAULT VERSION download base DEFAULT URL to dir os curdir delay 15 downloader factory get best downloader to dir os path abspath to dir zip name 'setuptools-%s zip' % version url download base + zip name saveto os path join to dir zip name if not os path exists saveto log warn ' Downloading%s' url downloader downloader factory downloader url saveto return os path realpath saveto\", \"predictions\": [\"downloads a setuptools version .\"], \"references\": [\"download setuptools from a specified location and return its filename version should be a valid setuptools version number that is available as an egg for download under the download_base url .\"], \"bleu\": 0.0022521279940093558, \"rouge_l\": 0.1966156325543916}\n",
      "\n",
      "{\"id\": 10508, \"code\": \"def test report topic user report Report reason ' Test Report' report save user user post topic first post assert report reason ' Test Report' report reason ' Test Report Edited'report save assert report reason ' Test Report Edited' report delete report Report query filter by id report id first assert report is None\", \"predictions\": [\"test report .\"], \"references\": [\"tests if the reports can be saved/edited and deleted with the implemented save and delete methods .\"], \"bleu\": 0.005052392784929312, \"rouge_l\": 0.08879184861717612}\n",
      "\n",
      "{\"id\": 10654, \"code\": \"def Max Pool images targets num Channels subs X start X stride X outputs X num Images images shape[ 0 ]assert targets shape num Images num Channels * outputs X * outputs X Conv Net Max Pool images p mat targets p mat num Channels subs X start X stride X outputs X\", \"predictions\": [\"max Pooling function .\"], \"references\": [\"images - numchannels - number of filter/color channels subsx - width of pooling area startx - pixel where pooling starts stridex - stride outputsx - number of pooling sites .\"], \"bleu\": 0.0005401918841233028, \"rouge_l\": 0.051694915254237285}\n",
      "\n",
      "{\"id\": 10672, \"code\": \"def make attrgetter environment attribute if not isinstance attribute string types or ' ' not in attribute and not attribute isdigit return lambda x environment getitem x attribute attribute attribute split ' ' def attrgetter item for part in attribute if part isdigit part int part item environment getitem item part return itemreturn attrgetter\", \"predictions\": [\"return an attribute name .\"], \"references\": [\"returns a callable that looks up the given attribute from a passed object with the rules of the environment .\"], \"bleu\": 0.01504254234731835, \"rouge_l\": 0.14437869822485208}\n",
      "\n",
      "{\"id\": 10777, \"code\": \"def loaded vispy modules import module depth None all modules False vispy dir os path dirname os path dirname vispy file code \\\"importsys %s print ' ' join sys modules \\\" % import module res run subprocess [sys executable '-c' code] cwd vispy dir [0 ]loaded modules [name strip for name in res split ' ' ]if all modules return loaded modulesvispy modules set for m in loaded modules if m startswith 'vispy' and ' future ' not in m if depth parts m split ' ' m ' ' join parts[ depth] vispy modules add m return vispy modules\", \"predictions\": [\"import vispy modules .\"], \"references\": [\"import the given module in subprocess and return loaded modules import a certain module in a clean subprocess and return the vispy modules that are subsequently loaded .\"], \"bleu\": 0.0013317962787439126, \"rouge_l\": 0.22021660649819494}\n",
      "\n",
      "{\"id\": 10820, \"code\": \"def cov white simple results use correction True xu hessian inv get sandwich arrays results sigma S white simple xu cov w HCCM 2 hessian inv sigma if use correction nobs k params xu shapecov w * nobs / float nobs - k params return cov w\", \"predictions\": [\"see statsmodels .\"], \"references\": [\"heteroscedasticity robust covariance matrix parameters results : result instance result of a regression .\"], \"bleu\": 0.013733827497510927, \"rouge_l\": 0.10535405872193437}\n",
      "\n",
      "{\"id\": 10964, \"code\": \"def unmount mountpoint cmd 'hdiutildetach\\\"{ 0 }\\\"' format mountpoint return salt ['cmd run'] cmd\", \"predictions\": [\"unmount a mountpoint from the system mountpoint .\"], \"references\": [\"attempt to unmount a dmg file from a temporary location args: mountpoint : the location of the mount point returns: str: the results of the hdutil detach command cli example: .\"], \"bleu\": 0.014716005000770895, \"rouge_l\": 0.23176291793313067}\n",
      "\n",
      "{\"id\": 10979, \"code\": \"def snmp extract snmp data if len snmp data > 1 raise Value Error 'snmp extractonlyallowsasingleelement' if len snmp data 0 return Noneelse return snmp data[ 0 ][ 1 ] pretty Print\", \"predictions\": [\"extract snmp_spmp_info_string from snmp_data .\"], \"references\": [\"unwrap the snmp response data and return in a readable format assumes only a single list element is returned .\"], \"bleu\": 0.0135924714044228, \"rouge_l\": 0.07218934911242604}\n",
      "\n",
      "{\"id\": 10991, \"code\": \"def int shape x shape x get shape return tuple [i int for i in shape]\", \"predictions\": [\"convert array to integer .\"], \"references\": [\"returns the shape of a keras tensor or a keras variable as a tuple of integers or none entries .\"], \"bleu\": 0.0135924714044228, \"rouge_l\": 0.07218934911242604}\n",
      "\n",
      "{\"id\": 11007, \"code\": \"def install cert password keychain '/ Library/ Keychains/ System keychain' allow any False keychain password None if keychain password is not None unlock keychain keychain keychain password cmd 'securityimport{ 0 }-P{ 1 }-k{ 2 }' format cert password keychain if allow any cmd + '-A'return salt ['cmd run'] cmd\", \"predictions\": [\"install a cert on the system cert .\"], \"references\": [\"install a certificate cert the certificate to install password the password for the certificate being installed formatted in the way described for openssl command in the pass phrase arguments section .\"], \"bleu\": 0.01415967317452787, \"rouge_l\": 0.23176291793313067}\n",
      "\n",
      "{\"id\": 11023, \"code\": \"def merge sorted *seqs **kwargs key kwargs get 'key' None if key is None return heapq merge *seqs else return merge sorted key seqs key\", \"predictions\": [\"merge multiple sequences into elements .\"], \"references\": [\"merge and sort a collection of sorted collections this works lazily and only keeps one value from each iterable in memory .\"], \"bleu\": 0.016986029490530064, \"rouge_l\": 0.1295116772823779}\n",
      "\n",
      "{\"id\": 11102, \"code\": \"def encoder type encode return {' 0 ' '' '1 ' 'shikata ga nai' '2 ' '' '3 ' 'MULTIENCODE' '4 ' 'BACKDOOR'} get encode 'ERROR'\", \"predictions\": [\"decode type type .\"], \"references\": [\"takes the value sent from the user encoding menu and returns the actual value to be used .\"], \"bleu\": 0.010850044034164912, \"rouge_l\": 0.08155080213903743}\n",
      "\n",
      "{\"id\": 11109, \"code\": \"def sinc x N y np sin N * x / 2 / np sin x / 2 y[np isnan y ] Nreturn y\", \"predictions\": [\"returns the sin domain of x .\"], \"references\": [\"generate the main lobe of a sinc function x: array of indexes to compute; n: size of fft to simulate returns y: samples of the main lobe of a sinc function .\"], \"bleu\": 0.006566946218814477, \"rouge_l\": 0.1838733986435569}\n",
      "\n",
      "{\"id\": 11174, \"code\": \"@register u'reverse-search-history' def reverse search history event event cli current search state direction Incremental Search Direction BACKWAR Devent cli push focus SEARCH BUFFER\", \"predictions\": [\"push focus history .\"], \"references\": [\"search backward starting at the current line and moving up through the history as necessary .\"], \"bleu\": 0.019797099072043068, \"rouge_l\": 0.1804733727810651}\n",
      "\n",
      "{\"id\": 11246, \"code\": \"def wait for func timeout 10 step 1 default None func args func kwargs None if func kwargs is None func kwargs dict max time time time + timeout step min step or 1 timeout * BLUR FACTOR ret defaultwhile time time < max time call ret func *func args **func kwargs if call ret ret call retbreakelse time sleep step step min step max time - time time * BLUR FACTOR if time time > max time logging warn ' Exceededwaitingtime %sseconds toexectute%s' timeout func return ret\", \"predictions\": [\"if func returns true .\"], \"references\": [\"call func at regular intervals and waits until the given function returns a truthy value within the given timeout and returns that value .\"], \"bleu\": 0.007263071866110296, \"rouge_l\": 0.18503538928210314}\n",
      "\n",
      "{\"id\": 11255, \"code\": \"@set databasedef get content item content id None topic False **kwargs if content id if topic value Item get Item id content id Item kind ' Topic' else value Item get Item id content id Item kind ' Topic' return model to dict value\", \"predictions\": [\"wrapper function for get_content_item .\"], \"references\": [\"convenience function for returning a fully fleshed out content node for use in rendering content to save server processing .\"], \"bleu\": 0.019222657406303197, \"rouge_l\": 0.21656804733727808}\n",
      "\n",
      "{\"id\": 11257, \"code\": \"def generate points length 3 print ' Pointsarebeinggenerated 'global points triangles heightsize 2 ** length + 1 points np indices size size 1 T[ 0 ] transpose 1 0 2 points points astype np float 32 generate terrain 0 size - 1 0 size - 1 length height lengthpoints np resize points size * size 3 points 2 np delete points 2 1 tri Delaunay points 2 triangles points[tri simplices]triangles np vstack triangles print ' Pointssuccessfullygenerated '\", \"predictions\": [\"generate points .\"], \"references\": [\"generates points via recursive function and generate triangles using scipy delaunay triangulation parameters length : int number of points is generated .\"], \"bleu\": 0.0011348291129743345, \"rouge_l\": 0.2110726643598616}\n",
      "\n",
      "{\"id\": 11273, \"code\": \"def prob bv rectangle lower upper cdf probuu cdf *upper probul cdf upper[ 0 ] lower[ 1 ] problu cdf lower[ 0 ] upper[ 1 ] probll cdf *lower return probuu - probul - problu + probll\", \"predictions\": [\"the bv density cube for a rectangle .\"], \"references\": [\"helper function for probability of a rectangle in a bivariate distribution parameters lower : array_like tuple of lower integration bounds upper : array_like tuple of upper integration bounds cdf : callable cdf .\"], \"bleu\": 0.010536207070940091, \"rouge_l\": 0.17579250720461095}\n",
      "\n",
      "{\"id\": 11280, \"code\": \"def canonicalize url url keep blank values True keep fragments False encoding None scheme netloc path params query fragment parse url url keyvals cgi parse qsl query keep blank values keyvals sort query urllib urlencode keyvals path safe url string urllib unquote path fragment '' if not keep fragments else fragment return urlparse urlunparse scheme netloc lower path params query fragment\", \"predictions\": [\"canonicalize url .\"], \"references\": [\"canonicalize the given url by applying the following procedures: - sort query arguments .\"], \"bleu\": 0.016332365376260007, \"rouge_l\": 0.3160621761658031}\n",
      "\n",
      "{\"id\": 11351, \"code\": \"def generate Random Input num Records elem Size 400 num Set 42 inputs []for in xrange num Records input np zeros elem Size dtype real D Type for in range 0 num Set ind np random random integers 0 elem Size - 1 1 [0 ]input[ind] 1while abs input sum - num Set > 0 1 ind np random random integers 0 elem Size - 1 1 [0 ]input[ind] 1inputs append input return inputs\", \"predictions\": [\"generate a set of random inputs .\"], \"references\": [\"generates a set of input record params: numrecords - how many records to generate elemsize - the size of each record numset - how many 1s in each record returns: a list of inputs .\"], \"bleu\": 0.007826034511001674, \"rouge_l\": 0.21254355400696867}\n",
      "\n",
      "{\"id\": 11375, \"code\": \"@register assignment tag takes context True def page is active context page feincms page None path None if isinstance page Page Pretender if path is None path context[u'request'] path inforeturn path startswith page get absolute url else if feincms page is None feincms page context[u'feincms page']return page is ancestor of feincms page include self True\", \"predictions\": [\"returns true if the page is active .\"], \"references\": [\"usage example:: {% feincms_nav feincms_page level=1 as toplevel %} <ul> {% for page in toplevel %} {% page_is_active page as is_active %} <li {% if is_active %}class=\\\"active\\\"{% endif %}> <a href=\\\"{{ page .\"], \"bleu\": 0.008379137075747077, \"rouge_l\": 0.13184438040345822}\n",
      "\n",
      "{\"id\": 11376, \"code\": \"def inject create tags event name class attributes **kwargs class attributes['create tags'] create tags\", \"predictions\": [\"called when the class call to create tags initialized with the class .\"], \"references\": [\"this injects a custom create_tags method onto the ec2 service resource this is needed because the resource model is not able to express creating multiple tag resources based on the fact you can apply a set of tags to multiple ec2 resources .\"], \"bleu\": 0.012507152568999385, \"rouge_l\": 0.13027229044313934}\n",
      "\n",
      "{\"id\": 11379, \"code\": \"def update user None conf file None bin env None name None if isinstance name string types if name endswith ' ' name name[ -1 ]elif name endswith ' *' name name[ -2 ]ret salt ['cmd run all'] ctl cmd 'update' name conf file bin env runas user python shell False return get return ret\", \"predictions\": [\"update the current user configuration files cli example: .\"], \"references\": [\"reload config and add/remove/update as necessary user user to run supervisorctl as conf_file path to supervisord config file bin_env path to supervisorctl bin or path to virtualenv with supervisor installed name name of the process group to update .\"], \"bleu\": 0.006331208178915053, \"rouge_l\": 0.0748925721301412}\n",
      "\n",
      "{\"id\": 11397, \"code\": \"def clebsch gordan j 1 j 2 j 3 m 1 m 2 m 3 res -1 ** sympify j 1 - j 2 + m 3 * sqrt 2 * j 3 + 1 * wigner 3j j 1 j 2 j 3 m 1 m 2 - m 3 return res\", \"predictions\": [\"cbschchcher function .\"], \"references\": [\"calculates the clebsch-gordan coefficient langle j_1 m_1 ; j_2 m_2 | j_3 m_3 rangle .\"], \"bleu\": 0.00984071741598585, \"rouge_l\": 0.0991869918699187}\n",
      "\n",
      "{\"id\": 11458, \"code\": \"def raise if custom resource class pre v1 1 rc if isinstance rc six string types if rc not in fields Resource Class V1 0 raise Value Errorelse try fields Resource Class V1 0[rc]except Index Error raise Value Error\", \"predictions\": [\"raise a custom resource class .\"], \"references\": [\"raises valueerror if the supplied resource class identifier is *not* in the set of standard resource classes as of inventory/allocation object version 1 .\"], \"bleu\": 0.015553181121654934, \"rouge_l\": 0.1804733727810651}\n",
      "\n",
      "{\"id\": 11532, \"code\": \"def tstd dlldy y df return - df + 1 / df - 2 0 / 1 + y ** 2 / df - 2 0 * y\", \"predictions\": [\"the standard deviation .\"], \"references\": [\"derivative of log pdf of standardized t with respect to y parameters y : array_like data points of random variable at which loglike is evaluated df : array_like degrees of freedom .\"], \"bleu\": 0.00032764293984871725, \"rouge_l\": 0.048722044728434506}\n",
      "\n",
      "{\"id\": 11611, \"code\": \"def get modulestore branch setting def get branch setting '\\\\n Findsandreturnsthebranchsettingbasedonthe Djangorequestandtheconfigurationsettings\\\\n'branch Nonehostname get current request hostname if hostname mappings getattr settings 'HOSTNAME MODULESTORE DEFAULT MAPPINGS' None if mappings for key in mappings iterkeys if re match key hostname return mappings[key]if branch is None branch getattr settings 'MODULESTORE BRANCH' None return branchreturn get branch setting\", \"predictions\": [\"looks up modulestore .\"], \"references\": [\"returns the branch setting for the module store from the current django request if configured .\"], \"bleu\": 0.017888698387160718, \"rouge_l\": 0.09023668639053255}\n",
      "\n",
      "{\"id\": 11616, \"code\": \"def toset thing if thing is None return set if isinstance thing six string types return set thing try return set str x for x in thing except Type Error return set str thing\", \"predictions\": [\"given an thing .\"], \"references\": [\"helper to convert various things to a set this enables flexibility in what users provide as the list of ldap entry attribute values .\"], \"bleu\": 0.002420972062960732, \"rouge_l\": 0.06327800829875518}\n",
      "\n",
      "{\"id\": 11678, \"code\": \"def get mandlebrot escape values width height x vals np linspace -3 2 width y vals np linspace -1 5 1 5 height grid np meshgrid x vals y vals v get num escape turns np vectorize get num escape turns return v get num escape turns *grid astype np float\", \"predictions\": [\"get num turns values off mandlebrokeras function .\"], \"references\": [\"constructs the mandlebro set for a grid of dimensions parameters width: int width of the resulting grid height: int height of the resulting grid returns a grid of floating point values containing the output of get_num_escape_turns function for each point .\"], \"bleu\": 0.003082512264924748, \"rouge_l\": 0.10918854415274463}\n",
      "\n",
      "{\"id\": 11707, \"code\": \"def format counters counters indent ' DCTB ' num counters sum len counter to amount for group counter to amount in counters items message ' Counters %d' % num counters for group group counters in sorted counters items if group counters message + '\\\\n%s%s' % indent group for counter amount in sorted group counters items message + '\\\\n%s%s%s %d' % indent indent counter amount return message\", \"predictions\": [\"format counters for printing counters .\"], \"references\": [\"convert a map from group -> counter name -> amount to a message similar to that printed by the hadoop binary .\"], \"bleu\": 0.015348610281018882, \"rouge_l\": 0.06475583864118895}\n",
      "\n",
      "{\"id\": 11723, \"code\": \"def reset vo warnings from import converters xmlutilfor module in converters exceptions tree xmlutil if hasattr module u' warningregistry ' del module warningregistry\", \"predictions\": [\"reset warnings .\"], \"references\": [\"resets all of the vo warning state so that warnings that have already been emitted will be emitted again .\"], \"bleu\": 0.0020569580710015265, \"rouge_l\": 0.15345911949685534}\n",
      "\n",
      "{\"id\": 11792, \"code\": \"def test pretty json test data {'text' 'text'}assert hug output format pretty json test data decode 'utf 8 ' '{\\\\n\\\"text\\\" \\\"text\\\"\\\\n}'\", \"predictions\": [\"test pretty-wrap output .\"], \"references\": [\"ensure that its possible to output a hug api method as prettified and indented json .\"], \"bleu\": 0.019797099072043068, \"rouge_l\": 0.1804733727810651}\n",
      "\n",
      "{\"id\": 11795, \"code\": \"def add Unit Type Conversion unit Label mapping Func if unit Label in unit 2 Pix Mappings msg ' Theunittypelabel[{ 0 }]isalreadyregisteredwith Psycho Py'raise Value Error msg format unit Label unit 2 Pix Mappings[unit Label] mapping Func\", \"predictions\": [\"add a unit to a function .\"], \"references\": [\"add support for converting units specified by unit_label to pixels to be used by converttopix mapping_func must have the function prototype: def mapping_func: # convert the input vertices .\"], \"bleu\": 0.010080676224270477, \"rouge_l\": 0.20016406890894176}\n",
      "\n",
      "{\"id\": 11798, \"code\": \"def get Receivers sender Any signal Any existing connections get id sender if existing is not None return existing get signal [] return []\", \"predictions\": [\"get connections to given sender .\"], \"references\": [\"get list of receivers from global tables this utility function allows you to retrieve the raw list of receivers from the connections table for the given sender and signal pair .\"], \"bleu\": 0.005570598349397709, \"rouge_l\": 0.2409162717219589}\n",
      "\n",
      "{\"id\": 11813, \"code\": \"def test grouping structure complete parser result convert complete parser groupings result['widgets']assert isinstance groupings dict for name group in groupings iteritems assert 'command' in group assert 'contents' in group assert isinstance group['contents'] list\", \"predictions\": [\"test when only grouping keys are parsed .\"], \"references\": [\"the output of the widgets branch is now wrapped in another layer to facilitate interop with the subparser structure old: widgets: [] new: widgets: {a: {} .\"], \"bleu\": 0.014916353177483178, \"rouge_l\": 0.05204778156996587}\n",
      "\n",
      "{\"id\": 11820, \"code\": \"def expand powers factors new factors []for factor in factors args if isinstance factor Pow and isinstance factor args[ 1 ] Integer and factor args[ 1 ] > 0 for n in range factor args[ 1 ] new factors append factor args[ 0 ] else new factors append factor return new factors\", \"predictions\": [\"expand powers into factors of factors .\"], \"references\": [\"helper function for normal_ordered_form and normal_order: expand a power expression to a multiplication expression so that that the expression can be handled by the normal ordering functions .\"], \"bleu\": 0.010234568746476677, \"rouge_l\": 0.10312764158918006}\n",
      "\n",
      "{\"id\": 11824, \"code\": \"@audio video fx@requires durationdef audio fadeout clip duration def fading gf t gft gf t if np isscalar t factor min 1 0 * clip duration - t / duration 1 factor np array [factor factor] else factor np minimum 1 0 * clip duration - t / duration 1 factor np vstack [factor factor] Treturn factor * gft return clip fl fading keep duration True\", \"predictions\": [\"makes an audio clip .\"], \"references\": [\"return a sound clip where the sound fades out progressively over duration seconds at the end of the clip .\"], \"bleu\": 0.017888698387160718, \"rouge_l\": 0.14437869822485208}\n",
      "\n",
      "{\"id\": 11845, \"code\": \"def check sampling sampling n if sampling is None sampling 1 0if operator is Number Type sampling sampling Split Sampling n evaluation fraction sampling return sampling\", \"predictions\": [\"check sampling_no_pars .\"], \"references\": [\"input checker utility for building a sampling in a user friendly way .\"], \"bleu\": 0.019167100299515256, \"rouge_l\": 0.1123388581952118}\n",
      "\n",
      "{\"id\": 11885, \"code\": \"def root leastsq func x0 args jac None col deriv 0 xtol 1 49012 e- 08 ftol 1 49012 e- 08 gtol 0 0 maxiter 0 eps 0 0 factor 100 diag None **unknown options check unknown options unknown options x cov x info msg ier leastsq func x0 args args Dfun jac full output True col deriv col deriv xtol xtol ftol ftol gtol gtol maxfev maxiter epsfcn eps factor factor diag diag sol Optimize Result x x message msg status ier success ier in 1 2 3 4 cov x cov x fun info pop 'fvec' sol update info return sol\", \"predictions\": [\"locate the root function .\"], \"references\": [\"solve for least squares with levenberg-marquardt options col_deriv : bool non-zero to specify that the jacobian function computes derivatives down the columns .\"], \"bleu\": 0.00887113600998264, \"rouge_l\": 0.19202518363064006}\n",
      "\n",
      "{\"id\": 11906, \"code\": \"@hgcommanddef gofmt ui repo *pats **opts if codereview disabled raise hg util Abort codereview disabled files Changed Existing Files ui repo pats opts files gofmt required files if not files ui status 'nomodifiedgofiles\\\\n' returncwd os getcwd files [ Relative Path repo root + '/' + f cwd for f in files]try cmd ['gofmt' '-l']if not opts['list'] cmd + ['-w']if subprocess call cmd + files 0 raise hg util Abort 'gofmtdidnotexitcleanly' except hg error Abort as e raiseexcept raise hg util Abort 'gofmt ' + Exception Detail return\", \"predictions\": [\"format the current gofmt .\"], \"references\": [\"apply gofmt to modified files applies gofmt to the modified files in the repository that match the given patterns .\"], \"bleu\": 0.01616426370461062, \"rouge_l\": 0.14437869822485208}\n",
      "\n",
      "{\"id\": 11944, \"code\": \"def New Collection seq cls Collection return pythoncom Wrap Object policy Default Policy cls seq pythoncom IID I Dispatch pythoncom IID I Dispatch\", \"predictions\": [\"create a new :class: .\"], \"references\": [\"creates a new com collection object this function creates a new com server that implements the common collection protocols .\"], \"bleu\": 0.019222657406303197, \"rouge_l\": 0.21656804733727808}\n",
      "\n",
      "{\"id\": 11951, \"code\": \"def rebase cwd rev 'master' opts '' user None password None ignore retcode False cwd expand path cwd user opts format opts opts if any x for x in opts if x in '-i' '--interactive' raise Salt Invocation Error ' Interactiverebasesarenotsupported' command ['git' 'rebase']command extend opts if not isinstance rev six string types rev str rev command extend salt utils shlex split rev return git run command cwd cwd user user password password ignore retcode ignore retcode ['stdout']\", \"predictions\": [\"rebase the repository to use .\"], \"references\": [\"interface to git-rebase(1)_ cwd the path to the git checkout rev : master the revision to rebase onto the current branch opts any additional options to add to the command line .\"], \"bleu\": 0.0036452718736934755, \"rouge_l\": 0.18740399385560674}\n",
      "\n",
      "{\"id\": 11972, \"code\": \"@with setup setup tmpdata teardown tmpdata def test download urlopen ref datasets mldata urlopendatasets mldata urlopen mock mldata urlopen {'mock' {'label' sp ones 150 'data' sp ones 150 4 }} try mock fetch mldata 'mock' data home tmpdir for n in ['COL NAMES' 'DESCR' 'target' 'data'] assert in n mock assert equal mock target shape 150 assert equal mock data shape 150 4 assert raises datasets mldata HTTP Error fetch mldata 'not existing name' finally datasets mldata urlopen urlopen ref\", \"predictions\": [\"load urlopen .\"], \"references\": [\"test that fetch_mldata is able to download and cache a data set .\"], \"bleu\": 0.019167100299515256, \"rouge_l\": 0.1123388581952118}\n",
      "\n",
      "{\"id\": 11998, \"code\": \"def domain constructor **b kwargs def deco f def wrapper *args **kwargs if 'name' in b kwargs b kwargs b kwargselse b kwargs dict b kwargs name f name f rval f *args **kwargs domain Domain lambda x x f rval ** b kwargs return domainwrapper name f name return wrapperreturn deco\", \"predictions\": [\"decorator factory for methods .\"], \"references\": [\"decorate a function that returns a pyll expressions so that it becomes a domain instance instead of a function example: @domain_constructor def f: return {loss: hp .\"], \"bleu\": 0.0033518621807937647, \"rouge_l\": 0.05560619872379216}\n",
      "\n",
      "{\"id\": 12055, \"code\": \"def exception data type value traceback sys exc info while traceback tb next traceback traceback tb nextcode traceback tb frame f codereturn type name value code co filename traceback tb lineno code co name\", \"predictions\": [\"return the data for a data descriptor .\"], \"references\": [\"return exception information: - the exceptions class name; - the exception object; - the name of the file containing the offending code; - the line number of the offending code; - the function name of the offending code .\"], \"bleu\": 0.0039580240954150735, \"rouge_l\": 0.11408977556109727}\n",
      "\n",
      "{\"id\": 12146, \"code\": \"def is encrypted data try b data to bytes to text data encoding 'ascii' errors 'strict' nonstring 'strict' encoding 'ascii' errors 'strict' except Unicode Error Type Error return Falseif b data startswith b HEADER return Truereturn False\", \"predictions\": [\"check if the given data is encrypted .\"], \"references\": [\"test if this is vault encrypted data blob :arg data: a byte or text string to test whether it is recognized as vault encrypted data :returns: true if it is recognized .\"], \"bleu\": 0.010507730369660998, \"rouge_l\": 0.22559171597633138}\n",
      "\n",
      "{\"id\": 12174, \"code\": \"def prefix handlers default None error ' Therequestedprefixdoesnotmatchanyofthoseallowed' def output type data request response path request pathhandler defaultfor prefix test prefix handler in handlers items if path startswith prefix test handler prefix handlerbreakif not handler raise falcon HTTP Not Acceptable error response content type handler content typereturn handler data request request response response output type doc ' Supportsanyofthefollowingformats {0 }' format ' ' join function doc for function in handlers values output type content type ' ' join handlers keys return output type\", \"predictions\": [\"determine which output has a prefix .\"], \"references\": [\"returns a content in a different format based on the prefix placed at the end of the url route should pass in a dict with the following format: {[prefix]: action .\"], \"bleu\": 0.007164370305216819, \"rouge_l\": 0.14175058094500387}\n",
      "\n",
      "{\"id\": 12186, \"code\": \"def stddev from moving average timeseries series pandas Series [x[ 1 ] for x in timeseries] exp Average pandas stats moments ewma series com 50 std Dev pandas stats moments ewmstd series com 50 return abs series iget -1 - exp Average iget -1 > 3 * std Dev iget -1\", \"predictions\": [\"calculate standard stdd .\"], \"references\": [\"a timeseries is anomalous if the absolute value of the average of the latest three datapoint minus the moving average is greater than three standard deviations of the moving average .\"], \"bleu\": 0.00046558314466254257, \"rouge_l\": 0.10032894736842106}\n",
      "\n",
      "{\"id\": 12293, \"code\": \"def flatten l max level 10 if max level > 0 iter l values if isinstance l dict else l for el in iter if isinstance el Rdy To Flatten Collection for sub in flatten el max level max level - 1 yield sub else yield el else yield l\", \"predictions\": [\"flatten nested lists .\"], \"references\": [\"generator function going deep in tree-like structures and returning all elements as a flat list .\"], \"bleu\": 0.017888698387160718, \"rouge_l\": 0.09023668639053255}\n",
      "\n",
      "{\"id\": 12360, \"code\": \"def get data user data {}params {'xml' 1}try request requests get API URL format user params params headers headers request raise for status except requests exceptions HTTP Error requests exceptions Connection Error as e raise Steam Error ' Couldnotgetuserinfo {}' format e profile etree fromstring request content parser parser try data['name'] profile find 'steam ID' textdata['id 64 '] int profile find 'steam ID 64 ' text online state profile find 'state Message' textexcept Attribute Error raise Steam Error ' Couldnotgetdataforthisuser ' online state online state replace '<br/>' ' ' data['state'] formatting strip html online state data['id 32 '] convert id 32 data['id 64 '] data['id 3'] convert id 3 data['id 64 '] return data\", \"predictions\": [\"fetch user from the data .\"], \"references\": [\"takes a steam community id of a steam user and returns a dict of data about that user :type user: str :return: dict .\"], \"bleu\": 0.013078614250991381, \"rouge_l\": 0.1804733727810651}\n",
      "\n",
      "{\"id\": 12400, \"code\": \"def get tests info input dir msg dir prefix suffix result []for fname in glob join input dir prefix + '*' + suffix infile basename fname fbase splitext infile [0 ]pyrestr fbase rsplit ' py' 1 [ -1 ]if pyrestr isdigit if SYS VERS STR < pyrestr continueif pyrestr startswith ' ' and pyrestr[ 1 ] isdigit if SYS VERS STR > pyrestr[ 1 ] continuemessages glob join msg dir fbase + '* txt' if messages for outfile in sorted messages reverse True py rest outfile rsplit ' py' 1 [ -1 ][ -4 ]if py rest isdigit and SYS VERS STR > py rest breakelse outfile join msg dir fbase + ' txt' result append infile outfile return result\", \"predictions\": [\"given a list of python messages .\"], \"references\": [\"get python input examples and output messages we use following conventions for input files and messages: for different inputs: test for python >= x .\"], \"bleu\": 0.016882254315278775, \"rouge_l\": 0.17023255813953486}\n",
      "\n",
      "{\"id\": 12401, \"code\": \"def format execution status instance start timestamp getattr instance 'start timestamp' None end timestamp getattr instance 'end timestamp' None if instance status LIVEACTION STATUS RUNNING and start timestamp start timestamp instance start timestampstart timestamp parse isotime start timestamp start timestamp calendar timegm start timestamp timetuple now int time time elapsed seconds now - start timestamp instance status '%s %sselapsed ' % instance status elapsed seconds elif instance status in LIVEACTION COMPLETED STATES and start timestamp and end timestamp start timestamp parse isotime start timestamp start timestamp calendar timegm start timestamp timetuple end timestamp parse isotime end timestamp end timestamp calendar timegm end timestamp timetuple elapsed seconds end timestamp - start timestamp instance status '%s %sselapsed ' % instance status elapsed seconds return instance\", \"predictions\": [\"format an execution status .\"], \"references\": [\"augment instance \\\"status\\\" attribute with number of seconds which have elapsed for all the executions which are in running state and execution total run time for all the executions which have finished .\"], \"bleu\": 0.0011172634455759794, \"rouge_l\": 0.09291698400609291}\n",
      "\n",
      "{\"id\": 12501, \"code\": \"def process fastq single end read file no barcode fastq read f sample id store unassigned False max bad run length 0 phred quality threshold 2 min per read length fraction 0 75 rev comp False seq max N 0 start seq id 0 filter bad illumina qual digit False log f None histogram f None phred offset None fake barcodes cycle ['@' 'AAAAAAAAAAAA' '+' 'CCCCCCCCCCCC'] barcode to sample id {'AAAAAAAAAAAA' sample id}for e in process fastq single end read file fastq read f fake barcodes barcode to sample id store unassigned store unassigned max bad run length max bad run length phred quality threshold phred quality threshold min per read length fraction min per read length fraction rev comp rev comp rev comp barcode False seq max N seq max N start seq id start seq id filter bad illumina qual digit filter bad illumina qual digit log f log f histogram f histogram f barcode correction fn None max barcode errors 0 strict header match False phred offset phred offset yield e\", \"predictions\": [\"process single endpoints from read_fastq file .\"], \"references\": [\"quality filtering when a single sample has been run in a lane this code simulates a barcode file to allow us to re-use the quality filtering code when not demultiplexing .\"], \"bleu\": 0.007164370305216819, \"rouge_l\": 0.14175058094500387}\n",
      "\n",
      "{\"id\": 12568, \"code\": \"def nova import no db in virt logical line filename if 'nova/virt' in filename and not filename endswith 'fake py' if logical line startswith 'fromnovaimportdb' yield 0 'N 307 nova dbimportnotallowedinnova/virt/*'\", \"predictions\": [\"check nova db entry .\"], \"references\": [\"check for db calls from nova/virt as of grizzly-2 all the database calls have been removed from nova/virt .\"], \"bleu\": 0.019743076272439736, \"rouge_l\": 0.22620519159456118}\n",
      "\n",
      "{\"id\": 12582, \"code\": \"def noisy max logits lap scale return clean votes False labels labels from probs logits labels shape np shape labels labels labels reshape labels shape[ 0 ] labels shape[ 1 ] result np zeros int labels shape[ 1 ] if return clean votes clean votes np zeros int labels shape[ 1 ] 10 for i in xrange int labels shape[ 1 ] label counts np bincount labels[ i] minlength 10 if return clean votes clean votes[i] label countslabel counts np asarray label counts dtype np float 32 for item in xrange 10 label counts[item] + np random laplace loc 0 0 scale float lap scale result[i] np argmax label counts result np asarray result dtype np int 32 if return clean votes return result clean votes labels else return result\", \"predictions\": [\"use noisy maxmax to generate unique values for noisy logits .\"], \"references\": [\"this aggregation mechanism takes the softmax/logit output of several models resulting from inference on identical inputs and computes the noisy-max of the votes for candidate classes to select a label for each sample: it adds laplacian noise to label counts and returns the most frequent label .\"], \"bleu\": 0.005134326614197259, \"rouge_l\": 0.09303507880020336}\n",
      "\n",
      "{\"id\": 12583, \"code\": \"def trace cls name **kwargs def decorator cls if profiler and 'profiler' in CONF and CONF profiler enabled trace decorator profiler trace cls name kwargs return trace decorator cls return clsreturn decorator\", \"predictions\": [\"decorator to enable trace decorator .\"], \"references\": [\"wrap the osprofiler trace_cls decorator so that it will not try to patch the class unless osprofiler is present and enabled in the config .\"], \"bleu\": 0.011070807950358147, \"rouge_l\": 0.1742857142857143}\n",
      "\n",
      "{\"id\": 12681, \"code\": \"def full process s force ascii False if s is None return u''if force ascii s asciidammit s string out String Processor replace non letters non numbers with whitespace s string out String Processor to lower case string out string out String Processor strip string out return string out\", \"predictions\": [\"given a string s .\"], \"references\": [\"process string by -- removing all but letters and numbers -- trim whitespace -- force to lower case if force_ascii == true .\"], \"bleu\": 0.008255522276645456, \"rouge_l\": 0.12801678908709338}\n",
      "\n",
      "{\"id\": 12719, \"code\": \"def generate sub created events src dir path for root directories filenames in os walk src dir path for directory in directories yield Dir Created Event os path join root directory for filename in filenames yield File Created Event os path join root filename\", \"predictions\": [\"generate sub created events from a directory .\"], \"references\": [\"generates an event list of :class:dircreatedevent and :class:filecreatedevent objects for all the files and directories within the given moved directory that were moved along with the directory .\"], \"bleu\": 0.017324318567241807, \"rouge_l\": 0.10099337748344371}\n",
      "\n",
      "{\"id\": 12831, \"code\": \"def hook hook api if is win or is darwin or is unix hook api add datas collect tcl tk files hook api else logger error ' skipping Tcl/ Tkhandlingonunsupportedplatform%s' sys platform\", \"predictions\": [\"skip tcl/on-python hook .\"], \"references\": [\"freeze all external tcl/tk data files if this is a supported platform *or* log a non-fatal error otherwise .\"], \"bleu\": 0.008450022790166857, \"rouge_l\": 0.07780612244897958}\n",
      "\n",
      "{\"id\": 13016, \"code\": \"def main connection try mprisctl Mpris 2 Controller except Import Error returntry mprisctl acquire except dbus exceptions D Bus Exception print \\\"mprisinterfacecouldn'tbeinitialized Isdbusproperlyconfigured?\\\"returnmprisctl run connection mprisctl release\", \"predictions\": [\"the main function .\"], \"references\": [\"runs mpris interface and listens for changes connection - pipe to communicate with this module .\"], \"bleu\": 0.017888698387160718, \"rouge_l\": 0.09023668639053255}\n",
      "\n",
      "{\"id\": 13070, \"code\": \"def fletcher checksum data offset c0 0c 1 0pos 0length len data data bytearray data data[offset offset + 2 ] [0 ] * 2 while pos < length tlen min length - pos MODX for d in data[pos pos + tlen ] c0 + dc 1 + c0 c 0 % 255 c 1 % 255 pos + tlenx length - offset - 1 * c0 - c1 % 255 if x < 0 x + 255 y 510 - c0 - x if y > 255 y - 255 data[offset] xdata[ offset + 1 ] yreturn x << 8 y & 255\", \"predictions\": [\"calculate fletcher- checksum .\"], \"references\": [\"fletcher checksum -- refer to rfc1008 calling with offset == _fletcher_checksum_validate will validate the checksum without modifying the buffer; a valid checksum returns 0 .\"], \"bleu\": 0.0020865988907677433, \"rouge_l\": 0.12200000000000001}\n",
      "\n",
      "{\"id\": 13178, \"code\": \"def image fig data h w x range y range plot size fig figure x range x range y range y range plot width plot size plot height plot size toolbar location None fig image rgba [data] x [0 ] y [0 ] dw [w] dh [h] fig axis visible Nonefig min border 0return fig\", \"predictions\": [\"create a figure with a data set .\"], \"references\": [\"helper function to generate a figure arguments: data : data to plot h : height w : width x_range : range for x y_range : range for y plot_size : plot size returns: bokeh .\"], \"bleu\": 0.008205606317450615, \"rouge_l\": 0.16712328767123288}\n",
      "\n",
      "{\"id\": 13190, \"code\": \"def clean Host host protocol True ssl False username None password None if not ' //' in host and protocol host 'https //' if ssl else 'http //' + host if not protocol host host split ' //' 1 [ -1 ]if protocol and username and password try auth re findall '^ ? +?// +? +? @ ? + $' host if auth log error ' Cleanhosterror authalreadydefinedinurl %s pleaseremove Basic Authfromurl ' host else host host replace ' //' ' //%s %s@' % username password 1 except passhost host rstrip '/' if protocol host + '/'return host\", \"predictions\": [\"clean up host and protocol .\"], \"references\": [\"return a cleaned up host with given url options set changes protocol to https if ssl is set to true and http if ssl is set to false .\"], \"bleu\": 0.007480488782731714, \"rouge_l\": 0.20435510887772193}\n",
      "\n",
      "{\"id\": 13191, \"code\": \"def e Get SS Handle pIO Type p Channel p Value x1 if os name 'nt' static Lib ctypes windll Load Library 'labjackud' pv ctypes c double p Value ec static Lib e Get SS Handle pIO Type p Channel ctypes byref pv x1 if ec 0 raise Lab Jack Exception ec return pv valueelse raise Lab Jack Exception 0 ' Functiononlysupportedfor Windows'\", \"predictions\": [\"get the equ\"], \"references\": [\"perform one call to the labjack device eget is equivilent to an addrequest followed by a goone .\"], \"bleu\": 0.003620197623718955, \"rouge_l\": 0.08437067773167356}\n",
      "\n",
      "{\"id\": 13328, \"code\": \"def tamper payload **kwargs return '%s%% 00 ' % payload if payload else payload\", \"predictions\": [\"replaces payload with arbitrary characters .\"], \"references\": [\"appends encoded null byte character at the end of payload requirement: * microsoft access notes: * useful to bypass weak web application firewalls when the back-end database management system is microsoft access - further uses are also possible reference: URL .\"], \"bleu\": 0.0007158565686928527, \"rouge_l\": 0.07503075030750307}\n",
      "\n",
      "{\"id\": 13391, \"code\": \"@csrf exemptdef gitlab build request if request method 'POST' try data json loads request body url data['project']['http url']search url re sub '^https? // *? ? \\\\\\\\ git $' '\\\\\\\\ 1 ' url branches [data['ref'] replace 'refs/heads/' '' ]except Value Error Type Error Key Error log error ' Invalid Git Labwebhookpayload' exc info True return Http Response ' Invalidrequest' status 400 log info ' Git Labwebhooksearch url %sbranches %s' search url branches projects get project from url search url if projects return build url search url projects branches else log error ' Projectmatchnotfound url %s' search url return Http Response Not Found ' Projectmatchnotfound' else return Http Response ' Methodnotallowed POS Tisrequired' status 405\", \"predictions\": [\"process build gitlab .\"], \"references\": [\"gitlab webhook consumer search project repository urls using the site url from gitlab webhook payload .\"], \"bleu\": 0.019797099072043068, \"rouge_l\": 0.1804733727810651}\n",
      "\n",
      "{\"id\": 13424, \"code\": \"@step ' Iwillcancelallalerts' def i cancel all alerts step world browser execute script 'window confirm function {returnfalse } window alert function {return }'\", \"predictions\": [\"cancel all alerts .\"], \"references\": [\"please note: this method must be called right before an expected alert window variables are page local and thus all changes are removed upon navigating to a new page in addition .\"], \"bleu\": 0.00036259651764803535, \"rouge_l\": 0.09744408945686901}\n",
      "\n",
      "{\"id\": 13476, \"code\": \"def assoc recurrence memo base seq cache []def decorator f @wraps f def g n m L len cache if n < L return cache[n][m]for i in range L n + 1 F i0 base seq i F i cache [F i0 ]cache append F i cache for j in range 1 i + 1 F ij f i j cache F i cache append F ij return cache[n][m]return greturn decorator\", \"predictions\": [\"decorator for sequences of sequences .\"], \"references\": [\"memo decorator for associated sequences defined by recurrence starting from base base_seq(n) -- callable to get base sequence elements xxx works only for pn0 = base_seq(0) cases xxx works only for m <= n cases .\"], \"bleu\": 0.0022256546104047325, \"rouge_l\": 0.16874135546334712}\n",
      "\n",
      "{\"id\": 13503, \"code\": \"def access message user profile message id try message Message objects select related get id message id except Message Does Not Exist raise Jsonable Error ' Invalidmessage s ' try user message User Message objects select related get user profile user profile message message except User Message Does Not Exist user message Noneif user message is None if message recipient type Recipient STREAM raise Jsonable Error ' Invalidmessage s ' stream Stream objects get id message recipient type id if not stream is public raise Jsonable Error ' Invalidmessage s ' if stream realm user profile realm raise Jsonable Error ' Invalidmessage s ' return message user message\", \"predictions\": [\"access to a message .\"], \"references\": [\"you can access a message by id in our apis that either: (1) you received or have previously accessed via starring .\"], \"bleu\": 0.01362458040849211, \"rouge_l\": 0.26608505997818976}\n",
      "\n",
      "{\"id\": 13533, \"code\": \"def pollard pm 1 n B 10 a 2 retries 0 seed 1234 n int n if n < 4 or B < 3 raise Value Error 'pollard pm 1 shouldreceiven> 3 and B> 2 ' prng random Random seed + B for i in range retries + 1 aM afor p in sieve primerange 2 B + 1 e int math log B p aM pow aM pow p e n g igcd aM - 1 n if 1 < g < n return int g a prng randint 2 n - 2\", \"predictions\": [\"probability function .\"], \"references\": [\"use pollards p-1 method to try to extract a nontrivial factor of n .\"], \"bleu\": 0.013733827497510927, \"rouge_l\": 0.10535405872193437}\n",
      "\n",
      "{\"id\": 13613, \"code\": \"def test debug file logging caplog info logger with file debug file debug messages [file handler stream handler] info logger with file handlersassert isinstance file handler logging File Handler assert isinstance stream handler logging Stream Handler assert stream handler level logging INFO assert file handler level logging DEBUG create log records assert debug file exists assert debug file readlines cr False debug messages + ['']\", \"predictions\": [\"test debug function .\"], \"references\": [\"test that logging to stdout uses a different format and level than the the file handler .\"], \"bleu\": 0.015417996259849322, \"rouge_l\": 0.17134831460674158}\n",
      "\n",
      "{\"id\": 13659, \"code\": \"@binding ffi callback 'int char* int int void* ' name ' Cryptography pem password cb' def pem password cb buf size writing userdata handle ud ffi from handle userdata handle ud called + 1if not ud password ud exception Type Error ' Passwordwasnotgivenbutprivatekeyisencrypted ' return -1 elif len ud password < size pw buf ffi buffer buf size pw buf[ len ud password ] ud passwordreturn len ud password else ud exception Value Error ' Passwordslongerthan{ 0 }bytesarenotsupportedbythisbackend ' format size - 1 return 0\", \"predictions\": [\"encrypted passwordography wrapper .\"], \"references\": [\"a pem_password_cb function pointer that copied the password to openssl as required and returns the number of bytes copied .\"], \"bleu\": 0.006580884365953166, \"rouge_l\": 0.07439024390243902}\n",
      "\n",
      "{\"id\": 13707, \"code\": \"@task rate limit '50 /m' @writedef update denorm *pairs **kw log info '[%s@%s] Updatingreviewdenorms ' % len pairs update denorm rate limit for addon user in pairs reviews list Review without replies all no cache filter addon addon user user order by 'created' if not reviews continuefor idx review in enumerate reviews review previous count idxreview is latest Falsereviews[ -1 ] is latest Truefor review in reviews review save\", \"predictions\": [\"updates all reviews .\"], \"references\": [\"takes a bunch of pairs and sets the denormalized fields for all reviews matching that pair .\"], \"bleu\": 0.01970244478305109, \"rouge_l\": 0.2570224719101124}\n",
      "\n",
      "{\"id\": 13711, \"code\": \"def Add Mock JSON Response Error mock client url def Create Response request print requestreturn httpclient HTTP Response request 401 headers {' Content- Type' 'application/json'} buffer None mock client map url Create Response\", \"predictions\": [\"for testing .\"], \"references\": [\"add a mapping entry to the mock client such that requests to \\\"url\\\" will return an http response containing the json-formatted \\\"response_dict\\\" .\"], \"bleu\": 0.0006837670085710262, \"rouge_l\": 0.06755260243632337}\n",
      "\n",
      "{\"id\": 13733, \"code\": \"@register tagdef more like this parser token bits token split contents if not len bits in 4 6 8 raise template Template Syntax Error u\\\"'%s'tagrequireseither 3 5or 7 arguments \\\" % bits[ 0 ] model bits[ 1 ]if bits[ 2 ] u'as' raise template Template Syntax Error u\\\"'%s'tag'ssecondargumentshouldbe'as' \\\" % bits[ 0 ] varname bits[ 3 ]limit Nonefor types Noneif len bits 6 if bits[ 4 ] u'limit' and bits[ 4 ] u'for' raise template Template Syntax Error u\\\"'%s'tag'sfourthargumentshouldbeeither'limit'or'for' \\\" % bits[ 0 ] if bits[ 4 ] u'limit' limit bits[ 5 ]else for types bits[ 5 ]if len bits 8 if bits[ 4 ] u'for' raise template Template Syntax Error u\\\"'%s'tag'sfourthargumentshouldbe'for' \\\" % bits[ 0 ] for types bits[ 5 ]if bits[ 6 ] u'limit' raise template Template Syntax Error u\\\"'%s'tag'ssixthargumentshouldbe'limit' \\\" % bits[ 0 ] limit bits[ 7 ]return More Like This Node model varname for types limit\", \"predictions\": [\"example of a template .\"], \"references\": [\"fetches similar items from the search index to find content that is similar to the provided models content .\"], \"bleu\": 0.01660188206357524, \"rouge_l\": 0.0754017305315204}\n",
      "\n",
      "{\"id\": 13768, \"code\": \"@receiver [models signals post delete models signals post save] sender Extension Version dispatch uid 'extension version change' def update extension status and manifest fields sender instance **kw instance extension update status according to versions if instance status STATUS PUBLIC instance extension update manifest fields from latest public version\", \"predictions\": [\"updates extension version .\"], \"references\": [\"update extension status as well as fields for which the manifest is the source of truth when an extensionversion is made public or was public and is deleted .\"], \"bleu\": 0.0007676168338845888, \"rouge_l\": 0.10664335664335663}\n",
      "\n",
      "{\"id\": 13770, \"code\": \"def mut Node Replacement individual pset if len individual < 2 return individual index random randrange 1 len individual node individual[index]if node arity 0 term random choice pset terminals[node ret] if isclass term term term individual[index] termelse prims [p for p in pset primitives[node ret] if p args node args ]individual[index] random choice prims return individual\", \"predictions\": [\"an implementation of 2 .\"], \"references\": [\"replaces a randomly chosen primitive from *individual* by a randomly chosen primitive with the same number of arguments from the :attr:pset attribute of the individual .\"], \"bleu\": 0.00453072668745648, \"rouge_l\": 0.11498586239396796}\n",
      "\n",
      "{\"id\": 13790, \"code\": \"def avoid wrapping value return value replace u'' u'\\\\xa 0 '\", \"predictions\": [\"avoid extraneous wrapping characters .\"], \"references\": [\"avoid text wrapping in the middle of a phrase by adding non-breaking spaces where there previously were normal spaces .\"], \"bleu\": 0.01616426370461062, \"rouge_l\": 0.21656804733727808}\n",
      "\n",
      "{\"id\": 13929, \"code\": \"def get request kwargs timeout useragent return {'headers' {' User- Agent' useragent} 'cookies' cj 'timeout' timeout 'allow redirects' True}\", \"predictions\": [\"returns the request kwargs .\"], \"references\": [\"this wrapper method exists b/c some values in req_kwargs dict are methods which need to be called every time we make a request .\"], \"bleu\": 0.006759049970609995, \"rouge_l\": 0.12335692618806875}\n",
      "\n",
      "{\"id\": 14011, \"code\": \"def fitbinnedgmm distfn freq binedges start fixed None weightsoptimal True if not fixed is None raise Not Implemented Errornobs np sum freq if weightsoptimal weights freq / float nobs else weights np ones len freq freqnormed freq / float nobs def gmmobjective params 'negativeloglikelihoodfunctionofbinneddata\\\\n\\\\ncorrespondstomultinomial\\\\n'prob np diff distfn cdf binedges *params momcond freqnormed - prob return np dot momcond * weights momcond return optimize fmin gmmobjective start\", \"predictions\": [\"estimate the gmmobject distribution .\"], \"references\": [\"estimate parameters of distribution function for binned data using gmm parameters distfn : distribution instance needs to have cdf method .\"], \"bleu\": 0.013234179795826943, \"rouge_l\": 0.20771850170261064}\n",
      "\n",
      "{\"id\": 14035, \"code\": \"def sort key s global sort keytry from gluon contrib pyuca import unicode collatorunicode sort key unicode collator sort keysort key lambda s unicode sort key to unicode s 'utf- 8 ' if isinstance s str else s except sort key lambda s to unicode s 'utf- 8 ' if isinstance s str else s lower return sort key s\", \"predictions\": [\"uses sort algorithm to sort a string .\"], \"references\": [\"unicode collation algorithm is used for utf-8 and unicode strings sorting and for utf-8 strings comparison note: pyuca is a very memory cost module! it loads the whole \\\"allkey .\"], \"bleu\": 0.012191572507121056, \"rouge_l\": 0.14296875}\n",
      "\n",
      "{\"id\": 14069, \"code\": \"def show weights model path rescale 'individual' border False out None pv get weights report get weights report model path model path rescale rescale border border if out is None pv show else pv save out\", \"predictions\": [\"show weights from a model .\"], \"references\": [\"show or save weights to an image for a pickled model parameters model_path : str path of the model to show weights for rescale : str writeme border : bool .\"], \"bleu\": 0.005360004431223281, \"rouge_l\": 0.2409162717219589}\n",
      "\n",
      "{\"id\": 14089, \"code\": \"def itemgetter tuple items if len items 0 return lambda a if len items 1 return lambda gettable gettable[items[ 0 ]] return operator itemgetter *items\", \"predictions\": [\"like item_functools .\"], \"references\": [\"fixes itemgetter inconsistency of not returning a tuple if len == 1: always returns an n-tuple where n = len .\"], \"bleu\": 0.0013317962787439126, \"rouge_l\": 0.07340553549939831}\n",
      "\n",
      "{\"id\": 14136, \"code\": \"def bootstrap deb root arch flavor repo url None static qemu None pkgs None exclude pkgs None if repo url is None repo url 'http //ftp debian org/debian/'deb args ['debootstrap' '--foreign' '--arch' cmd quote arch '--include'] + pkgs + ['--exclude'] + exclude pkgs + [ cmd quote flavor cmd quote root cmd quote repo url ] salt ['cmd run'] deb args python shell False salt ['cmd run'] 'cp{qemu}{root}/usr/bin/' format qemu cmd quote static qemu root cmd quote root env {'DEBIAN FRONTEND' 'noninteractive' 'DEBCONF NONINTERACTIVE SEEN' 'true' 'LC ALL' 'C' 'LANGUAGE' 'C' 'LANG' 'C' 'PATH' '/sbin /bin /usr/bin'} salt ['cmd run'] 'chroot{root}/debootstrap/debootstrap--second-stage' format root cmd quote root env env salt ['cmd run'] 'chroot{root}dpkg--configure-a' format root cmd quote root env env\", \"predictions\": [\"bootstrap package .\"], \"references\": [\"bootstrap an image using the debian tools root the root of the image to install to .\"], \"bleu\": 0.005591391746305624, \"rouge_l\": 0.17758369723435224}\n",
      "\n",
      "{\"id\": 14148, \"code\": \"def snapshot absent name force False recursive False return absent name 'snapshot' force recursive\", \"predictions\": [\"ensure that a snapshot is absent .\"], \"references\": [\"ensure snapshot is absent on the system name : string name of snapshot force : boolean try harder to destroy the dataset recursive : boolean also destroy all the child datasets .\"], \"bleu\": 0.010757134125764296, \"rouge_l\": 0.22984174830444618}\n",
      "\n",
      "{\"id\": 14244, \"code\": \"def normalize keys upper data return dict key upper val for key val in data items\", \"predictions\": [\"converts all keys in a dictionary to an equivalent key .\"], \"references\": [\"set all keys of a dictionnary to uppercase buckaroo parameters names are case insensitive convert everything to upper case to be able to easily detected the presence of a parameter by checking the uppercase key only .\"], \"bleu\": 0.017430653462748635, \"rouge_l\": 0.22775357809583077}\n",
      "\n",
      "{\"id\": 14391, \"code\": \"def build name registry xml parent data bsetter XML Sub Element xml parent 'org jenkinsci plugins buildnamesetter Build Name Setter' XML Sub Element bsetter 'template' text data['name']\", \"predictions\": [\"yaml: build-namesetter-name build-namesetter .\"], \"references\": [\"yaml: build-name set the name of the build requires the jenkins :jenkins-wiki:build name setter plugin <build+name+setter+plugin> .\"], \"bleu\": 0.015417996259849322, \"rouge_l\": 0.17134831460674158}\n",
      "\n",
      "{\"id\": 14445, \"code\": \"def default billship handler request order form if not request session get u'free shipping' settings clear cache set shipping request u' Flatrateshipping' settings SHOP DEFAULT SHIPPING VALUE\", \"predictions\": [\"default handler for billship .\"], \"references\": [\"default billing/shipping handler - called when the first step in the checkout process with billing/shipping address fields is submitted .\"], \"bleu\": 0.01616426370461062, \"rouge_l\": 0.21656804733727808}\n",
      "\n",
      "{\"id\": 14521, \"code\": \"def radius neighbors graph X radius mode 'connectivity' metric 'minkowski' p 2 metric params None include self False n jobs 1 if not isinstance X Radius Neighbors Mixin X Nearest Neighbors radius radius metric metric p p metric params metric params n jobs n jobs fit X else check params X metric p metric params query query include self X include self return X radius neighbors graph query radius mode\", \"predictions\": [\"evaluate radius by radius .\"], \"references\": [\"computes the graph of neighbors for points in x neighborhoods are restricted the points at a distance lower than radius .\"], \"bleu\": 0.014646027502104971, \"rouge_l\": 0.13847900113507378}\n",
      "\n",
      "{\"id\": 14564, \"code\": \"def strip named query txt if named query regex match txt txt named query regex sub '' txt return txt\", \"predictions\": [\"return the first named query and the query string .\"], \"references\": [\"this will strip \\\"save named query\\\" command in the beginning of the line: s zzz select * from abc -> select * from abc s zzz select * from abc -> select * from abc .\"], \"bleu\": 0.011773227948589666, \"rouge_l\": 0.1183699870633894}\n",
      "\n",
      "{\"id\": 14625, \"code\": \"def const expr c test expr expr const codes return eval c\", \"predictions\": [\"evaluate c_expr -> expression .\"], \"references\": [\"const -> value safe python constant evaluation evaluates a string that contains an expression describing a python constant .\"], \"bleu\": 0.019743076272439736, \"rouge_l\": 0.22620519159456118}\n",
      "\n",
      "{\"id\": 14664, \"code\": \"@never cachedef unsubscribe request hash None token None perm setting None assert hash is not None and token is not None user Nonetry email Unsubscribe Code parse token hash user User Profile objects get email email except Value Error User Profile Does Not Exist passperm settings []if user is not None unsubscribed Trueif not perm setting perm settings [l for l in notifications NOTIFICATIONS if not l mandatory ]else perm setting notifications NOTIFICATIONS BY SHORT[perm setting] User Notification update or create update {'enabled' False} user user notification id perm setting id perm settings [perm setting]else unsubscribed Falseemail ''return render request 'users/unsubscribe html' {'unsubscribed' unsubscribed 'email' email 'perm settings' perm settings}\", \"predictions\": [\"unsubscribe from a user .\"], \"references\": [\"pulled from django contrib so that we can add user into the form so then we can show relevant messages about the user .\"], \"bleu\": 0.008637296739954455, \"rouge_l\": 0.18503538928210314}\n",
      "\n",
      "{\"id\": 14678, \"code\": \"def parse process statistics statistics if statistics is None statistics DEFAULT STATISTIC Sstatistics util listify statistics statistics [ tuplize statistic for in statistics]for statistic in statistics if statistic[ 0 ] not in STATISTIC TYPES raise Exception ' Unknownstatistictypeencountered%s' % statistic[ 0 ] if statistic[ 1 ] not in PROCESS COLUMNS raise Exception ' Unknownprocesscolumnencountered%s' % statistic[ 1 ] return statistics\", \"predictions\": [\"parses a list of process statistics .\"], \"references\": [\"turn string or list of strings into list of tuples in format where stat is a value from statistic_types and resource is a value from process_columns .\"], \"bleu\": 0.01595259364508863, \"rouge_l\": 0.15954664341761116}\n",
      "\n",
      "{\"id\": 14841, \"code\": \"@ssl required@anonymous csrf@mobile template 'users/{mobile/}pw reset confirm html' def password reset confirm request template uidb 36 None token None try uid int base 36 to int uidb 36 except Value Error raise Http 404 user get object or 404 User id uid int context {}if default token generator check token user token context['validlink'] Trueif request method 'POST' form Set Password Form user request POST if form is valid form save return Http Response Redirect reverse 'users pw reset complete' else form Set Password Form None else context['validlink'] Falseform Nonecontext['form'] formreturn render request template context\", \"predictions\": [\"password reset confirm .\"], \"references\": [\"view that checks the hash in a password reset link and presents a form for entering a new password .\"], \"bleu\": 0.009306775922740032, \"rouge_l\": 0.2231707317073171}\n",
      "\n",
      "{\"id\": 14864, \"code\": \"def compare optimizers optimizers random a -1 3 + np random random size 100 random b 0 3 + np random random size 100 param grid product FUNCTIONS random a random b print ' Benching 1 Droot-finderoptimizersfromscipy optimize 'for optimizer in OPTIMIZERS print '% 20 s %8 itotalfunctioncalls' % optimizer name bench optimizer optimizer param grid\", \"predictions\": [\"compare the two optimizers .\"], \"references\": [\"compare all the optimizers given on a grid of a few different functions all admitting a signle root in zero and a upper and lower bounds .\"], \"bleu\": 0.004214743557820027, \"rouge_l\": 0.22242479489516864}\n",
      "\n",
      "{\"id\": 14869, \"code\": \"def check course access course user action check if enrolled False access response has access user action course course id if not access response raise Courseware Access Exception access response if check if enrolled if not user id and Course Enrollment is enrolled user course id or has access user 'staff' course raise User Not Enrolled course id\", \"predictions\": [\"wrapper for has_to_access_for_view .\"], \"references\": [\"check that the user has the access to perform the specified action on the course .\"], \"bleu\": 0.017888698387160718, \"rouge_l\": 0.09023668639053255}\n",
      "\n",
      "{\"id\": 14873, \"code\": \"def resolve etag is at header req metadata alternate etag Nonemetadata Header Key Dict metadata if 'X- Backend- Etag- Is- At' in req headers names list from csv req headers['X- Backend- Etag- Is- At'] for name in names if name in metadata alternate etag metadata[name]breakreturn alternate etag\", \"predictions\": [\"given an etag--value pair .\"], \"references\": [\"helper function to resolve an alternative etag value that may be stored in metadata under an alternate name .\"], \"bleu\": 0.018373002712755784, \"rouge_l\": 0.1508034610630408}\n",
      "\n",
      "{\"id\": 14878, \"code\": \"def Init Colorize output file color Falseif options options colorize is not None and curses and options options color 'yes' or options options color 'auto' and output file isatty try curses setupterm if curses tigetnum 'colors' > 0 color Trueexcept Exception passif not color return []directives []normal unicode curses tigetstr 'sgr 0 ' 'ascii' fg color unicode curses tigetstr 'setaf' or curses tigetstr 'setf' or '' 'ascii' for directive in options options colorize regexp color index directive split ' ' color unicode curses tparm fg color int color index 'ascii' directives append Color Directive re compile regexp color normal return directives\", \"predictions\": [\"initialize curses directives .\"], \"references\": [\"initializes the colorization directives via --colorize as a mapping between compiled regular expressions meant to be matched against log filename and target curses color escape codes .\"], \"bleu\": 0.001359960878556037, \"rouge_l\": 0.11380597014925373}\n",
      "\n",
      "{\"id\": 14882, \"code\": \"def handle Description Option cmd Arg Str out Dir usage Str hs Version cla Description Template File try args json loads cmd Arg Str except Exception as e raise Invalid Command Arg Exception make Usage Error Str 'JSO Nargparsingfailedfor--description %s\\\\n' + 'ARG <%s>' % str e cmd Arg Str usage Str files Description generate Experiment args out Dir hs Version hs Version cla Description Template File cla Description Template File pprint pprint files Description return\", \"predictions\": [\"handle command-line argument usage .\"], \"references\": [\"parses and validates the --description option args and executes the request parameters: cmdargstr: json string compatible with _gexperimentdescriptionschema outdir: where to place generated experiment files usagestr: program usage string hsversion: which version of hypersearch permutations file to generate .\"], \"bleu\": 0.00033651328298856827, \"rouge_l\": 0.07979071288423806}\n",
      "\n",
      "{\"id\": 14938, \"code\": \"def local align primer seq primer sequence sw scorer equality scorer ambigs query primer primerquery sequence str sequence alignment pair hmm align unaligned seqs [query primer query sequence] primer hit str alignment Seqs[ 0 ] target hit str alignment Seqs[ 1 ] insertions primer hit count '-' deletions target hit count '-' mismatches 0for i in range len target hit if sw scorer target hit[i] primer hit[i] -1 and target hit[i] '-' and primer hit[i] '-' mismatches + 1try hit start query sequence index target hit replace '-' '' except Value Error raise Value Error 'substringnotfound querystring%s target hit%s' % query sequence target hit mismatch count insertions + deletions + mismatches return mismatch count hit start\", \"predictions\": [\"compares query against primer .\"], \"references\": [\"perform local alignment of primer and sequence primer: input primer sequence sequence: target sequence to test primer against returns the number of mismatches .\"], \"bleu\": 0.007263071866110296, \"rouge_l\": 0.12335692618806875}\n",
      "\n",
      "{\"id\": 15170, \"code\": \"def memoize func func result cache {}@wraps func def memoized func *args **kwargs key args tuple sorted kwargs items if key in func result cache return func result cache[key]else result func *args **kwargs if isinstance result Generator Type or not isinstance result Hashable raise Type Error \\\" Can'tmemoizeageneratorornon-hashableobject \\\" func result cache[key] resultreturn resultreturn memoized func\", \"predictions\": [\"memoize decorator .\"], \"references\": [\"decorator to cause a function to cache its results for each combination of inputs and return the cached result on subsequent calls .\"], \"bleu\": 0.0007567125856731294, \"rouge_l\": 0.13510520487264674}\n",
      "\n",
      "{\"id\": 15194, \"code\": \"def rundeck registry xml parent data p XML Sub Element xml parent 'org jenkinsci plugins rundeck Rundeck Notifier' mappings [ 'job-id' 'job Id' None 'options' 'options' '' 'node-filters' 'node Filters' '' 'tag' 'tag' '' 'wait-for-rundeck' 'should Wait For Rundeck Job' False 'fail-the-build' 'should Fail The Build' False ]helpers convert mapping to xml p data mappings fail required True\", \"predictions\": [\"yaml: rundeckeckeckeckeckeckeckeckeckeckeckecke\"], \"references\": [\"yaml: rundeck trigger a rundeck job when the build is complete .\"], \"bleu\": 0.005119732577934196, \"rouge_l\": 0.12655601659751037}\n",
      "\n",
      "{\"id\": 15224, \"code\": \"def build national number for parsing number index of phone context number find RFC 3966 PHONE CONTEXT if index of phone context > 0 phone context start index of phone context + len RFC 3966 PHONE CONTEXT if number[phone context start] PLUS SIGN phone context end number find U SEMICOLON phone context start if phone context end > 0 national number number[phone context start phone context end]else national number number[phone context start ]else national number U EMPTY STRIN Gindex of rfc 3996 prefix number find RFC 3966 PREFIX index of national number index of rfc 3996 prefix + len RFC 3966 PREFIX if index of rfc 3996 prefix > 0 else 0 national number + number[index of national number index of phone context]else national number extract possible number number index of isdn national number find RFC 3966 ISDN SUBADDRESS if index of isdn > 0 national number national number[ index of isdn]return national number\", \"predictions\": [\"construct a national number from the phone number .\"], \"references\": [\"converts number to a form that we can parse and return it if it is written in rfc3966; otherwise extract a possible number out of it and return it .\"], \"bleu\": 0.017210008144936065, \"rouge_l\": 0.14022988505747128}\n",
      "\n",
      "{\"id\": 15231, \"code\": \"def register send self print ' Sending Local Registration'notifications []default Notifications []for notice in self notifications notifications append notice[' Notification- Name'] if notice get ' Notification- Enabled' True default Notifications append notice[' Notification- Name'] app Icon get resource self ' Application- Icon' growl Growl Growl Notifier application Name self headers[' Application- Name'] notifications notifications default Notifications default Notifications application Icon app Icon growl register return self encode\", \"predictions\": [\"user-call notification .\"], \"references\": [\"resend a gntp register message to growl running on a local osx machine .\"], \"bleu\": 0.013733827497510927, \"rouge_l\": 0.10535405872193437}\n",
      "\n",
      "{\"id\": 15274, \"code\": \"def compute log ais weights batch size free energy fn sample fn betas log ais w numpy zeros batch size dtype float X for i in range len betas - 1 bp bp 1 betas[i] betas[ i + 1 ] log ais w + free energy fn bp - free energy fn bp 1 sample fn bp 1 if i % 1000 0 0 logging info ' Temperature%f' % bp 1 return log ais w\", \"predictions\": [\"compute log-likelihood function .\"], \"references\": [\"compute log of the ais weights parameters batch_size : scalar size of a batch of samples free_energy_fn : theano .\"], \"bleu\": 0.0072829457434388815, \"rouge_l\": 0.14878048780487804}\n",
      "\n",
      "{\"id\": 15278, \"code\": \"def test init with header original header fits Header [ 'a' 10 ] new header fits Header original header copy True original header['a'] 20 assert new header['a'] 10 new header['a'] 0assert original header['a'] 20\", \"predictions\": [\"test init_header .\"], \"references\": [\"make sure that creating a header from another header makes a copy if copy is true .\"], \"bleu\": 0.005052392784929312, \"rouge_l\": 0.08879184861717612}\n",
      "\n",
      "{\"id\": 15391, \"code\": \"def update configuration schema schema default update configuration schema for plugin in plugins Plugin Implementations plugins I Configurer if hasattr plugin 'update config schema' schema plugin update config schema schema return schema\", \"predictions\": [\"update the configuration schema .\"], \"references\": [\"returns the schema for the config options that can be edited during runtime by default these are the keys of the :py:func:ckan .\"], \"bleu\": 0.00887113600998264, \"rouge_l\": 0.19202518363064006}\n",
      "\n",
      "{\"id\": 15584, \"code\": \"def ppcc max x brack 0 0 1 0 dist 'tukeylambda' dist parse dist kw dist osm uniform calc uniform order statistic medians len x osr sort x def tempfunc shape mi yvals func xvals func mi shape r prob stats pearsonr xvals yvals return 1 - r return optimize brent tempfunc brack brack args osm uniform osr dist ppf\", \"predictions\": [\"calculate the maxians of a given distribution .\"], \"references\": [\"calculate the shape parameter that maximizes the ppcc the probability plot correlation coefficient plot can be used to determine the optimal shape parameter for a one-parameter family of distributions .\"], \"bleu\": 0.016045011753648093, \"rouge_l\": 0.190625}\n",
      "\n",
      "{\"id\": 15597, \"code\": \"def request user has resource api permission permission type def decorate func function name func name if function name not in ['post'] raise Exception ' Thisdecoratorshouldonlybeusedtowrappostmethods' @wraps func def func wrapper *args **kwargs resource api args[ 1 ]utils assert request user has resource api permission request pecan request resource api resource api permission type permission type return func *args **kwargs return func wrapperreturn decorate\", \"predictions\": [\"a decorator to require a resource .\"], \"references\": [\"a decorator meant to wrap post pecan rest controller methods this decorator assumes the first argument passed to the decorated function is a resource api object .\"], \"bleu\": 0.019203753662310582, \"rouge_l\": 0.3190932868352223}\n",
      "\n",
      "{\"id\": 15600, \"code\": \"def de dupe version table apps schema editor db alias schema editor connection alias Version apps get model u'reversion' u' Version' keep version ids Version objects using db alias order by values list u'revision id' u'content type id' u'object id' annotate max pk models Max u'pk' values list u'max pk' flat True if keep version ids count Version objects using db alias all count returndelete version ids list Version objects using db alias exclude pk in keep version ids values list u'pk' flat True Version objects using db alias filter pk in delete version ids delete\", \"predictions\": [\"deletes version of the version table .\"], \"references\": [\"removes some duplicate version models that may have crept into the database and will prevent the unique index being added by migration 0004 .\"], \"bleu\": 0.019474777613022468, \"rouge_l\": 0.17613089509143406}\n",
      "\n",
      "{\"id\": 15609, \"code\": \"def rm rf name if not os path exists name returntry shutil rmtree name except OS Error as e if e errno errno ENOTDIR safe delete name elif e errno errno ENOENT raise\", \"predictions\": [\"remove directory .\"], \"references\": [\"remove a file or a directory similarly to running rm -rf <name> in a unix shell .\"], \"bleu\": 0.0060083414476263496, \"rouge_l\": 0.2663755458515284}\n",
      "\n",
      "{\"id\": 15613, \"code\": \"def to encodable string obj encoding if isinstance obj Data Token obj obj get value if isinstance obj unicode obj obj encode encoding errors 'ignore' else obj str obj return obj\", \"predictions\": [\"converts a string to an encoder .\"], \"references\": [\"this makes an extra effort to return a string which can be url-encoded from an object that can be one of: * byte-string * unicode * datatoken and in all cases it might have invalid encoding .\"], \"bleu\": 0.004001344331835448, \"rouge_l\": 0.16191108161911083}\n",
      "\n",
      "{\"id\": 15819, \"code\": \"def run script usage tests test data dir scripts dir working dir verbose False tests None force overwrite False timeout 60 working dir join working dir 'script usage tests' logger Noneif verbose logger sys stdoutscript tester Script Tester logger logger script tester scripts dir test data dir working dir scripts tests timeout timeout force overwrite force overwrite result summary script tester result summary has failures or errors script tester has failures or errors if exists working dir rmtree working dir return result summary has failures or errors\", \"predictions\": [\"run the script tests .\"], \"references\": [\"test script_usage examples when test data is present in test_data_dir returns a result summary string and a boolean indicating whether there were any errors or failures while running the commands .\"], \"bleu\": 0.0016667612018820286, \"rouge_l\": 0.0983078162771958}\n",
      "\n",
      "{\"id\": 15855, \"code\": \"def power state vm state force power status vm get status check status '' join state split ' ' upper if not force and power status in ['SUSPENDED' 'POWERINGON' 'RESETTING' 'BLOCKEDONMSG'] return 'V Misin%spowerstate Forceisrequired ' % power status if power status check status return Falseelse try if state 'powered off' vm power off sync run True elif state 'powered on' vm power on sync run True elif state 'restarted' if power status in 'POWEREDON' 'POWERINGON' 'RESETTING' vm reset sync run False else return ' Cannotrestart V Minthecurrentstate%s' % power status return Trueexcept Exception return get exception return False\", \"predictions\": [\"check vm state .\"], \"references\": [\"correctly set the power status for a vm determined by the current and requested states .\"], \"bleu\": 0.019797099072043068, \"rouge_l\": 0.1804733727810651}\n",
      "\n",
      "{\"id\": 15873, \"code\": \"def verify webhook signature body public key utils ['http query'] 'https //api travis-ci org/config' ['config']['notifications']['webhook']['public key']pkey public key Open SSL crypto load publickey Open SSL crypto FILETYPE PEM public key certificate Open SSL crypto X509 certificate set pubkey pkey public key signature base 64 b64 decode signature payload json loads parse qs body ['payload'][ 0 ] try Open SSL crypto verify certificate signature payload str 'sha 1 ' except Open SSL crypto Error return Falsereturn True\", \"predictions\": [\"verify a webhook .\"], \"references\": [\"verify the webhook signature from travisci signature the signature header from the webhook header body the full payload body from the webhook post .\"], \"bleu\": 0.002879037202495718, \"rouge_l\": 0.18983402489626555}\n",
      "\n",
      "{\"id\": 15909, \"code\": \"def remove unicode encoding xml file with open xml file 'rb' as f xml content f read modified xml re sub 'encoding [\\\\\\\\\\\\'\\\"]+unicode[\\\\\\\\\\\\'\\\"]+' '' xml content decode 'utf- 16 ' count 1 xmltree lxml etree parse String IO modified xml return xmltree\", \"predictions\": [\"remove unicode encoding from xml .\"], \"references\": [\"attempts to remove the \\\"encoding=unicode\\\" from an xml file as lxml does not support that on a windows node currently see issue #38100 .\"], \"bleu\": 0.013828950874622525, \"rouge_l\": 0.24063116370808674}\n",
      "\n",
      "{\"id\": 15952, \"code\": \"def n colors lowcolor highcolor n colors diff 0 float highcolor[ 0 ] - lowcolor[ 0 ] incr 0 diff 0 / n colors - 1 diff 1 float highcolor[ 1 ] - lowcolor[ 1 ] incr 1 diff 1 / n colors - 1 diff 2 float highcolor[ 2 ] - lowcolor[ 2 ] incr 2 diff 2 / n colors - 1 color tuples []for index in range n colors new tuple lowcolor[ 0 ] + index * incr 0 lowcolor[ 1 ] + index * incr 1 lowcolor[ 2 ] + index * incr 2 color tuples append new tuple return color tuples\", \"predictions\": [\"return a tuple containing the number of n colors .\"], \"references\": [\"splits a low and high color into a list of n_colors colors in it accepts two color tuples and returns a list of n_colors colors which form the intermediate colors between lowcolor and highcolor from linearly interpolating through rgb space .\"], \"bleu\": 0.0074738370239103655, \"rouge_l\": 0.1413673232908459}\n",
      "\n",
      "{\"id\": 15958, \"code\": \"def download setuptools version DEFAULT VERSION download base DEFAULT URL to dir os curdir delay 15 to dir os path abspath to dir try from urllib request import urlopenexcept Import Error from urllib 2 import urlopentgz name 'distribute-%s tar gz' % version url download base + tgz name saveto os path join to dir tgz name src dst Noneif not os path exists saveto try log warn ' Downloading%s' url src urlopen url data src read dst open saveto 'wb' dst write data finally if src src close if dst dst close return os path realpath saveto\", \"predictions\": [\"downloads a setuptools version of the given setuptools package .\"], \"references\": [\"download distribute from a specified location and return its filename version should be a valid distribute version number that is available as an egg for download under the download_base url .\"], \"bleu\": 0.01941077134364101, \"rouge_l\": 0.17862371888726208}\n",
      "\n",
      "{\"id\": 15959, \"code\": \"@statfuncdef quantiles x qlist 2 5 25 50 75 97 5 transform lambda x x x transform x copy if x ndim > 1 sx np sort x T Telse sx np sort x try quants [sx[int len sx * q / 100 0 ] for q in qlist]return dict zip qlist quants except Index Error log warning ' Toofewelementsforquantilecalculation'\", \"predictions\": [\"calculate the sample quantiles of the input data .\"], \"references\": [\"returns a dictionary of requested quantiles from array :arguments: x : numpy array an array containing mcmc samples qlist : tuple or list a list of desired quantiles (defaults to ) transform : callable function to transform data .\"], \"bleu\": 0.007529117812929203, \"rouge_l\": 0.1497851442602824}\n",
      "\n",
      "{\"id\": 16003, \"code\": \"def write With Attribute Escaping write def write data write escape For Content data replace '\\\"' '&quot ' return write\", \"predictions\": [\"write the xml .\"], \"references\": [\"decorate a c{write} callable so that all output written is properly quoted for inclusion within an xml attribute value .\"], \"bleu\": 0.0072829457434388815, \"rouge_l\": 0.14878048780487804}\n",
      "\n",
      "{\"id\": 16006, \"code\": \"def int or true div x discrete y discrete if x discrete and y discrete if config int division 'raise' raise Integer Division Error \\\" With`config int division`setto'raise' dividingtwointegertypeswith'/'isforbiddentoavoidconfusionbetweenintegerandfloatingpointdivisions Pleaseuse//forintegerdivision orifyouwantafloatresulteithercastoneoftheargumentstoafloatordirectlycall`x truediv y ` \\\" elif config int division 'int' warnings warn ' Divisionoftwointegertypeswithx/yisdeprecated pleaseusex//yforanintegerdivision ' Deprecation Warning stacklevel 4 return int divelif config int division 'float X' return true divelse raise Not Implemented Error config int division else return true div\", \"predictions\": [\"helper for true_div_div_divator .\"], \"references\": [\"return int or true depending on the type of division used for x / y .\"], \"bleu\": 0.019797099072043068, \"rouge_l\": 0.1804733727810651}\n",
      "\n",
      "{\"id\": 16015, \"code\": \"def sysctl cmdline result sh 'sysctl' + cmdline if FREEBSD result result[ result find ' ' + 2 ]elif OPENBSD or NETBSD result result[ result find ' ' + 1 ]try return int result except Value Error return result\", \"predictions\": [\"parse sysctl parameter .\"], \"references\": [\"expects a sysctl command with an argument and parse the result returning only the value of interest .\"], \"bleu\": 0.012902949563521738, \"rouge_l\": 0.16310160427807485}\n",
      "\n",
      "{\"id\": 16022, \"code\": \"def extract issues logs issues ISSUE REGEX findall '' join [log message for log in logs] links { ISSUE URL FORMAT STRING % issue for issue in issues}return links\", \"predictions\": [\"extract issues from the given issues .\"], \"references\": [\"extract references to issues out of a list of logs args: logs : list of logs to parse returns: set[str]: set of found issues as links to github .\"], \"bleu\": 0.010080676224270477, \"rouge_l\": 0.20016406890894176}\n",
      "\n",
      "{\"id\": 16153, \"code\": \"@timer timeddef identity *args **kwargs return args kwargs\", \"predictions\": [\"timeddefer .\"], \"references\": [\"an identity function used as a default task to test the timing of .\"], \"bleu\": 0.00188344435971766, \"rouge_l\": 0.11010830324909747}\n",
      "\n",
      "{\"id\": 16174, \"code\": \"def gen preprocess options macros include dirs pp opts []for macro in macros if not isinstance macro tuple and 1 < len macro < 2 raise Type Error \\\"badmacrodefinition'%s' eachelementof'macros'listmustbea 1 -or 2 -tuple\\\" % macro if len macro 1 pp opts append '-U%s' % macro[ 0 ] elif len macro 2 if macro[ 1 ] is None pp opts append '-D%s' % macro[ 0 ] else pp opts append '-D%s %s' % macro for dir in include dirs pp opts append '-I%s' % dir return pp opts\", \"predictions\": [\"generate c preprocessor options .\"], \"references\": [\"generate c pre-processor options as used by at least two types of compilers: the typical unix compiler and visual c++ .\"], \"bleu\": 0.016641100089707282, \"rouge_l\": 0.27695800227014755}\n",
      "\n",
      "{\"id\": 16178, \"code\": \"def open file filename filename filename or 'subunit bin' return open filename 'wb'\", \"predictions\": [\"open a file .\"], \"references\": [\"open a subunit file this is not a context manager because it is used asynchronously by hooks out of the scope of enable() because we want to patch it in our tests .\"], \"bleu\": 0.00038156602230068177, \"rouge_l\": 0.1894409937888199}\n",
      "\n",
      "{\"id\": 16266, \"code\": \"def test nonexistent extra warns user with wheel script data result script pip 'install' '--no-index' '--find-links ' + data find links 'simplewheel[nonexistent]' expect stderr True assert \\\"simplewheel 2 0doesnotprovidetheextra'nonexistent'\\\" in result stderr\", \"predictions\": [\"test nonexistent extra details .\"], \"references\": [\"a warning is logged telling the user that the extra option they requested does not exist in the project they are wishing to install .\"], \"bleu\": 0.005533842072529231, \"rouge_l\": 0.11902439024390245}\n",
      "\n",
      "{\"id\": 16371, \"code\": \"def register access role cls try role name cls ROLEREGISTERED ACCESS ROLES[role name] clsexcept Attribute Error log exception u\\\" Unabletoregister Access Rolewithattribute'ROLE' \\\" return cls\", \"predictions\": [\"register an access role .\"], \"references\": [\"decorator that allows access roles to be registered within the roles module and referenced by their string values .\"], \"bleu\": 0.018373002712755784, \"rouge_l\": 0.1508034610630408}\n",
      "\n",
      "{\"id\": 16389, \"code\": \"def test notation regexp pattern re compile SCIENTIFIC NOTATION REGEXP matches [' 1 e 3 ' '1 E4 ' '- 1 e- 3 ' '2 3e+ 4 ' ' 2e 4 ']fails ['string' '4 ' '2 1' '1 2e 3 2' ' e4 ' 'a 3 e 4 ']for match in matches assert pattern match match for fail in fails assert not pattern match fail\", \"predictions\": [\"test regular regexp .\"], \"references\": [\"tests for regular expression aiming to filter scientific notations which are not correctly parsed as floats by yaml .\"], \"bleu\": 0.009351487442933324, \"rouge_l\": 0.15561224489795916}\n",
      "\n",
      "{\"id\": 16515, \"code\": \"def get exception for uncaught api error func exc if isinstance exc mongoengine Validation Error result webob exc HTTP Bad Request detail exc message return resultelif isinstance exc jsonschema Validation Error result webob exc HTTP Bad Request detail exc message return resultreturn exc\", \"predictions\": [\"return the exception for a mongodb api .\"], \"references\": [\"utility function which tries to map an uncaught exception throwed inside an api to a more user-friendly exception which is returned instead of returning internal server error .\"], \"bleu\": 0.01655239530492347, \"rouge_l\": 0.15149006622516556}\n",
      "\n",
      "{\"id\": 16590, \"code\": \"def get tool path by shed tool conf filename app shed tool conf for shed tool conf dict in app toolbox dynamic confs include migrated tool conf True config filename shed tool conf dict['config filename']if config filename shed tool conf return shed tool conf dict['tool path']else file name basic util strip path config filename if file name shed tool conf return shed tool conf dict['tool path']return None\", \"predictions\": [\"look for shed-related tool path .\"], \"references\": [\"return the tool_path config setting for the received shed_tool_conf file by searching the tool boxs in-memory list of shed_tool_confs for the dictionary whose config_filename key has a value matching the received shed_tool_conf .\"], \"bleu\": 0.0029182332923432435, \"rouge_l\": 0.1367713004484305}\n",
      "\n",
      "{\"id\": 16724, \"code\": \"@task queue 'web' time limit EMAIL TIME LIMIT def send email task recipient subject template template html context None msg Email Multi Alternatives subject get template template render context settings DEFAULT FROM EMAIL [recipient] try msg attach alternative get template template html render context 'text/html' except Template Does Not Exist passmsg send log info ' Sentemailtorecipient %s' recipient\", \"predictions\": [\"send email to tasks .\"], \"references\": [\"send multipart email recipient email recipient address subject email subject header template plain text template to send template_html html template to send as new message part context a dictionary to pass into the template calls .\"], \"bleu\": 0.0006966924242467454, \"rouge_l\": 0.1717100633356791}\n",
      "\n",
      "{\"id\": 16842, \"code\": \"def publish file token room filepath message '' api url None if not os path isfile filepath raise Value Error \\\" File'{ 0 }'doesnotexist\\\" format filepath if len message > 1000 raise Value Error ' Messagetoolong' url '{ 0 }/v 2 /room/{ 1 }/share/file' format api url room headers {' Content-type' 'multipart/related boundary boundary 123456 '}headers[' Authorization'] ' Bearer' + token msg json dumps {'message' message} payload '--boundary 123456 \\\\n Content- Type application/json charset UTF- 8 \\\\n Content- Disposition attachment name \\\"metadata\\\"\\\\n\\\\n{ 0 }\\\\n\\\\n--boundary 123456 \\\\n Content- Disposition attachment name \\\"file\\\" filename \\\"{ 1 }\\\"\\\\n\\\\n{ 2 }\\\\n\\\\n--boundary 123456 --' format msg os path basename filepath open filepath 'rb' read salt utils http query url method 'POST' header dict headers data payload\", \"predictions\": [\"publish a file file to a room .\"], \"references\": [\"send file to a hipchat room via api version 2 parameters token : str hipchat api version 2 compatible token - must be token for active user room: str name or api id of the room to notify filepath: str full path of file to be sent message: str .\"], \"bleu\": 0.001801444330946982, \"rouge_l\": 0.15250000000000002}\n",
      "\n",
      "{\"id\": 16986, \"code\": \"def db Validator fileused get File Used host Configuration get 'nupic cluster database host' port int Configuration get 'nupic cluster database port' user Configuration get 'nupic cluster database user' passwd '*' * len Configuration get 'nupic cluster database passwd' print ' Thisscriptwillvalidatethatyour My SQ Lissetupcorrectlyfor'print ' Nu PIC My SQ Lisrequiredfor Nu PI Cswarming Thesettingsare'print 'definedinaconfigurationfilefoundin'print '$NUPIC/src/nupic/support/nupic-default xml Outoftheboxthose'print \\\"settingscontain My SQL'sdefaultaccesscredentials \\\"printprint ' Thenupic-default xmlcanbeduplicatedtodefineuserspecific'print 'changescallingthecopiedfile'print '$NUPIC/src/nupic/support/nupic-site xml Refertothe'print 'nupic-default xmlforadditionalinstructions 'printprint ' Defaults localhost 3306 root nopassword'printprint ' Retrievedthefollowing Nu PI Cconfigurationusing ' fileusedprint 'host ' hostprint 'port ' portprint 'user ' userprint 'passwd ' passwdif test Db Connection host port user passwd print ' Connectionsuccessful 'else print \\\" Couldn'tconnecttothedatabaseoryoudon'thavethepermissionsrequiredtocreatedatabasesandtables Pleaseensureyouhave My SQL\\\\ninstalled running accessibleusingthe Nu PI Cconfigurationsettings andtheuserspecifiedhaspermissiontocreatebothdatabasesandtables \\\"\", \"predictions\": [\"this function generates the validator database .\"], \"references\": [\"let the user know what nupic config file is being used and whether or not they have mysql set up correctly for swarming .\"], \"bleu\": 0.018123322676611493, \"rouge_l\": 0.11742059672762271}\n",
      "\n",
      "{\"id\": 16992, \"code\": \"def allow new attributes f def decorated self *args **kw ' Thedecoratedfunctionthatreplaces init or setstate \\\\n\\\\n'if not hasattr self ' can Add Attributes' self dict [' can Add Attributes'] 1else self can Add Attributes + 1assert self can Add Attributes > 1 count self can Add Attributesf self *args **kw if hasattr self ' can Add Attributes' self can Add Attributes - 1else self can Add Attributes count - 1 assert self can Add Attributes > 0 if self can Add Attributes 0 del self can Add Attributesdecorated doc f doc decorated name f name return decorated\", \"predictions\": [\"decorator to require new attributes .\"], \"references\": [\"a decorator that maintains the attribute lock state of an object it coperates with the lockattributesmetaclass that replaces the __setattr__ method with a custom one that checks the _canaddattributes counter and allows setting new attributes only if _canaddattributes > 0 .\"], \"bleu\": 0.0009672655064374154, \"rouge_l\": 0.15006150061500614}\n",
      "\n",
      "{\"id\": 17016, \"code\": \"def updatedb dt meta None res frappe db sql u'selectissinglefromtab Doc Typewherename %s' dt if not res raise Exception u' Wrongdoctype\\\"%s\\\"inupdatedb' % dt if not res[ 0 ][ 0 ] tab Db Table dt u'tab' meta tab validate frappe db commit tab sync frappe db begin\", \"predictions\": [\"update db .\"], \"references\": [\"syncs a doctype to the table * creates if required * updates columns * updates indices .\"], \"bleu\": 0.005052392784929312, \"rouge_l\": 0.08879184861717612}\n",
      "\n",
      "{\"id\": 17032, \"code\": \"def shrink tensor x w return x[tuple [slice w - w ] * x ndim ]\", \"predictions\": [\"returns a wsensor tensor .\"], \"references\": [\"x : a theano tensortype variable w : a theano integer scalar returns: y: a theano tensortype variable containing all but the borders of x .\"], \"bleu\": 0.00453072668745648, \"rouge_l\": 0.11498586239396796}\n",
      "\n",
      "{\"id\": 17083, \"code\": \"def cov nw groupsum results nlags time weights func weights bartlett use correction 0 xu hessian inv get sandwich arrays results S hac S hac groupsum xu time nlags nlags weights func weights func cov hac HCCM 2 hessian inv S hac if use correction nobs k params xu shapeif use correction 'hac' cov hac * nobs / float nobs - k params elif use correction in ['c' 'cluster'] n groups len np unique time cov hac * n groups / n groups - 1 0 cov hac * nobs - 1 0 / float nobs - k params return cov hac\", \"predictions\": [\"see statsmodels .\"], \"references\": [\"driscoll and kraay panel robust covariance matrix robust covariance matrix for panel data of driscoll and kraay .\"], \"bleu\": 0.003620197623718955, \"rouge_l\": 0.08437067773167356}\n",
      "\n",
      "{\"id\": 17110, \"code\": \"def prepare fsdev job global FSDEV JO Bglobal FSDEV DISKLIS Tglobal FSDEV PREP CN Tif not FSDEV FS DESC return None None FSDEV PREP CNT + 1if FSDEV PREP CNT > 1 return FSDEV DISKLIST[ 0 ]['mountpt'] FSDEV DISKLIST FSDEV JOB job path toss disks prepare disks job fs desc FSDEV FS DESC disk 1 only FSDEV DISK 1 ONLY disk list None FSDEV DISKLIST disksreturn path disks\", \"predictions\": [\"prepare the fsdev distribution .\"], \"references\": [\"called from the test file to get the necessary drive(s) ready; return a pair of values: the absolute path to the first drives mount point plus the complete disk list .\"], \"bleu\": 0.0016667612018820286, \"rouge_l\": 0.0983078162771958}\n",
      "\n",
      "{\"id\": 17175, \"code\": \"def gen cosine amp amp 100 period 1000 x0 0 xn 50000 step 1 k 0 0001 cos np zeros xn - x0 * step 1 1 for i in range len cos idx x0 + i * step cos[ i 0 0 ] amp * np cos 2 * np pi * idx / period cos[ i 0 0 ] cos[ i 0 0 ] * np exp - k * idx return cos\", \"predictions\": [\"generate cosine transform .\"], \"references\": [\"generates an absolute cosine time series with the amplitude exponentially decreasing arguments: amp: amplitude of the cosine function period: period of the cosine function x0: initial x of the time series xn: final x of the time series step: step of the time series discretization k: exponential rate .\"], \"bleu\": 5.1721615423201436e-06, \"rouge_l\": 0.06545064377682402}\n",
      "\n",
      "{\"id\": 17188, \"code\": \"def tamper payload **kwargs headers kwargs get 'headers' {} headers['X-originating-IP'] '127 0 0 1'return payload\", \"predictions\": [\"adds an http header to a wsgi-hack-forward-enper-hack tamper-hack tamening inverse .\"], \"references\": [\"append a http header x-originating-ip to bypass waf protection of varnish firewall notes: reference: URL examples: >> x-forwarded-for: target_cacheserver_ip >> x-remote-ip: target_proxy_ip >> x-originating-ip: target_local_ip >> x-remote-addr: target_internaluser_ip >> x-remote-ip: * or %00 or %0a .\"], \"bleu\": 0.01836784847078841, \"rouge_l\": 0.15531508593252702}\n",
      "\n",
      "{\"id\": 17266, \"code\": \"def kendall tau worder normalize True worder len len worder increasing sequences find increasing sequences worder num increasing pairs sum choose len seq 2 for seq in increasing sequences num possible pairs choose worder len 2 tau 2 * num increasing pairs / num possible pairs - 1 if normalize return tau + 1 / 2 else return tau\", \"predictions\": [\"kendall algorithm .\"], \"references\": [\"calculates the kendalls tau correlation coefficient given the *worder* list of word alignments from word_rank_alignment() .\"], \"bleu\": 0.007051182147062658, \"rouge_l\": 0.09370199692780337}\n",
      "\n",
      "{\"id\": 17354, \"code\": \"def report error error exc info request None extra data None level None if HAS ROLLBAR and hasattr settings u'ROLLBAR' rollbar report exc info exc info request extra data extra data level level LOGGER error u' Handledexception%s %s' error class name force text error encode u'utf- 8 ' if sys argv[ 1 2] [u'test'] traceback print exc\", \"predictions\": [\"report error for the given error .\"], \"references\": [\"wrapper for error reporting this can be used for store exceptions in error reporting solutions as rollbar while handling error gracefully and giving user cleaner message .\"], \"bleu\": 0.013414478810154213, \"rouge_l\": 0.2127288578901482}\n",
      "\n",
      "{\"id\": 17419, \"code\": \"def rounded num precision 0 precision cint precision multiplier 10 ** precision num round num * multiplier if precision else num 8 floor math floor num decimal part num - floor if not precision and decimal part 0 5 num floor if floor % 2 0 else floor + 1 else num round num return num / multiplier if precision else num\", \"predictions\": [\"round a number .\"], \"references\": [\"round method for round halfs to nearest even algorithm aka bankers rounding - compatible with python3 .\"], \"bleu\": 0.015417996259849322, \"rouge_l\": 0.17134831460674158}\n",
      "\n",
      "{\"id\": 17465, \"code\": \"def censor non alphanum s def censor ch if ch > 'A' and ch < 'z' or ch > '0 ' and ch < '9 ' return chreturn '*'return '' join censor ch for ch in s\", \"predictions\": [\"avoid non-alphanumeric characters .\"], \"references\": [\"returns s with all non-alphanumeric characters replaced with * parameters s : str the string to be censored .\"], \"bleu\": 0.01195013683221571, \"rouge_l\": 0.23341836734693874}\n",
      "\n",
      "{\"id\": 17528, \"code\": \"def make colorscale colors scale None colorscale []if len colors < 2 raise exceptions Plotly Error ' Youmustinputalistofcolorsthathasatleasttwocolors ' if scale is None scale incr 1 0 / len colors - 1 return [[ i * scale incr color] for i color in enumerate colors ]else if len colors len scale raise exceptions Plotly Error ' Thelengthofcolorsandscalemustbethesame ' validate scale values scale colorscale [list tup for tup in zip scale colors ]return colorscale\", \"predictions\": [\"given a list of colors .\"], \"references\": [\"makes a colorscale from a list of colors and a scale takes a list of colors and scales and constructs a colorscale based on the colors in sequential order .\"], \"bleu\": 0.011785360562036348, \"rouge_l\": 0.2479674796747967}\n",
      "\n",
      "{\"id\": 17609, \"code\": \"def configure proxy proxyname start True changes new []changes old []status file Truetest opts ['test']proxyfile '/etc/salt/proxy' status file msg new msg old proxy conf file proxyfile test changes new extend msg new changes old extend msg old status proc Falseif start status proc msg new msg old proxy process proxyname test changes old extend msg old changes new extend msg new else changes old append ' Startis False notstartingsalt-proxyprocess' log debug ' Processnotstarted' return {'result' status file and status proc 'changes' {'old' '\\\\n' join changes old 'new' '\\\\n' join changes new }}\", \"predictions\": [\"configure proxy process if start_proxy is present .\"], \"references\": [\"create the salt proxy file and start the proxy process if required parameters: proxyname: name to be used for this proxy start: boolean indicating if the process should be started default = true cli example: .\"], \"bleu\": 0.009530247520250274, \"rouge_l\": 0.16310160427807485}\n",
      "\n",
      "{\"id\": 17654, \"code\": \"def escape backslashes data jinja env if '\\\\\\\\' in data and '{{' in data new data []d 2 jinja env preprocess data in var Falsefor token in jinja env lex d2 if token[ 1 ] 'variable begin' in var Truenew data append token[ 2 ] elif token[ 1 ] 'variable end' in var Falsenew data append token[ 2 ] elif in var and token[ 1 ] 'string' new data append token[ 2 ] replace '\\\\\\\\' '\\\\\\\\\\\\\\\\' else new data append token[ 2 ] data '' join new data return data\", \"predictions\": [\"escape backslashes and remove backslashes .\"], \"references\": [\"double backslashes within jinja2 expressions a user may enter something like this in a playbook:: debug: msg: \\\"test case 13; {{ test1_name | regex_replace(^_name$ .\"], \"bleu\": 0.010302547672789446, \"rouge_l\": 0.11619047619047619}\n",
      "\n",
      "{\"id\": 17813, \"code\": \"def auth u p global user passworduser upassword p\", \"predictions\": [\"authenticate using current user .\"], \"references\": [\"set the username and password to be used in subsequent queries to the musicbrainz xml api that require authentication .\"], \"bleu\": 0.0135924714044228, \"rouge_l\": 0.07218934911242604}\n",
      "\n",
      "{\"id\": 17821, \"code\": \"def weighted choice choices values weights zip *choices total 0cum weights []for w in weights total + wcum weights append total x random uniform 0 total i bisect bisect cum weights x return values[i]\", \"predictions\": [\"given an item .\"], \"references\": [\"returns a value from choices chosen by weighted random selection choices should be a list of tuples .\"], \"bleu\": 0.010850044034164912, \"rouge_l\": 0.08155080213903743}\n",
      "\n",
      "{\"id\": 17866, \"code\": \"def to marshallable type obj if obj is None return Noneif hasattr obj ' marshallable ' return obj marshallable if hasattr obj ' getitem ' return objreturn dict obj dict\", \"predictions\": [\"given an object .\"], \"references\": [\"helper for converting an object to a dictionary only if it is not dictionary already or an indexable object nor a simple type .\"], \"bleu\": 0.003423771525565438, \"rouge_l\": 0.18983402489626555}\n",
      "\n",
      "{\"id\": 17892, \"code\": \"def find vpc module vpc conn vpc id None cidr None if vpc id None and cidr None module fail json msg ' Youmustspecifyeitheravpc idoracidrblock+listofuniquetags aborting' found vpcs []resource tags module params get 'resource tags' if vpc id is not None found vpcs vpc conn get all vpcs None {'vpc-id' vpc id 'state' 'available'} else previous vpcs vpc conn get all vpcs None {'cidr' cidr 'state' 'available'} for vpc in previous vpcs vpc tags dict t name t value for t in vpc conn get all tags filters {'resource-id' vpc id} if resource tags and set resource tags items issubset set vpc tags items found vpcs append vpc found vpc Noneif len found vpcs 1 found vpc found vpcs[ 0 ]if len found vpcs > 1 module fail json msg ' Foundmorethanonevpcbasedonthesuppliedcriteria aborting' return found vpc\", \"predictions\": [\"find the vpc and return a vpc object .\"], \"references\": [\"finds a vpc that matches a specific id or cidr + tags module : ansiblemodule object vpc_conn: authenticated vpcconnection connection object returns: a vpc object that matches either an id or cidr and one or more tag values .\"], \"bleu\": 0.010778452582485743, \"rouge_l\": 0.18723143032535294}\n",
      "\n",
      "{\"id\": 17921, \"code\": \"def format content password salt encrypt True if not encrypt and not salt return passwordassert salt ' format contentwascalledwithencryptionrequestedbutnosaltvalue'return u'%ssalt %s' % password salt\", \"predictions\": [\"formats content to be used with the given salt .\"], \"references\": [\"format the password and salt for saving :arg password: the plaintext password to save :arg salt: the salt to use when encrypting a password :arg encrypt: whether the user requests that this password is encrypted .\"], \"bleu\": 0.011773227948589666, \"rouge_l\": 0.15782664941785254}\n",
      "\n",
      "{\"id\": 17994, \"code\": \"def list catalogs results 30 start 0 result util callm '%s/%s' % 'catalog' 'list' {'results' results 'start' start} cats [ Catalog **util fix d for d in result['response']['catalogs']]start result['response']['start']total result['response']['total']return Result List cats start total\", \"predictions\": [\"list the catalogs .\"], \"references\": [\"returns list of all catalogs created on this api key args: kwargs: results : an integer number of results to return start : an integer starting value for the result set returns: a list of catalog objects example: .\"], \"bleu\": 7.159298543463193e-05, \"rouge_l\": 0.12167553191489362}\n",
      "\n",
      "{\"id\": 18028, \"code\": \"def line 2 d seg dist p1 p2 p0 x21 p2 [ 0 ] - p1 [ 0 ] y21 p2 [ 1 ] - p1 [ 1 ] x01 np asarray p0 [ 0 ] - p1 [ 0 ] y01 np asarray p0 [ 1 ] - p1 [ 1 ] u x01 * x21 + y01 * y21 / float abs x21 ** 2 + y21 ** 2 u np clip u 0 1 d np sqrt x01 - u * x21 ** 2 + y01 - u * y21 ** 2 return d\", \"predictions\": [\"return line perpendicular to line 2 .\"], \"references\": [\"distance(s) from line defined by p1 - p2 to point(s) p0 p0[0] = x(s) p0[1] = y(s) intersection point p = p1 + u* and intersection point lies within segment if u is between 0 and 1 .\"], \"bleu\": 0.002635624544228439, \"rouge_l\": 0.11860012961762798}\n",
      "\n",
      "{\"id\": 18092, \"code\": \"@pytest yield fixture def use vcr request monkeypatch if VCR RECORD MODE u'off' yield None else module request module name split u'tests ' [ -1 ]class name request cls name cassette name u' ' join [module class name request function name ] cassette path os path join VCR CASSETTE DIR cassette name online Trueif vcr record mode u'none' online Falseelif vcr record mode u'once' online not os path exists cassette path if not online log debug u' Disablingdomainlimitersduring VC Rplayback ' monkeypatch setattr u'flexget utils requests limit domains' mock Mock with vcr use cassette path cassette path as cassette yield cassette\", \"predictions\": [\"set vcr_limit .\"], \"references\": [\"this fixture is applied automatically to any test using the online mark .\"], \"bleu\": 0.019167100299515256, \"rouge_l\": 0.1123388581952118}\n",
      "\n",
      "{\"id\": 18149, \"code\": \"def gs decorrelation w W j w - np dot np dot w W[ j] T W[ j] return w\", \"predictions\": [\"the[x][x][x][i] .\"], \"references\": [\"orthonormalize w wrt the first j rows of w parameters w : ndarray of shape(n) array to be orthogonalized w : ndarray of shape null space definition j : int < p the no of rows of null space w wrt which w is orthogonalized .\"], \"bleu\": 2.1195374009482997e-10, \"rouge_l\": 0.03575615474794842}\n",
      "\n",
      "{\"id\": 18192, \"code\": \"def Unique Iterator iterator key lambda x x so far set def no dups x k key x if k in so far return Falseelse so far add k return Truereturn Iterator Filter iterator no dups\", \"predictions\": [\"return unique elements .\"], \"references\": [\"takes an iterator and returns an iterator that returns only the first occurence of each entry .\"], \"bleu\": 0.013931732312048943, \"rouge_l\": 0.08567415730337079}\n",
      "\n",
      "{\"id\": 18225, \"code\": \"def write checkpoint current key ctr cluster mapping ids bestscores order out fp checkpoint dir out fp + '/checkpoints/' if not exists checkpoint dir create dir checkpoint dir out fp checkpoint dir + '/checkpoint%d pickle' % ctr out fh open out fp 'w' pickle dump current key ctr cluster mapping ids bestscores order out fh return out fp\", \"predictions\": [\"save checkpoint information to checkpoint_key .\"], \"references\": [\"write intermediate results to checkpoint file current_key: the identifier of the current denoiser round ctr: a uniq counter to label the checkpoint cluster_mapping: an intermediate cluster mapping as dict ids: the dict of active ids order: a list of ids .\"], \"bleu\": 0.0007692379442157136, \"rouge_l\": 0.11254612546125461}\n",
      "\n",
      "{\"id\": 18311, \"code\": \"def generate module src if not src return UNKNOWN MODULE filename ext splitext urlsplit src path if ext not in ' js' ' jsx' ' coffee' return UNKNOWN MODUL Eif filename endswith ' min' filename filename[ -4 ]tokens filename split '/' for idx token in enumerate tokens if VERSION RE match token return '/' join tokens[ idx + 1 ] return CLEAN MODULE RE sub '' filename or UNKNOWN MODULE\", \"predictions\": [\"given a src .\"], \"references\": [\"converts a url into a made-up module name by doing the following: * extract just the path name ignoring querystrings * trimming off the initial / * trimming off the file extension * removes off useless folder prefixes e .\"], \"bleu\": 4.90721024165063e-05, \"rouge_l\": 0.07922077922077922}\n",
      "\n",
      "{\"id\": 18395, \"code\": \"def load class dotted path dotted path split dotted path split ' ' if len dotted path split > 1 klass name dotted path split[ -1 ]module name ' ' join dotted path split[ -1 ] module load module module name if has attribute module klass name klass getattr module klass name return klasselse raise Attribute Error ' Module%sdoesnothaveclassattribute%s' % module name klass name else raise Value Error ' Dottedmodulepath%smustcontainamodulenameandaclassname' % dotted path\", \"predictions\": [\"load a class from a dotted path .\"], \"references\": [\"loads and returns a class definition provided a dotted path specification the last part of the dotted path is the class name and there is at least one module name preceding the class name .\"], \"bleu\": 0.012622857620562433, \"rouge_l\": 0.2506849315068493}\n",
      "\n",
      "{\"id\": 18396, \"code\": \"def deconv X w subsample 1 1 border mode 0 0 conv mode 'conv' img gpu contiguous X kerns gpu contiguous w desc Gpu Dnn Conv Desc border mode border mode subsample subsample conv mode conv mode gpu alloc empty img shape[ 0 ] kerns shape[ 1 ] img shape[ 2 ] * subsample[ 0 ] img shape[ 3 ] * subsample[ 1 ] shape kerns shape out gpu alloc empty img shape[ 0 ] kerns shape[ 1 ] img shape[ 2 ] * subsample[ 0 ] img shape[ 3 ] * subsample[ 1 ] d img Gpu Dnn Conv Grad I kerns img out desc return d img\", \"predictions\": [\"convolutional convolution function .\"], \"references\": [\"sets up dummy convolutional forward pass and uses its grad as deconv currently only tested/working with same padding .\"], \"bleu\": 0.009351487442933324, \"rouge_l\": 0.15561224489795916}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in lines:\n",
    "    js = json.loads(line)\n",
    "    if js['bleu']<=0.02:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRC_BA</th>\n",
       "      <th>PRC_CAT</th>\n",
       "      <th>PRC_JPM</th>\n",
       "      <th>PRC_MCD</th>\n",
       "      <th>PRC_MMM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>112.786011</td>\n",
       "      <td>75.253960</td>\n",
       "      <td>52.891674</td>\n",
       "      <td>79.218002</td>\n",
       "      <td>138.201538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>112.004875</td>\n",
       "      <td>71.281593</td>\n",
       "      <td>51.249664</td>\n",
       "      <td>78.343079</td>\n",
       "      <td>135.084717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>110.685638</td>\n",
       "      <td>70.822929</td>\n",
       "      <td>49.920807</td>\n",
       "      <td>78.487503</td>\n",
       "      <td>133.644241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>112.404106</td>\n",
       "      <td>71.920425</td>\n",
       "      <td>49.996979</td>\n",
       "      <td>79.855064</td>\n",
       "      <td>134.612991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>114.391670</td>\n",
       "      <td>72.657578</td>\n",
       "      <td>51.114243</td>\n",
       "      <td>80.152367</td>\n",
       "      <td>137.839325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                PRC_BA    PRC_CAT    PRC_JPM    PRC_MCD     PRC_MMM\n",
       "Date                                                               \n",
       "2015-01-02  112.786011  75.253960  52.891674  79.218002  138.201538\n",
       "2015-01-05  112.004875  71.281593  51.249664  78.343079  135.084717\n",
       "2015-01-06  110.685638  70.822929  49.920807  78.487503  133.644241\n",
       "2015-01-07  112.404106  71.920425  49.996979  79.855064  134.612991\n",
       "2015-01-08  114.391670  72.657578  51.114243  80.152367  137.839325"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# Random Stock Selection\n",
    "\n",
    "np.random.seed (1291523)\n",
    "ticker_list = ['AAPL', 'AXP', 'BA', 'CAT', 'CSCO', 'CVX', 'DIS', 'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'KO',\n",
    "           'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PFE', 'PG', 'TRV', 'UNH', 'UTX', 'V', 'VZ', 'WMT', 'XOM']\n",
    "stock_list = sorted(np.random.choice(ticker_list,5,replace=False))\n",
    "stock_list\n",
    "start = dt.datetime(2015, 1, 1)\n",
    "end = dt.datetime.now()\n",
    "\n",
    "prices = pd.DataFrame()\n",
    "for ticker in stock_list:\n",
    "    prices['PRC_' + ticker] = web.DataReader(ticker, 'yahoo', start, end)['Adj Close']\n",
    "\n",
    "prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.to_pickle('price.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_env",
   "language": "python",
   "name": "wy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
